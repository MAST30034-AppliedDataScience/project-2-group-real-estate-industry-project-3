{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:35.463832Z",
     "start_time": "2024-09-25T07:10:30.327037Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 17:10:32 WARN Utils: Your hostname, coldbrew.local resolves to a loopback address: 127.0.0.1; using 172.16.119.16 instead (on interface en0)\n",
      "24/09/25 17:10:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/25 17:10:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/09/25 17:10:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import functions as F  #filtering\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import pandas as pd\n",
    "# starting a Spark session\n",
    "spark = (\n",
    "    SparkSession.builder.appName('PropertyFirstCleaning')\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"2g\")\n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# read the parquet dataset\n",
    "property = spark.read.parquet('../data/landing/property_data/property_table_01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:36.325101Z",
     "start_time": "2024-09-25T07:10:35.465101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(432315, 10)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of rows and columns\n",
    "row_count = property.count()\n",
    "column_count = len(property.columns)\n",
    "\n",
    "# Return the shape of the cleaned DataFrame\n",
    "property_shape = (row_count, column_count)\n",
    "property_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:38.907910Z",
     "start_time": "2024-09-25T07:10:36.326696Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of duplicate rows directly\n",
    "duplicate_count = property.count() - property.dropDuplicates().count()\n",
    "duplicate_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:39.893782Z",
     "start_time": "2024-09-25T07:10:38.909306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-------------+---------------------+--------+------+-----------------+-------------+---------------+------------------+\n",
      "|Year|Year ending|Police Region|Local Government Area|Postcode|Suburb|Location Division|Property Item|Number of Items|Value of Items ($)|\n",
      "+----+-----------+-------------+---------------------+--------+------+-----------------+-------------+---------------+------------------+\n",
      "|   0|          0|            0|                    0|       0|     0|                0|            0|              0|                 0|\n",
      "+----+-----------+-------------+---------------------+--------+------+-----------------+-------------+---------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Get the number of NA values for each column\n",
    "na_counts = property.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in property.columns])\n",
    "na_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are no duplicates and NULL values on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:40.146296Z",
     "start_time": "2024-09-25T07:10:39.894498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "+----+-----------+------------------+---------------------+--------+-------+-----------------+--------------------+---------------+------------------+\n|Year|Year ending|     Police Region|Local Government Area|Postcode| Suburb|Location Division|       Property Item|Number of Items|Value of Items ($)|\n+----+-----------+------------------+---------------------+--------+-------+-----------------+--------------------+---------------+------------------+\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|     Car Accessories|             14|            2040.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|       Cash/Document|             42|           51750.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|            Clothing|              9|            2140.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|Electrical Applia...|             24|           13310.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|                Food|              1|             200.0|\n+----+-----------+------------------+---------------------+--------+-------+-----------------+--------------------+---------------+------------------+",
      "text/html": "<table border='1'>\n<tr><th>Year</th><th>Year ending</th><th>Police Region</th><th>Local Government Area</th><th>Postcode</th><th>Suburb</th><th>Location Division</th><th>Property Item</th><th>Number of Items</th><th>Value of Items ($)</th></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Car Accessories</td><td>14</td><td>2040.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Cash/Document</td><td>42</td><td>51750.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Clothing</td><td>9</td><td>2140.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Electrical Applia...</td><td>24</td><td>13310.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Food</td><td>1</td><td>200.0</td></tr>\n</table>\n"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "property.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:40.539612Z",
     "start_time": "2024-09-25T07:10:40.146982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-------------+---------------------+--------+--------+-----------------+---------------+---------------+------------------+\n",
      "|Year|Year ending|Police Region|Local Government Area|Postcode|  Suburb|Location Division|  Property Item|Number of Items|Value of Items ($)|\n",
      "+----+-----------+-------------+---------------------+--------+--------+-----------------+---------------+---------------+------------------+\n",
      "|2024|      March|     Victoria|             Victoria|Victoria|Victoria|    1 Residential|Car Accessories|           6636|        1659629.97|\n",
      "+----+-----------+-------------+---------------------+--------+--------+-----------------+---------------+---------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Create a filter condition to check if any column contains 'VICTORIA' or None\n",
    "condition = F.lit(False)\n",
    "for col in property.columns:\n",
    "    condition = condition | F.lower(F.col(col)).isin(F.lower(F.lit('Victoria')), None)\n",
    "\n",
    "# Apply the condition to filter the DataFrame\n",
    "victoria_none_check = property.filter(condition)\n",
    "\n",
    "victoria_none_check.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:41.559057Z",
     "start_time": "2024-09-25T07:10:40.550687Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows containing 'Victoria' or None: 989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Apply the condition to filter the DataFrame and count the results\n",
    "victoria_none_count = property.filter(condition).count()\n",
    "\n",
    "# Show the count of rows that match the condition\n",
    "print(f\"Number of rows containing 'Victoria' or None: {victoria_none_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:41.584497Z",
     "start_time": "2024-09-25T07:10:41.573998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.00228768374911812"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "victoria_none_count / row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:42.881722Z",
     "start_time": "2024-09-25T07:10:41.587595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+------------------+---------------------+--------+-------+-----------------+---------------+---------------+------------------+\n",
      "|Year|Year ending|     Police Region|Local Government Area|Postcode| Suburb|Location Division|  Property Item|Number of Items|Value of Items ($)|\n",
      "+----+-----------+------------------+---------------------+--------+-------+-----------------+---------------+---------------+------------------+\n",
      "|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|Car Accessories|             14|            2040.0|\n",
      "+----+-----------+------------------+---------------------+--------+-------+-----------------+---------------+---------------+------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows remaining after removing rows containing 'Victoria': 431294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a filter condition to check if any column contains 'Victoria' (case-insensitive)\n",
    "condition = F.lit(False)\n",
    "\n",
    "for col in property.columns:\n",
    "    condition = condition | F.lower(F.col(col)).contains(F.lower(F.lit('Victoria')))\n",
    "\n",
    "# Filter out rows where any column contains 'Victoria'\n",
    "property = property.filter(~condition)\n",
    "\n",
    "# Show the resulting DataFrame without rows containing 'Victoria'\n",
    "property.show(1)\n",
    "\n",
    "# Optionally, count the remaining rows\n",
    "remaining_count = property.count()\n",
    "print(f\"Number of rows remaining after removing rows containing 'Victoria': {remaining_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:43.129189Z",
     "start_time": "2024-09-25T07:10:42.886580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "+----+-----------+------------------+---------------------+--------+-------+-----------------+--------------------+---------------+------------------+\n|Year|Year ending|     Police Region|Local Government Area|Postcode| Suburb|Location Division|       Property Item|Number of Items|Value of Items ($)|\n+----+-----------+------------------+---------------------+--------+-------+-----------------+--------------------+---------------+------------------+\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|     Car Accessories|             14|            2040.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|       Cash/Document|             42|           51750.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|            Clothing|              9|            2140.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|Electrical Applia...|             24|           13310.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|                Food|              1|             200.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|           Furniture|              1|            1000.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|        Garden Items|             10|            5253.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|           Jewellery|             79|          140802.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|   Personal Property|             54|           38369.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|  Photographic Equip|              3|             700.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|      Sporting Goods|              5|            1169.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|    Timber/Build Mat|              6|           22055.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|               Tools|             17|           20920.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|    1 Residential|              Tv/Vcr|              6|           10700.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|      2 Community|     Car Accessories|             25|             200.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|      2 Community|       Cash/Document|             23|            3945.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|      2 Community|            Clothing|              6|             970.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|      2 Community|Electrical Applia...|              3|            1360.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|      2 Community|     Marine Property|              1|            1500.0|\n|2024|      March|1 North West Metro|              Banyule|    3079|Ivanhoe|      2 Community|               Other|             24|           11950.0|\n+----+-----------+------------------+---------------------+--------+-------+-----------------+--------------------+---------------+------------------+\nonly showing top 20 rows",
      "text/html": "<table border='1'>\n<tr><th>Year</th><th>Year ending</th><th>Police Region</th><th>Local Government Area</th><th>Postcode</th><th>Suburb</th><th>Location Division</th><th>Property Item</th><th>Number of Items</th><th>Value of Items ($)</th></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Car Accessories</td><td>14</td><td>2040.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Cash/Document</td><td>42</td><td>51750.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Clothing</td><td>9</td><td>2140.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Electrical Applia...</td><td>24</td><td>13310.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Food</td><td>1</td><td>200.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Furniture</td><td>1</td><td>1000.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Garden Items</td><td>10</td><td>5253.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Jewellery</td><td>79</td><td>140802.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Personal Property</td><td>54</td><td>38369.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Photographic Equip</td><td>3</td><td>700.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Sporting Goods</td><td>5</td><td>1169.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Timber/Build Mat</td><td>6</td><td>22055.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Tools</td><td>17</td><td>20920.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>1 Residential</td><td>Tv/Vcr</td><td>6</td><td>10700.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>2 Community</td><td>Car Accessories</td><td>25</td><td>200.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>2 Community</td><td>Cash/Document</td><td>23</td><td>3945.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>2 Community</td><td>Clothing</td><td>6</td><td>970.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>2 Community</td><td>Electrical Applia...</td><td>3</td><td>1360.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>2 Community</td><td>Marine Property</td><td>1</td><td>1500.0</td></tr>\n<tr><td>2024</td><td>March</td><td>1 North West Metro</td><td>Banyule</td><td>3079</td><td>Ivanhoe</td><td>2 Community</td><td>Other</td><td>24</td><td>11950.0</td></tr>\n</table>\nonly showing top 20 rows\n"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for a specific suburb, e.g., 'Arcadia'\n",
    "specific_suburb = \"Ivanhoe\"\n",
    "suburb_check = property[property['Suburb'] == specific_suburb]\n",
    "\n",
    "# Show the result\n",
    "suburb_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:44.730843Z",
     "start_time": "2024-09-25T07:10:43.130429Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "    Postcode  Average Value Per Item ($)\n1       3959                 1102.127216\n2       3414                 2064.451777\n3       3015                  665.748732\n4       3858                  823.703448\n5       3517                 2851.723577\n..       ...                         ...\n688     3419                  794.301733\n689     3093                 1447.499927\n690     3033                  752.596557\n691     3715                 1341.936842\n692     3920                  879.625000\n\n[692 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Postcode</th>\n      <th>Average Value Per Item ($)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>3959</td>\n      <td>1102.127216</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3414</td>\n      <td>2064.451777</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3015</td>\n      <td>665.748732</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3858</td>\n      <td>823.703448</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3517</td>\n      <td>2851.723577</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>688</th>\n      <td>3419</td>\n      <td>794.301733</td>\n    </tr>\n    <tr>\n      <th>689</th>\n      <td>3093</td>\n      <td>1447.499927</td>\n    </tr>\n    <tr>\n      <th>690</th>\n      <td>3033</td>\n      <td>752.596557</td>\n    </tr>\n    <tr>\n      <th>691</th>\n      <td>3715</td>\n      <td>1341.936842</td>\n    </tr>\n    <tr>\n      <th>692</th>\n      <td>3920</td>\n      <td>879.625000</td>\n    </tr>\n  </tbody>\n</table>\n<p>692 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean and convert the 'Value of Items ($)' and 'Number of Items' columns to numeric\n",
    "property = property.withColumn(\"Value of Items ($)\", F.regexp_replace(F.col(\"Value of Items ($)\"), \"[$,]\", \"\").cast(\"float\"))\n",
    "property = property.withColumn(\"Number of Items\", F.col(\"Number of Items\").cast(\"int\"))\n",
    "\n",
    "# Filter out instances where 'Value of Items ($)' is 0\n",
    "filtered_property_df = property.filter(property[\"Value of Items ($)\"] > 0)\n",
    "\n",
    "# Calculate the sum of 'Value of Items ($)' and 'Number of Items' for each 'Postcode'\n",
    "average_value_by_postcode = filtered_property_df.groupBy(\"Postcode\").agg(\n",
    "    (F.sum(\"Value of Items ($)\") / F.sum(\"Number of Items\")).alias(\"Average Value Per Item ($)\")\n",
    ")\n",
    "\n",
    "# Convert to Pandas for easier viewing\n",
    "average_value_by_postcode_summary = average_value_by_postcode.toPandas()\n",
    "\n",
    "# Adjust the index to start from 1\n",
    "average_value_by_postcode_summary.index = average_value_by_postcode_summary.index + 1\n",
    "\n",
    "# Show the resulting summary\n",
    "average_value_by_postcode_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:45.984257Z",
     "start_time": "2024-09-25T07:10:44.732902Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "            Property Item  Count\n1         Car Accessories  31320\n2           Cash/Document  30208\n3       Cigarettes/Liquor  16660\n4                Clothing  19486\n5           Domestic Pets   4036\n6   Electrical Appliances  31240\n7              Explosives     70\n8     Firearms/Ammunition   4067\n9                    Food  13790\n10              Furniture   9936\n11           Garden Items  18171\n12        Household Items  21256\n13              Jewellery  17964\n14              Livestock   3657\n15        Marine Property   6127\n16                  Other  42187\n17      Personal Property  29050\n18     Photographic Equip  15777\n19        Police Property   1071\n20            Power Tools  31567\n21         Sporting Goods  20889\n22       Timber/Build Mat  18563\n23                  Tools  30241\n24                 Tv/Vcr  11690\n25                Weapons   2271",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Property Item</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Car Accessories</td>\n      <td>31320</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cash/Document</td>\n      <td>30208</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Cigarettes/Liquor</td>\n      <td>16660</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Clothing</td>\n      <td>19486</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Domestic Pets</td>\n      <td>4036</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Electrical Appliances</td>\n      <td>31240</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Explosives</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Firearms/Ammunition</td>\n      <td>4067</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Food</td>\n      <td>13790</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Furniture</td>\n      <td>9936</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Garden Items</td>\n      <td>18171</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Household Items</td>\n      <td>21256</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Jewellery</td>\n      <td>17964</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Livestock</td>\n      <td>3657</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Marine Property</td>\n      <td>6127</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Other</td>\n      <td>42187</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Personal Property</td>\n      <td>29050</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Photographic Equip</td>\n      <td>15777</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Police Property</td>\n      <td>1071</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Power Tools</td>\n      <td>31567</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Sporting Goods</td>\n      <td>20889</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Timber/Build Mat</td>\n      <td>18563</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Tools</td>\n      <td>30241</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Tv/Vcr</td>\n      <td>11690</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Weapons</td>\n      <td>2271</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the occurrences of each 'Property Item'\n",
    "property_item_counts = property.groupBy(\"Property Item\").count().orderBy(\"Property Item\", ascending=True)\n",
    "\n",
    "# Convert to Pandas for easier viewing (optional, if the dataset is small enough to fit in memory)\n",
    "property_item_summary = property_item_counts.toPandas()\n",
    "\n",
    "# Adjust the index to start from 1\n",
    "property_item_summary.index = property_item_summary.index + 1\n",
    "\n",
    "# Rename columns for better readability\n",
    "property_item_summary.columns = ['Property Item', 'Count']\n",
    "\n",
    "property_item_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:46.156203Z",
     "start_time": "2024-09-25T07:10:45.986776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    sa2_code       sa2_name chg_flag    chg_lbl sa3_code  sa3_name sa4_code  \\\n0  201011001      Alfredton        0  No change    20101  Ballarat      201   \n1  201011002       Ballarat        0  No change    20101  Ballarat      201   \n2  201011005      Buninyong        0  No change    20101  Ballarat      201   \n3  201011006      Delacombe        0  No change    20101  Ballarat      201   \n4  201011007  Smythes Creek        0  No change    20101  Ballarat      201   \n\n   sa4_name gcc_code      gcc_name ste_code  ste_name aus_code   aus_name  \\\n0  Ballarat    2RVIC  Rest of Vic.        2  Victoria      AUS  Australia   \n1  Ballarat    2RVIC  Rest of Vic.        2  Victoria      AUS  Australia   \n2  Ballarat    2RVIC  Rest of Vic.        2  Victoria      AUS  Australia   \n3  Ballarat    2RVIC  Rest of Vic.        2  Victoria      AUS  Australia   \n4  Ballarat    2RVIC  Rest of Vic.        2  Victoria      AUS  Australia   \n\n   areasqkm                                           loci_uri  \\\n0   52.7109  http://linked.data.gov.au/dataset/asgsed3/SA2/...   \n1   12.3787  http://linked.data.gov.au/dataset/asgsed3/SA2/...   \n2   51.5855  http://linked.data.gov.au/dataset/asgsed3/SA2/...   \n3   34.1607  http://linked.data.gov.au/dataset/asgsed3/SA2/...   \n4  104.7274  http://linked.data.gov.au/dataset/asgsed3/SA2/...   \n\n                                            geometry  \n0  POLYGON ((143.78281 -37.56667, 143.75557 -37.5...  \n1  POLYGON ((143.81896 -37.55583, 143.81644 -37.5...  \n2  POLYGON ((143.8417 -37.61597, 143.84175 -37.61...  \n3  POLYGON ((143.75049 -37.5912, 143.75044 -37.59...  \n4  POLYGON ((143.73295 -37.62334, 143.73262 -37.6...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sa2_code</th>\n      <th>sa2_name</th>\n      <th>chg_flag</th>\n      <th>chg_lbl</th>\n      <th>sa3_code</th>\n      <th>sa3_name</th>\n      <th>sa4_code</th>\n      <th>sa4_name</th>\n      <th>gcc_code</th>\n      <th>gcc_name</th>\n      <th>ste_code</th>\n      <th>ste_name</th>\n      <th>aus_code</th>\n      <th>aus_name</th>\n      <th>areasqkm</th>\n      <th>loci_uri</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>201011001</td>\n      <td>Alfredton</td>\n      <td>0</td>\n      <td>No change</td>\n      <td>20101</td>\n      <td>Ballarat</td>\n      <td>201</td>\n      <td>Ballarat</td>\n      <td>2RVIC</td>\n      <td>Rest of Vic.</td>\n      <td>2</td>\n      <td>Victoria</td>\n      <td>AUS</td>\n      <td>Australia</td>\n      <td>52.7109</td>\n      <td>http://linked.data.gov.au/dataset/asgsed3/SA2/...</td>\n      <td>POLYGON ((143.78281 -37.56667, 143.75557 -37.5...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>201011002</td>\n      <td>Ballarat</td>\n      <td>0</td>\n      <td>No change</td>\n      <td>20101</td>\n      <td>Ballarat</td>\n      <td>201</td>\n      <td>Ballarat</td>\n      <td>2RVIC</td>\n      <td>Rest of Vic.</td>\n      <td>2</td>\n      <td>Victoria</td>\n      <td>AUS</td>\n      <td>Australia</td>\n      <td>12.3787</td>\n      <td>http://linked.data.gov.au/dataset/asgsed3/SA2/...</td>\n      <td>POLYGON ((143.81896 -37.55583, 143.81644 -37.5...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>201011005</td>\n      <td>Buninyong</td>\n      <td>0</td>\n      <td>No change</td>\n      <td>20101</td>\n      <td>Ballarat</td>\n      <td>201</td>\n      <td>Ballarat</td>\n      <td>2RVIC</td>\n      <td>Rest of Vic.</td>\n      <td>2</td>\n      <td>Victoria</td>\n      <td>AUS</td>\n      <td>Australia</td>\n      <td>51.5855</td>\n      <td>http://linked.data.gov.au/dataset/asgsed3/SA2/...</td>\n      <td>POLYGON ((143.8417 -37.61597, 143.84175 -37.61...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>201011006</td>\n      <td>Delacombe</td>\n      <td>0</td>\n      <td>No change</td>\n      <td>20101</td>\n      <td>Ballarat</td>\n      <td>201</td>\n      <td>Ballarat</td>\n      <td>2RVIC</td>\n      <td>Rest of Vic.</td>\n      <td>2</td>\n      <td>Victoria</td>\n      <td>AUS</td>\n      <td>Australia</td>\n      <td>34.1607</td>\n      <td>http://linked.data.gov.au/dataset/asgsed3/SA2/...</td>\n      <td>POLYGON ((143.75049 -37.5912, 143.75044 -37.59...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>201011007</td>\n      <td>Smythes Creek</td>\n      <td>0</td>\n      <td>No change</td>\n      <td>20101</td>\n      <td>Ballarat</td>\n      <td>201</td>\n      <td>Ballarat</td>\n      <td>2RVIC</td>\n      <td>Rest of Vic.</td>\n      <td>2</td>\n      <td>Victoria</td>\n      <td>AUS</td>\n      <td>Australia</td>\n      <td>104.7274</td>\n      <td>http://linked.data.gov.au/dataset/asgsed3/SA2/...</td>\n      <td>POLYGON ((143.73295 -37.62334, 143.73262 -37.6...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sf stands for shape file\n",
    "sf = gpd.read_file(\"../data/landing/boundaries/Victoria/vic_dist_boundaries.shp\")\n",
    "\n",
    "sf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:46.162173Z",
     "start_time": "2024-09-25T07:10:46.156967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     sa2_name  \\\n",
      "223  Ivanhoe East - Eaglemont   \n",
      "\n",
      "                                              geometry  \n",
      "223  POLYGON ((145.05176 -37.76678, 145.05188 -37.7...  \n"
     ]
    }
   ],
   "source": [
    "# For exact match search\n",
    "exact_match = sf[sf['sa2_name'].str.lower() == 'ivanhoe east - eaglemont']\n",
    "print(exact_match[['sa2_name', 'geometry']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:51.422965Z",
     "start_time": "2024-09-25T07:10:46.162749Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "   Year Year ending       Police Region Local Government Area Postcode  \\\n0  2024       March  1 North West Metro               Banyule     3079   \n1  2024       March  1 North West Metro               Banyule     3079   \n2  2024       March  1 North West Metro               Banyule     3079   \n3  2024       March  1 North West Metro               Banyule     3079   \n4  2024       March  1 North West Metro               Banyule     3079   \n\n    Suburb Location Division          Property Item  Number of Items  \\\n0  Ivanhoe     1 Residential        Car Accessories               14   \n1  Ivanhoe     1 Residential          Cash/Document               42   \n2  Ivanhoe     1 Residential               Clothing                9   \n3  Ivanhoe     1 Residential  Electrical Appliances               24   \n4  Ivanhoe     1 Residential                   Food                1   \n\n   Value of Items ($) sa2_name  \\\n0              2040.0  Ivanhoe   \n1             51750.0  Ivanhoe   \n2              2140.0  Ivanhoe   \n3             13310.0  Ivanhoe   \n4               200.0  Ivanhoe   \n\n                                            geometry  \n0  POLYGON ((145.02852 -37.76136, 145.02856 -37.7...  \n1  POLYGON ((145.02852 -37.76136, 145.02856 -37.7...  \n2  POLYGON ((145.02852 -37.76136, 145.02856 -37.7...  \n3  POLYGON ((145.02852 -37.76136, 145.02856 -37.7...  \n4  POLYGON ((145.02852 -37.76136, 145.02856 -37.7...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Year ending</th>\n      <th>Police Region</th>\n      <th>Local Government Area</th>\n      <th>Postcode</th>\n      <th>Suburb</th>\n      <th>Location Division</th>\n      <th>Property Item</th>\n      <th>Number of Items</th>\n      <th>Value of Items ($)</th>\n      <th>sa2_name</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3079</td>\n      <td>Ivanhoe</td>\n      <td>1 Residential</td>\n      <td>Car Accessories</td>\n      <td>14</td>\n      <td>2040.0</td>\n      <td>Ivanhoe</td>\n      <td>POLYGON ((145.02852 -37.76136, 145.02856 -37.7...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3079</td>\n      <td>Ivanhoe</td>\n      <td>1 Residential</td>\n      <td>Cash/Document</td>\n      <td>42</td>\n      <td>51750.0</td>\n      <td>Ivanhoe</td>\n      <td>POLYGON ((145.02852 -37.76136, 145.02856 -37.7...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3079</td>\n      <td>Ivanhoe</td>\n      <td>1 Residential</td>\n      <td>Clothing</td>\n      <td>9</td>\n      <td>2140.0</td>\n      <td>Ivanhoe</td>\n      <td>POLYGON ((145.02852 -37.76136, 145.02856 -37.7...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3079</td>\n      <td>Ivanhoe</td>\n      <td>1 Residential</td>\n      <td>Electrical Appliances</td>\n      <td>24</td>\n      <td>13310.0</td>\n      <td>Ivanhoe</td>\n      <td>POLYGON ((145.02852 -37.76136, 145.02856 -37.7...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3079</td>\n      <td>Ivanhoe</td>\n      <td>1 Residential</td>\n      <td>Food</td>\n      <td>1</td>\n      <td>200.0</td>\n      <td>Ivanhoe</td>\n      <td>POLYGON ((145.02852 -37.76136, 145.02856 -37.7...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the PySpark DataFrame to Pandas\n",
    "property_pandas = property.toPandas()\n",
    "\n",
    "# Perform the left join on 'suburb' from property and 'sa2_name' from sf\n",
    "merged_df = property_pandas.merge(sf[['sa2_name', 'geometry']], \n",
    "                                  left_on='Suburb', right_on='sa2_name', \n",
    "                                  how='left')\n",
    "\n",
    "# Convert the merged DataFrame back to a GeoDataFrame\n",
    "merged_gdf = gpd.GeoDataFrame(merged_df, geometry='geometry')\n",
    "\n",
    "# Display the merged GeoDataFrame\n",
    "merged_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:51.652893Z",
     "start_time": "2024-09-25T07:10:51.423767Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_7/sr3p02zn35v2xg1fm8dsbz6c0000gn/T/ipykernel_1373/2782866017.py:1: UserWarning: Geometry is in a geographic CRS. Results from 'length' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  merged_gdf.length\n"
     ]
    },
    {
     "data": {
      "text/plain": "0         0.160206\n1         0.160206\n2         0.160206\n3         0.160206\n4         0.160206\n            ...   \n431289         NaN\n431290         NaN\n431291         NaN\n431292         NaN\n431293         NaN\nLength: 431294, dtype: float64"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_gdf.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:51.747855Z",
     "start_time": "2024-09-25T07:10:51.653778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Year Year ending       Police Region Local Government Area Postcode  \\\n45  2024       March  1 North West Metro               Banyule     3079   \n46  2024       March  1 North West Metro               Banyule     3079   \n47  2024       March  1 North West Metro               Banyule     3079   \n48  2024       March  1 North West Metro               Banyule     3079   \n49  2024       March  1 North West Metro               Banyule     3079   \n\n          Suburb Location Division  Property Item  Number of Items  \\\n45  Ivanhoe East     1 Residential  Cash/Document               10   \n46  Ivanhoe East     1 Residential       Clothing                2   \n47  Ivanhoe East     1 Residential      Jewellery                3   \n48  Ivanhoe East     1 Residential          Other                8   \n49  Ivanhoe East     1 Residential    Power Tools                3   \n\n    Value of Items ($) sa2_name geometry  \n45               187.0      NaN     None  \n46               450.0      NaN     None  \n47              5000.0      NaN     None  \n48              2500.0      NaN     None  \n49              1350.0      NaN     None  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Year ending</th>\n      <th>Police Region</th>\n      <th>Local Government Area</th>\n      <th>Postcode</th>\n      <th>Suburb</th>\n      <th>Location Division</th>\n      <th>Property Item</th>\n      <th>Number of Items</th>\n      <th>Value of Items ($)</th>\n      <th>sa2_name</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>45</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3079</td>\n      <td>Ivanhoe East</td>\n      <td>1 Residential</td>\n      <td>Cash/Document</td>\n      <td>10</td>\n      <td>187.0</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3079</td>\n      <td>Ivanhoe East</td>\n      <td>1 Residential</td>\n      <td>Clothing</td>\n      <td>2</td>\n      <td>450.0</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3079</td>\n      <td>Ivanhoe East</td>\n      <td>1 Residential</td>\n      <td>Jewellery</td>\n      <td>3</td>\n      <td>5000.0</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3079</td>\n      <td>Ivanhoe East</td>\n      <td>1 Residential</td>\n      <td>Other</td>\n      <td>8</td>\n      <td>2500.0</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3079</td>\n      <td>Ivanhoe East</td>\n      <td>1 Residential</td>\n      <td>Power Tools</td>\n      <td>3</td>\n      <td>1350.0</td>\n      <td>NaN</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any rows have missing geometry (NaN values in the 'geometry' column)\n",
    "missing_geometry = merged_gdf[merged_gdf['geometry'].isnull()]\n",
    "\n",
    "# Count how many suburbs are missing geometry\n",
    "missing_geometry_count = missing_geometry.shape[0]\n",
    "\n",
    "# Show the first few rows of suburbs without geometry\n",
    "# missing_geometry.head(20), missing_geometry_count\n",
    "missing_geometry.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:51.857075Z",
     "start_time": "2024-09-25T07:10:51.748475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(array(['Ivanhoe East', 'Bellfield', 'Heidelberg Heights', ...,\n        'Swanwater', 'Tanwood', 'Chinangin'], dtype=object),\n 297977)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any rows have missing geometry (NaN values in the 'geometry' column)\n",
    "missing_geometry = merged_gdf[merged_gdf['geometry'].isnull()]\n",
    "\n",
    "# Count how many suburbs are missing geometry\n",
    "missing_geometry_count = missing_geometry.shape[0]\n",
    "\n",
    "# Return the suburb names for the rows with missing geometry\n",
    "missing_suburbs = missing_geometry['Suburb'].unique()\n",
    "\n",
    "# Show the missing suburbs and the count of missing geometries\n",
    "missing_suburbs, missing_geometry_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:51.980285Z",
     "start_time": "2024-09-25T07:10:51.859357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        id  postcode   locality state        long        lat  \\\n6202  4746      3000  MELBOURNE   VIC  144.982585 -37.814437   \n\n                        dc           type                       status  \\\n6202  CITY DELIVERY CENTRE  Delivery Area  Updated 17-Mar-2024 AUSPOST   \n\n          sa3  ...   altitude  chargezone phn_code                 phn_name  \\\n6202  20604.0  ...  27.332188          V1   PHN201  North Western Melbourne   \n\n      lgaregion  lgacode  electorate    electoraterating  sed_code  \\\n6202  Melbourne  24600.0   Melbourne  Inner Metropolitan   24703.0   \n\n                               sed_name  \n6202  Melbourne (Northern Metropolitan)  \n\n[1 rows x 41 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>postcode</th>\n      <th>locality</th>\n      <th>state</th>\n      <th>long</th>\n      <th>lat</th>\n      <th>dc</th>\n      <th>type</th>\n      <th>status</th>\n      <th>sa3</th>\n      <th>...</th>\n      <th>altitude</th>\n      <th>chargezone</th>\n      <th>phn_code</th>\n      <th>phn_name</th>\n      <th>lgaregion</th>\n      <th>lgacode</th>\n      <th>electorate</th>\n      <th>electoraterating</th>\n      <th>sed_code</th>\n      <th>sed_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6202</th>\n      <td>4746</td>\n      <td>3000</td>\n      <td>MELBOURNE</td>\n      <td>VIC</td>\n      <td>144.982585</td>\n      <td>-37.814437</td>\n      <td>CITY DELIVERY CENTRE</td>\n      <td>Delivery Area</td>\n      <td>Updated 17-Mar-2024 AUSPOST</td>\n      <td>20604.0</td>\n      <td>...</td>\n      <td>27.332188</td>\n      <td>V1</td>\n      <td>PHN201</td>\n      <td>North Western Melbourne</td>\n      <td>Melbourne</td>\n      <td>24600.0</td>\n      <td>Melbourne</td>\n      <td>Inner Metropolitan</td>\n      <td>24703.0</td>\n      <td>Melbourne (Northern Metropolitan)</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 41 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Load the suburb_df Parquet file\n",
    "suburb_df = pd.read_parquet('../data/landing/suburb_match/suburb_match.parquet')\n",
    "\n",
    "# Filter the DataFrame to only include rows where the state is 'VIC'\n",
    "suburb_df = suburb_df[suburb_df['state'] == 'VIC']\n",
    "\n",
    "# Display the first 10 rows of the filtered DataFrame\n",
    "suburb_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:51.983889Z",
     "start_time": "2024-09-25T07:10:51.980920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['id', 'postcode', 'locality', 'state', 'long', 'lat', 'dc', 'type',\n       'status', 'sa3', 'sa3name', 'sa4', 'sa4name', 'region', 'Lat_precise',\n       'Long_precise', 'SA1_CODE_2021', 'SA1_NAME_2021', 'SA2_CODE_2021',\n       'SA2_NAME_2021', 'SA3_CODE_2021', 'SA3_NAME_2021', 'SA4_CODE_2021',\n       'SA4_NAME_2021', 'RA_2011', 'RA_2016', 'RA_2021', 'RA_2021_NAME',\n       'MMM_2015', 'MMM_2019', 'ced', 'altitude', 'chargezone', 'phn_code',\n       'phn_name', 'lgaregion', 'lgacode', 'electorate', 'electoraterating',\n       'sed_code', 'sed_name'],\n      dtype='object')"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suburb_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:51.996384Z",
     "start_time": "2024-09-25T07:10:51.984449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        id  postcode       locality state        long        lat  \\\n6393  4651      3079        IVANHOE   VIC  145.048573 -37.772675   \n6394  4652      3079   IVANHOE EAST   VIC  145.048573 -37.772675   \n6395  4653      3079  IVANHOE NORTH   VIC  145.048573 -37.772675   \n\n                              dc           type              status      sa3  \\\n6393  HEIDELBERG WEST DEL CENTRE  Delivery Area  Updated 6-Feb-2020  20901.0   \n6394  HEIDELBERG WEST DEL CENTRE  Delivery Area  Updated 6-Feb-2020  20901.0   \n6395  HEIDELBERG WEST DEL CENTRE  Delivery Area  Updated 6-Feb-2020  20901.0   \n\n      ... altitude  chargezone phn_code           phn_name  lgaregion  \\\n6393  ...      NaN          V1   PHN202  Eastern Melbourne    Banyule   \n6394  ...      NaN          V1   PHN202  Eastern Melbourne    Banyule   \n6395  ...      NaN          V1   PHN202  Eastern Melbourne    Banyule   \n\n      lgacode  electorate    electoraterating  sed_code  \\\n6393  20660.0    Jagajaga  Outer Metropolitan   23802.0   \n6394  20660.0    Jagajaga  Outer Metropolitan   23802.0   \n6395  20660.0    Jagajaga  Outer Metropolitan   23802.0   \n\n                                  sed_name  \n6393  Ivanhoe (North-Eastern Metropolitan)  \n6394  Ivanhoe (North-Eastern Metropolitan)  \n6395  Ivanhoe (North-Eastern Metropolitan)  \n\n[3 rows x 41 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>postcode</th>\n      <th>locality</th>\n      <th>state</th>\n      <th>long</th>\n      <th>lat</th>\n      <th>dc</th>\n      <th>type</th>\n      <th>status</th>\n      <th>sa3</th>\n      <th>...</th>\n      <th>altitude</th>\n      <th>chargezone</th>\n      <th>phn_code</th>\n      <th>phn_name</th>\n      <th>lgaregion</th>\n      <th>lgacode</th>\n      <th>electorate</th>\n      <th>electoraterating</th>\n      <th>sed_code</th>\n      <th>sed_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6393</th>\n      <td>4651</td>\n      <td>3079</td>\n      <td>IVANHOE</td>\n      <td>VIC</td>\n      <td>145.048573</td>\n      <td>-37.772675</td>\n      <td>HEIDELBERG WEST DEL CENTRE</td>\n      <td>Delivery Area</td>\n      <td>Updated 6-Feb-2020</td>\n      <td>20901.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>PHN202</td>\n      <td>Eastern Melbourne</td>\n      <td>Banyule</td>\n      <td>20660.0</td>\n      <td>Jagajaga</td>\n      <td>Outer Metropolitan</td>\n      <td>23802.0</td>\n      <td>Ivanhoe (North-Eastern Metropolitan)</td>\n    </tr>\n    <tr>\n      <th>6394</th>\n      <td>4652</td>\n      <td>3079</td>\n      <td>IVANHOE EAST</td>\n      <td>VIC</td>\n      <td>145.048573</td>\n      <td>-37.772675</td>\n      <td>HEIDELBERG WEST DEL CENTRE</td>\n      <td>Delivery Area</td>\n      <td>Updated 6-Feb-2020</td>\n      <td>20901.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>PHN202</td>\n      <td>Eastern Melbourne</td>\n      <td>Banyule</td>\n      <td>20660.0</td>\n      <td>Jagajaga</td>\n      <td>Outer Metropolitan</td>\n      <td>23802.0</td>\n      <td>Ivanhoe (North-Eastern Metropolitan)</td>\n    </tr>\n    <tr>\n      <th>6395</th>\n      <td>4653</td>\n      <td>3079</td>\n      <td>IVANHOE NORTH</td>\n      <td>VIC</td>\n      <td>145.048573</td>\n      <td>-37.772675</td>\n      <td>HEIDELBERG WEST DEL CENTRE</td>\n      <td>Delivery Area</td>\n      <td>Updated 6-Feb-2020</td>\n      <td>20901.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>PHN202</td>\n      <td>Eastern Melbourne</td>\n      <td>Banyule</td>\n      <td>20660.0</td>\n      <td>Jagajaga</td>\n      <td>Outer Metropolitan</td>\n      <td>23802.0</td>\n      <td>Ivanhoe (North-Eastern Metropolitan)</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 41 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Searching for an exact match of 'Ivanhoe East - Eaglemont' in the 'sa2_name_2021' column\n",
    "exact_sa2_name = suburb_df[suburb_df['SA2_NAME_2021'] == 'Ivanhoe East - Eaglemont']\n",
    "exact_sa2_name.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:52.122920Z",
     "start_time": "2024-09-25T07:10:51.997022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing geometry suburbs matched with SA2_NAME_2021: 290965\n",
      "    Year       Police Region Local Government Area Postcode        Suburb  \\\n",
      "45  2024  1 North West Metro               Banyule     3079  Ivanhoe East   \n",
      "46  2024  1 North West Metro               Banyule     3079  Ivanhoe East   \n",
      "47  2024  1 North West Metro               Banyule     3079  Ivanhoe East   \n",
      "48  2024  1 North West Metro               Banyule     3079  Ivanhoe East   \n",
      "49  2024  1 North West Metro               Banyule     3079  Ivanhoe East   \n",
      "\n",
      "                    sa2_name geometry  \n",
      "45  Ivanhoe East - Eaglemont     None  \n",
      "46  Ivanhoe East - Eaglemont     None  \n",
      "47  Ivanhoe East - Eaglemont     None  \n",
      "48  Ivanhoe East - Eaglemont     None  \n",
      "49  Ivanhoe East - Eaglemont     None  \n",
      "\n",
      "Number of unmatched suburbs: 17\n",
      "First few unmatched suburbs: ['Melbourne' 'Shepparton' 'Mansfield' 'Bandiana' 'McMahons Creek'\n",
      " 'McKinnon' 'Dandenong' 'Dandenong South' 'McCrae' 'Bakery Hill'\n",
      " 'McMillans' 'McKenzie Creek' 'Mildura' 'McKenzie Hill'\n",
      " 'McLoughlins Beach' 'McIntyre' 'Murray-sunset']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dakshagrawal/PycharmProjects/project-2-group-real-estate-industry-project-3/.venv/lib/python3.12/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming suburb_df and missing_geometry are already loaded\n",
    "\n",
    "# Clean the locality column in suburb_df for consistency\n",
    "suburb_df['locality'] = suburb_df['locality'].str.strip().str.title()\n",
    "\n",
    "# Create a dictionary to map 'locality' to 'SA2_NAME_2021'\n",
    "locality_to_sa2_mapping = suburb_df.set_index('locality')['SA2_NAME_2021'].to_dict()\n",
    "\n",
    "# Replace the 'Suburb' values in missing_geometry with corresponding 'SA2_NAME_2021'\n",
    "missing_geometry['sa2_name'] = missing_geometry['Suburb'].map(locality_to_sa2_mapping)\n",
    "\n",
    "# Count how many suburbs were matched\n",
    "matched_count = missing_geometry['sa2_name'].notna().sum()\n",
    "print(f\"Missing geometry suburbs matched with SA2_NAME_2021: {matched_count}\")\n",
    "\n",
    "# Display the first few rows of missing_geometry after updating SA2 names\n",
    "print(missing_geometry[['Year', 'Police Region', 'Local Government Area', 'Postcode', 'Suburb', 'sa2_name', 'geometry']].head())\n",
    "\n",
    "# Optionally, you can create a new DataFrame with only matched rows\n",
    "# missing_geometry_with_sa2 = missing_geometry.dropna(subset=['sa2_name'])\n",
    "\n",
    "# Check for unmatched suburbs\n",
    "unmatched_suburbs = missing_geometry[missing_geometry['sa2_name'].isna()]['Suburb'].unique()\n",
    "print(f\"\\nNumber of unmatched suburbs: {len(unmatched_suburbs)}\")\n",
    "print(\"First few unmatched suburbs:\", unmatched_suburbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:52.218137Z",
     "start_time": "2024-09-25T07:10:52.124891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially matched suburbs: 290965\n",
      "Final count of matched suburbs: 297977\n",
      "\n",
      "Number of remaining unmatched suburbs: 0\n",
      "All suburbs have been matched!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dakshagrawal/PycharmProjects/project-2-group-real-estate-industry-project-3/.venv/lib/python3.12/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# Clean the locality column in suburb_df for consistency\n",
    "suburb_df['locality'] = suburb_df['locality'].str.strip().str.title()\n",
    "\n",
    "# Create a dictionary to map 'locality' to 'SA2_NAME_2021'\n",
    "locality_to_sa2_mapping = suburb_df.set_index('locality')['SA2_NAME_2021'].to_dict()\n",
    "\n",
    "# Replace the 'Suburb' values in missing_geometry with corresponding 'SA2_NAME_2021'\n",
    "missing_geometry['sa2_name'] = missing_geometry['Suburb'].map(locality_to_sa2_mapping)\n",
    "\n",
    "# Count how many suburbs were matched initially\n",
    "initial_matched_count = missing_geometry['sa2_name'].notna().sum()\n",
    "print(f\"Initially matched suburbs: {initial_matched_count}\")\n",
    "\n",
    "# Manual matching dictionary for unmatched suburbs\n",
    "manual_matches = {\n",
    "    'Melbourne': 'North Melbourne',\n",
    "    'Shepparton': 'Shepparton Surrounds - East',\n",
    "    'Bandiana': 'Wodonga',\n",
    "    'McMahons Creek': 'Yarra Valley',\n",
    "    'McKinnon': 'Bentleigh East - South',\n",
    "    'Dandenong': 'Mount Dandenong - Olinda',\n",
    "    'Dandenong South': 'Mount Dandenong - Olinda',\n",
    "    'McCrae': 'Rosebud - McCrae',\n",
    "    'Bakery Hill': 'Sebastopol - Redan',\n",
    "    'McMillans': 'Gannawarra',\n",
    "    'Spring Hill': 'Seymour Surrounds',\n",
    "    'McKenzie Creek': 'Southern Grampians',\n",
    "    'Inglewood': 'Loddon',\n",
    "    'Mildura': 'Mildura - South',\n",
    "    'McKenzie Hill': 'Castlemaine Surrounds',\n",
    "    'Kingston': 'Castlemaine Surrounds',\n",
    "    'McLoughlins Beach': 'Yarram',\n",
    "    'McIntyre': 'Loddon',\n",
    "    'Murray-sunset': 'Mildura Surrounds',\n",
    "    'Mansfield': 'Mansfield (Vic.)'\n",
    "    # Add more manual matches here as needed\n",
    "}\n",
    "\n",
    "# Apply manual matches\n",
    "missing_geometry.loc[missing_geometry['sa2_name'].isna(), 'sa2_name'] = missing_geometry.loc[missing_geometry['sa2_name'].isna(), 'Suburb'].map(manual_matches)\n",
    "\n",
    "# Final count of matched suburbs\n",
    "final_matched_count = missing_geometry['sa2_name'].notna().sum()\n",
    "print(f\"Final count of matched suburbs: {final_matched_count}\")\n",
    "\n",
    "# Display the first few rows of missing_geometry after all matching\n",
    "#print(missing_geometry[['Year', 'Police Region', 'Local Government Area', 'Postcode', 'Suburb', 'sa2_name', 'geometry']].head())\n",
    "\n",
    "# Check for any remaining unmatched suburbs\n",
    "unmatched_suburbs = missing_geometry[missing_geometry['sa2_name'].isna()]['Suburb'].unique()\n",
    "print(f\"\\nNumber of remaining unmatched suburbs: {len(unmatched_suburbs)}\")\n",
    "if len(unmatched_suburbs) > 0:\n",
    "    print(\"Remaining unmatched suburbs:\", unmatched_suburbs)\n",
    "else:\n",
    "    print(\"All suburbs have been matched!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:52.226428Z",
     "start_time": "2024-09-25T07:10:52.219656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Year Year ending       Police Region Local Government Area Postcode  \\\n45  2024       March  1 North West Metro               Banyule     3079   \n\n          Suburb Location Division  Property Item  Number of Items  \\\n45  Ivanhoe East     1 Residential  Cash/Document               10   \n\n    Value of Items ($)                  sa2_name geometry  \n45               187.0  Ivanhoe East - Eaglemont     None  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Year ending</th>\n      <th>Police Region</th>\n      <th>Local Government Area</th>\n      <th>Postcode</th>\n      <th>Suburb</th>\n      <th>Location Division</th>\n      <th>Property Item</th>\n      <th>Number of Items</th>\n      <th>Value of Items ($)</th>\n      <th>sa2_name</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>45</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3079</td>\n      <td>Ivanhoe East</td>\n      <td>1 Residential</td>\n      <td>Cash/Document</td>\n      <td>10</td>\n      <td>187.0</td>\n      <td>Ivanhoe East - Eaglemont</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_geometry.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:52.246113Z",
     "start_time": "2024-09-25T07:10:52.227786Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      Year Year ending       Police Region Local Government Area Postcode  \\\n4994  2024       March  1 North West Metro             Melbourne     3031   \n\n          Suburb Location Division    Property Item  Number of Items  \\\n4994  Kensington     1 Residential  Car Accessories               13   \n\n      Value of Items ($)           sa2_name geometry  \n4994              2243.0  Kensington (Vic.)     None  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Year ending</th>\n      <th>Police Region</th>\n      <th>Local Government Area</th>\n      <th>Postcode</th>\n      <th>Suburb</th>\n      <th>Location Division</th>\n      <th>Property Item</th>\n      <th>Number of Items</th>\n      <th>Value of Items ($)</th>\n      <th>sa2_name</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4994</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Melbourne</td>\n      <td>3031</td>\n      <td>Kensington</td>\n      <td>1 Residential</td>\n      <td>Car Accessories</td>\n      <td>13</td>\n      <td>2243.0</td>\n      <td>Kensington (Vic.)</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Searching for an exact match of 'Ivanhoe East - Eaglemont' in the 'sa2_name_2021' column\n",
    "exact_sa2_name = missing_geometry[missing_geometry['sa2_name'] == 'Kensington (Vic.)']\n",
    "exact_sa2_name.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:52.249837Z",
     "start_time": "2024-09-25T07:10:52.246911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'# Step 1: Merge the dataframes\\nmissing_merged_df = missing_geometry.merge(sf[[\\'sa2_name\\', \\'geometry\\']], on=\\'sa2_name\\', how=\\'left\\', suffixes=(\\'\\', \\'_sf\\'))\\n\\n# Step 2: Update the geometry column\\nmissing_geometry[\\'geometry\\'] = missing_merged_df[\\'geometry_sf\\']\\n\\n# Step 3: Verify the update\\nprint(\"Number of null geometries:\")\\nprint(missing_geometry[\\'geometry\\'].isnull().sum())\\n\\nprint(\"\\nSample of updated geometries:\")\\nprint(missing_geometry[\\'geometry\\'].head())\\n\\n# Step 4: Check the columns in the final dataframe\\nprint(\"\\nColumns in the updated missing_geometry dataframe:\")\\nprint(missing_geometry.columns)\\n\\n# Optional: If you want to remove the original geometry column (if it existed)\\nif \\'geometry_x\\' in missing_geometry.columns:\\n    missing_geometry = missing_geometry.drop(columns=[\\'geometry_x\\'])\\n\\nprint(\"\\nFinal columns in missing_geometry:\")\\nprint(missing_geometry.columns)'"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Step 1: Merge the dataframes\n",
    "missing_merged_df = missing_geometry.merge(sf[['sa2_name', 'geometry']], on='sa2_name', how='left', suffixes=('', '_sf'))\n",
    "\n",
    "# Step 2: Update the geometry column\n",
    "missing_geometry['geometry'] = missing_merged_df['geometry_sf']\n",
    "\n",
    "# Step 3: Verify the update\n",
    "print(\"Number of null geometries:\")\n",
    "print(missing_geometry['geometry'].isnull().sum())\n",
    "\n",
    "print(\"\\nSample of updated geometries:\")\n",
    "print(missing_geometry['geometry'].head())\n",
    "\n",
    "# Step 4: Check the columns in the final dataframe\n",
    "print(\"\\nColumns in the updated missing_geometry dataframe:\")\n",
    "print(missing_geometry.columns)\n",
    "\n",
    "# Optional: If you want to remove the original geometry column (if it existed)\n",
    "if 'geometry_x' in missing_geometry.columns:\n",
    "    missing_geometry = missing_geometry.drop(columns=['geometry_x'])\n",
    "\n",
    "print(\"\\nFinal columns in missing_geometry:\")\n",
    "print(missing_geometry.columns)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:52.442568Z",
     "start_time": "2024-09-25T07:10:52.250689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93212\n",
      "45    POLYGON ((145.03287 -37.74091, 145.0328 -37.74...\n",
      "46    POLYGON ((145.03287 -37.74091, 145.0328 -37.74...\n",
      "47    POLYGON ((145.03287 -37.74091, 145.0328 -37.74...\n",
      "48    POLYGON ((145.03287 -37.74091, 145.0328 -37.74...\n",
      "49    POLYGON ((145.03287 -37.74091, 145.0328 -37.74...\n",
      "Name: geometry, dtype: geometry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dakshagrawal/PycharmProjects/project-2-group-real-estate-industry-project-3/.venv/lib/python3.12/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Merge the dataframes\n",
    "missing_merged_df = missing_geometry.merge(sf[['sa2_name', 'geometry']], on='sa2_name', how='left', suffixes=('', '_sf'))\n",
    "\n",
    "# Step 2: Update the geometry column\n",
    "missing_geometry['geometry'] = missing_merged_df['geometry_sf']\n",
    "\n",
    "# Step 3: Verify the update\n",
    "print(missing_geometry['geometry'].isnull().sum())\n",
    "print(missing_geometry['geometry'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:52.448528Z",
     "start_time": "2024-09-25T07:10:52.444243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'missing_merged_df.head()'"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''missing_merged_df.head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:52.455352Z",
     "start_time": "2024-09-25T07:10:52.450957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'# Step 1: Merge the dataframes\\nmissing_merged_df = missing_geometry.merge(sf[[\\'sa2_name\\', \\'geometry\\']], on=\\'sa2_name\\', how=\\'left\\', suffixes=(\\'\\', \\'_sf\\'))\\n\\n# Step 2: Update the geometry column\\nmissing_geometry[\\'geometry\\'] = missing_merged_df[\\'geometry_sf\\']\\n\\n# Step 3: Filter the unmatched instances\\nunmatched_instances = missing_geometry[missing_geometry[\\'geometry\\'].isnull()]\\n\\n# Step 4: Get the distinct sa2_name values for unmatched instances\\ndistinct_unmatched_sa2_names = unmatched_instances[\\'sa2_name\\'].unique()\\n\\n# Show the distinct sa2_name values that were not matched with geometry\\nprint(\"Distinct sa2_name values that are not matched with geometry:\")\\nprint(distinct_unmatched_sa2_names)'"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Step 1: Merge the dataframes\n",
    "missing_merged_df = missing_geometry.merge(sf[['sa2_name', 'geometry']], on='sa2_name', how='left', suffixes=('', '_sf'))\n",
    "\n",
    "# Step 2: Update the geometry column\n",
    "missing_geometry['geometry'] = missing_merged_df['geometry_sf']\n",
    "\n",
    "# Step 3: Filter the unmatched instances\n",
    "unmatched_instances = missing_geometry[missing_geometry['geometry'].isnull()]\n",
    "\n",
    "# Step 4: Get the distinct sa2_name values for unmatched instances\n",
    "distinct_unmatched_sa2_names = unmatched_instances['sa2_name'].unique()\n",
    "\n",
    "# Show the distinct sa2_name values that were not matched with geometry\n",
    "print(\"Distinct sa2_name values that are not matched with geometry:\")\n",
    "print(distinct_unmatched_sa2_names)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:52.858157Z",
     "start_time": "2024-09-25T07:10:52.457116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unmatched sa2_names: 0\n",
      "\n",
      "Names with leading/trailing whitespace in missing_geometry: 0\n",
      "Names with leading/trailing whitespace in sf: 0\n",
      "\n",
      "Data type of sa2_name in missing_geometry: object\n",
      "Data type of sa2_name in sf: object\n",
      "\n",
      "Merge results:\n",
      "_merge\n",
      "both          297977\n",
      "left_only          0\n",
      "right_only         0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of unmatched rows after merge: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create sets of sa2_names from both dataframes\n",
    "missing_sa2names = set(missing_geometry['sa2_name'])\n",
    "sf_sa2names = set(sf['sa2_name'])\n",
    "\n",
    "# Step 2: Find sa2_names that are in missing_geometry but not in sf\n",
    "unmatched_names = missing_sa2names - sf_sa2names\n",
    "\n",
    "print(f\"Number of unmatched sa2_names: {len(unmatched_names)}\")\n",
    "\n",
    "if len(unmatched_names) > 0:\n",
    "    print(\"\\nSample of unmatched sa2_names:\")\n",
    "    print(list(unmatched_names)[:10])\n",
    "\n",
    "    # Step 3: Detailed comparison for unmatched names\n",
    "    for name in list(unmatched_names)[:10]:\n",
    "        close_matches = [sf_name for sf_name in sf_sa2names if name.lower() == sf_name.lower()]\n",
    "        if close_matches:\n",
    "            print(f\"\\nPossible match for '{name}':\")\n",
    "            print(close_matches)\n",
    "\n",
    "# Step 4: Check for leading/trailing whitespace\n",
    "whitespace_issues_missing = missing_geometry[missing_geometry['sa2_name'].str.strip() != missing_geometry['sa2_name']]\n",
    "whitespace_issues_sf = sf[sf['sa2_name'].str.strip() != sf['sa2_name']]\n",
    "\n",
    "print(f\"\\nNames with leading/trailing whitespace in missing_geometry: {len(whitespace_issues_missing)}\")\n",
    "print(f\"Names with leading/trailing whitespace in sf: {len(whitespace_issues_sf)}\")\n",
    "\n",
    "# Step 5: Check for slight differences in names\n",
    "def find_close_matches(name, name_list, max_distance=3):\n",
    "    return [n for n in name_list if abs(len(n) - len(name)) <= max_distance and sum(c1 != c2 for c1, c2 in zip(name, n)) <= max_distance]\n",
    "\n",
    "sample_unmatched = list(unmatched_names)[:10]\n",
    "for name in sample_unmatched:\n",
    "    close_matches = find_close_matches(name, sf_sa2names)\n",
    "    if close_matches:\n",
    "        print(f\"\\nPossible close matches for '{name}':\")\n",
    "        print(close_matches)\n",
    "\n",
    "# Step 6: Check data types\n",
    "print(\"\\nData type of sa2_name in missing_geometry:\", missing_geometry['sa2_name'].dtype)\n",
    "print(\"Data type of sa2_name in sf:\", sf['sa2_name'].dtype)\n",
    "\n",
    "# Step 7: Perform the merge and check results\n",
    "merged_df = missing_geometry.merge(sf[['sa2_name', 'geometry']], on='sa2_name', how='left', indicator=True)\n",
    "\n",
    "print(\"\\nMerge results:\")\n",
    "print(merged_df['_merge'].value_counts())\n",
    "\n",
    "unmatched_after_merge = merged_df[merged_df['_merge'] == 'left_only']\n",
    "print(f\"\\nNumber of unmatched rows after merge: {len(unmatched_after_merge)}\")\n",
    "\n",
    "if len(unmatched_after_merge) > 0:\n",
    "    print(\"\\nSample of unmatched sa2_names after merge:\")\n",
    "    print(unmatched_after_merge['sa2_name'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:53.055857Z",
     "start_time": "2024-09-25T07:10:52.858833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully matched DataFrame:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dakshagrawal/PycharmProjects/project-2-group-real-estate-industry-project-3/.venv/lib/python3.12/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "data": {
      "text/plain": "     Year Year ending       Police Region Local Government Area Postcode  \\\n45   2024       March  1 North West Metro               Banyule     3079   \n46   2024       March  1 North West Metro               Banyule     3079   \n47   2024       March  1 North West Metro               Banyule     3079   \n48   2024       March  1 North West Metro               Banyule     3079   \n49   2024       March  1 North West Metro               Banyule     3079   \n..    ...         ...                 ...                   ...      ...   \n185  2024       March  1 North West Metro               Banyule     3083   \n186  2024       March  1 North West Metro               Banyule     3083   \n187  2024       March  1 North West Metro               Banyule     3083   \n188  2024       March  1 North West Metro               Banyule     3083   \n189  2024       March  1 North West Metro               Banyule     3083   \n\n           Suburb Location Division          Property Item  Number of Items  \\\n45   Ivanhoe East     1 Residential          Cash/Document               10   \n46   Ivanhoe East     1 Residential               Clothing                2   \n47   Ivanhoe East     1 Residential              Jewellery                3   \n48   Ivanhoe East     1 Residential                  Other                8   \n49   Ivanhoe East     1 Residential            Power Tools                3   \n..            ...               ...                    ...              ...   \n185      Bundoora           3 Other                  Other                4   \n186      Bundoora           3 Other            Power Tools                1   \n187      Bundoora           3 Other                 Tv/Vcr                1   \n188      Bundoora     All Locations        Car Accessories               43   \n189      Bundoora     All Locations  Electrical Appliances               12   \n\n     Value of Items ($)                  sa2_name  \\\n45                187.0  Ivanhoe East - Eaglemont   \n46                450.0  Ivanhoe East - Eaglemont   \n47               5000.0  Ivanhoe East - Eaglemont   \n48               2500.0  Ivanhoe East - Eaglemont   \n49               1350.0  Ivanhoe East - Eaglemont   \n..                  ...                       ...   \n185              3054.0           Bundoora - West   \n186               300.0           Bundoora - West   \n187               658.0           Bundoora - West   \n188              1965.0           Bundoora - West   \n189              6680.0           Bundoora - West   \n\n                                              geometry  \n45   POLYGON ((145.03287 -37.74091, 145.0328 -37.74...  \n46   POLYGON ((145.03287 -37.74091, 145.0328 -37.74...  \n47   POLYGON ((145.03287 -37.74091, 145.0328 -37.74...  \n48   POLYGON ((145.03287 -37.74091, 145.0328 -37.74...  \n49   POLYGON ((145.03287 -37.74091, 145.0328 -37.74...  \n..                                                 ...  \n185  POLYGON ((145.06122 -37.726, 145.0614 -37.7249...  \n186  POLYGON ((145.06122 -37.726, 145.0614 -37.7249...  \n187  POLYGON ((145.06122 -37.726, 145.0614 -37.7249...  \n188  POLYGON ((145.06122 -37.726, 145.0614 -37.7249...  \n189  POLYGON ((145.06122 -37.726, 145.0614 -37.7249...  \n\n[100 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Year ending</th>\n      <th>Police Region</th>\n      <th>Local Government Area</th>\n      <th>Postcode</th>\n      <th>Suburb</th>\n      <th>Location Division</th>\n      <th>Property Item</th>\n      <th>Number of Items</th>\n      <th>Value of Items ($)</th>\n      <th>sa2_name</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>45</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3079</td>\n      <td>Ivanhoe East</td>\n      <td>1 Residential</td>\n      <td>Cash/Document</td>\n      <td>10</td>\n      <td>187.0</td>\n      <td>Ivanhoe East - Eaglemont</td>\n      <td>POLYGON ((145.03287 -37.74091, 145.0328 -37.74...</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3079</td>\n      <td>Ivanhoe East</td>\n      <td>1 Residential</td>\n      <td>Clothing</td>\n      <td>2</td>\n      <td>450.0</td>\n      <td>Ivanhoe East - Eaglemont</td>\n      <td>POLYGON ((145.03287 -37.74091, 145.0328 -37.74...</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3079</td>\n      <td>Ivanhoe East</td>\n      <td>1 Residential</td>\n      <td>Jewellery</td>\n      <td>3</td>\n      <td>5000.0</td>\n      <td>Ivanhoe East - Eaglemont</td>\n      <td>POLYGON ((145.03287 -37.74091, 145.0328 -37.74...</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3079</td>\n      <td>Ivanhoe East</td>\n      <td>1 Residential</td>\n      <td>Other</td>\n      <td>8</td>\n      <td>2500.0</td>\n      <td>Ivanhoe East - Eaglemont</td>\n      <td>POLYGON ((145.03287 -37.74091, 145.0328 -37.74...</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3079</td>\n      <td>Ivanhoe East</td>\n      <td>1 Residential</td>\n      <td>Power Tools</td>\n      <td>3</td>\n      <td>1350.0</td>\n      <td>Ivanhoe East - Eaglemont</td>\n      <td>POLYGON ((145.03287 -37.74091, 145.0328 -37.74...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>185</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3083</td>\n      <td>Bundoora</td>\n      <td>3 Other</td>\n      <td>Other</td>\n      <td>4</td>\n      <td>3054.0</td>\n      <td>Bundoora - West</td>\n      <td>POLYGON ((145.06122 -37.726, 145.0614 -37.7249...</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3083</td>\n      <td>Bundoora</td>\n      <td>3 Other</td>\n      <td>Power Tools</td>\n      <td>1</td>\n      <td>300.0</td>\n      <td>Bundoora - West</td>\n      <td>POLYGON ((145.06122 -37.726, 145.0614 -37.7249...</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3083</td>\n      <td>Bundoora</td>\n      <td>3 Other</td>\n      <td>Tv/Vcr</td>\n      <td>1</td>\n      <td>658.0</td>\n      <td>Bundoora - West</td>\n      <td>POLYGON ((145.06122 -37.726, 145.0614 -37.7249...</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3083</td>\n      <td>Bundoora</td>\n      <td>All Locations</td>\n      <td>Car Accessories</td>\n      <td>43</td>\n      <td>1965.0</td>\n      <td>Bundoora - West</td>\n      <td>POLYGON ((145.06122 -37.726, 145.0614 -37.7249...</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Banyule</td>\n      <td>3083</td>\n      <td>Bundoora</td>\n      <td>All Locations</td>\n      <td>Electrical Appliances</td>\n      <td>12</td>\n      <td>6680.0</td>\n      <td>Bundoora - West</td>\n      <td>POLYGON ((145.06122 -37.726, 145.0614 -37.7249...</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Merge the dataframes to include geometry (this was already done correctly)\n",
    "missing_merged_df = missing_geometry.merge(sf[['sa2_name', 'geometry']], on='sa2_name', how='left', suffixes=('', '_sf'))\n",
    "\n",
    "# Step 2: Update the geometry column\n",
    "missing_geometry['geometry'] = missing_merged_df['geometry_sf']\n",
    "\n",
    "# Step 3: Display the fully matched DataFrame (since there are no unmatched rows)\n",
    "print(\"Fully matched DataFrame:\")\n",
    "missing_geometry.head(100)  # Display the first few rows of the fully matched DataFrame\n",
    "\n",
    "# Optionally, save the fully matched DataFrame to a CSV for further inspection\n",
    "# missing_geometry.to_csv(\"fully_matched_df.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:53.059698Z",
     "start_time": "2024-09-25T07:10:53.056578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with null geometry: 93212\n"
     ]
    }
   ],
   "source": [
    "# Check if any rows have null geometry after the merge\n",
    "null_geometry_count = missing_geometry['geometry'].isnull().sum()\n",
    "print(f\"Number of rows with null geometry: {null_geometry_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:53.080776Z",
     "start_time": "2024-09-25T07:10:53.060357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        Year Year ending       Police Region Local Government Area Postcode  \\\n297977  2017       March  1 North West Metro                  Hume     3059   \n297978  2017       March  1 North West Metro                  Hume     3059   \n297979  2017       March  1 North West Metro                  Hume     3059   \n297980  2017       March  1 North West Metro                  Hume     3059   \n297981  2017       March  1 North West Metro                  Hume     3059   \n\n           Suburb Location Division          Property Item  Number of Items  \\\n297977  Greenvale       2 Community               Clothing                6   \n297978  Greenvale       2 Community  Electrical Appliances               14   \n297979  Greenvale       2 Community           Garden Items                1   \n297980  Greenvale       2 Community                  Other                9   \n297981  Greenvale       2 Community      Personal Property               18   \n\n        Value of Items ($)           sa2_name geometry  \n297977               402.0  Greenvale - Bulla     None  \n297978              1705.0  Greenvale - Bulla     None  \n297979              5000.0  Greenvale - Bulla     None  \n297980              6960.0  Greenvale - Bulla     None  \n297981              1848.0  Greenvale - Bulla     None  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Year ending</th>\n      <th>Police Region</th>\n      <th>Local Government Area</th>\n      <th>Postcode</th>\n      <th>Suburb</th>\n      <th>Location Division</th>\n      <th>Property Item</th>\n      <th>Number of Items</th>\n      <th>Value of Items ($)</th>\n      <th>sa2_name</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>297977</th>\n      <td>2017</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Hume</td>\n      <td>3059</td>\n      <td>Greenvale</td>\n      <td>2 Community</td>\n      <td>Clothing</td>\n      <td>6</td>\n      <td>402.0</td>\n      <td>Greenvale - Bulla</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>297978</th>\n      <td>2017</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Hume</td>\n      <td>3059</td>\n      <td>Greenvale</td>\n      <td>2 Community</td>\n      <td>Electrical Appliances</td>\n      <td>14</td>\n      <td>1705.0</td>\n      <td>Greenvale - Bulla</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>297979</th>\n      <td>2017</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Hume</td>\n      <td>3059</td>\n      <td>Greenvale</td>\n      <td>2 Community</td>\n      <td>Garden Items</td>\n      <td>1</td>\n      <td>5000.0</td>\n      <td>Greenvale - Bulla</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>297980</th>\n      <td>2017</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Hume</td>\n      <td>3059</td>\n      <td>Greenvale</td>\n      <td>2 Community</td>\n      <td>Other</td>\n      <td>9</td>\n      <td>6960.0</td>\n      <td>Greenvale - Bulla</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>297981</th>\n      <td>2017</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Hume</td>\n      <td>3059</td>\n      <td>Greenvale</td>\n      <td>2 Community</td>\n      <td>Personal Property</td>\n      <td>18</td>\n      <td>1848.0</td>\n      <td>Greenvale - Bulla</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first few rows where geometry is null\n",
    "null_geometry_rows = missing_geometry[missing_geometry['geometry'].isnull()]\n",
    "null_geometry_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:53.100648Z",
     "start_time": "2024-09-25T07:10:53.081536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      Year Year ending       Police Region Local Government Area Postcode  \\\n3407  2024       March  1 North West Metro                  Hume     3059   \n3408  2024       March  1 North West Metro                  Hume     3059   \n3409  2024       March  1 North West Metro                  Hume     3059   \n3410  2024       March  1 North West Metro                  Hume     3059   \n3411  2024       March  1 North West Metro                  Hume     3059   \n\n         Suburb Location Division          Property Item  Number of Items  \\\n3407  Greenvale     1 Residential        Car Accessories               20   \n3408  Greenvale     1 Residential          Cash/Document               18   \n3409  Greenvale     1 Residential      Cigarettes/Liquor                4   \n3410  Greenvale     1 Residential               Clothing               13   \n3411  Greenvale     1 Residential  Electrical Appliances               40   \n\n      Value of Items ($)           sa2_name  \\\n3407              1070.0  Greenvale - Bulla   \n3408            204414.0  Greenvale - Bulla   \n3409               598.0  Greenvale - Bulla   \n3410             11576.0  Greenvale - Bulla   \n3411             60767.0  Greenvale - Bulla   \n\n                                               geometry  \n3407  POLYGON ((144.57114 -37.67301, 144.57256 -37.6...  \n3408  POLYGON ((144.5927 -37.85777, 144.59031 -37.85...  \n3409  POLYGON ((144.5927 -37.85777, 144.59031 -37.85...  \n3410  POLYGON ((144.5927 -37.85777, 144.59031 -37.85...  \n3411  POLYGON ((144.5927 -37.85777, 144.59031 -37.85...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Year ending</th>\n      <th>Police Region</th>\n      <th>Local Government Area</th>\n      <th>Postcode</th>\n      <th>Suburb</th>\n      <th>Location Division</th>\n      <th>Property Item</th>\n      <th>Number of Items</th>\n      <th>Value of Items ($)</th>\n      <th>sa2_name</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3407</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Hume</td>\n      <td>3059</td>\n      <td>Greenvale</td>\n      <td>1 Residential</td>\n      <td>Car Accessories</td>\n      <td>20</td>\n      <td>1070.0</td>\n      <td>Greenvale - Bulla</td>\n      <td>POLYGON ((144.57114 -37.67301, 144.57256 -37.6...</td>\n    </tr>\n    <tr>\n      <th>3408</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Hume</td>\n      <td>3059</td>\n      <td>Greenvale</td>\n      <td>1 Residential</td>\n      <td>Cash/Document</td>\n      <td>18</td>\n      <td>204414.0</td>\n      <td>Greenvale - Bulla</td>\n      <td>POLYGON ((144.5927 -37.85777, 144.59031 -37.85...</td>\n    </tr>\n    <tr>\n      <th>3409</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Hume</td>\n      <td>3059</td>\n      <td>Greenvale</td>\n      <td>1 Residential</td>\n      <td>Cigarettes/Liquor</td>\n      <td>4</td>\n      <td>598.0</td>\n      <td>Greenvale - Bulla</td>\n      <td>POLYGON ((144.5927 -37.85777, 144.59031 -37.85...</td>\n    </tr>\n    <tr>\n      <th>3410</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Hume</td>\n      <td>3059</td>\n      <td>Greenvale</td>\n      <td>1 Residential</td>\n      <td>Clothing</td>\n      <td>13</td>\n      <td>11576.0</td>\n      <td>Greenvale - Bulla</td>\n      <td>POLYGON ((144.5927 -37.85777, 144.59031 -37.85...</td>\n    </tr>\n    <tr>\n      <th>3411</th>\n      <td>2024</td>\n      <td>March</td>\n      <td>1 North West Metro</td>\n      <td>Hume</td>\n      <td>3059</td>\n      <td>Greenvale</td>\n      <td>1 Residential</td>\n      <td>Electrical Appliances</td>\n      <td>40</td>\n      <td>60767.0</td>\n      <td>Greenvale - Bulla</td>\n      <td>POLYGON ((144.5927 -37.85777, 144.59031 -37.85...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Searching for an exact match of 'Ivanhoe East - Eaglemont' in the 'sa2_name_2021' column\n",
    "exact_sa2_name = missing_geometry[missing_geometry['sa2_name'] == 'Greenvale - Bulla']\n",
    "exact_sa2_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:53.170696Z",
     "start_time": "2024-09-25T07:10:53.106871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sa2_names in missing_geometry but not in sf:\n",
      "[]\n",
      "\n",
      "Number of unmatched sa2_names in missing_geometry: 0\n",
      "\n",
      "sa2_names in sf but not in missing_geometry:\n",
      "['Narre Warren South - East', 'Clayton (North) - Notting Hill', 'Carnegie', 'Seymour', 'Traralgon - West', 'St Kilda East', 'Craigieburn - South', 'Reservoir - North East', 'Moorabbin Airport', 'Cranbourne North - West', 'Tarneit (West) - Mount Cottrell', 'Chelsea Heights', 'Lynbrook - Lyndhurst', 'Maiden Gully', 'Mooroopna', 'Thornbury', 'Bentleigh - McKinnon', 'Mount Martha', 'Leopold', 'Belmont', 'Vermont', 'Bundoora - East', 'Point Cook - South', 'Flemington', 'Geelong', 'Seddon - Kingsville', 'Oak Park', 'Hughesdale', 'Parkville', 'Langwarrin', 'Burwood East', 'Boronia', 'Aspendale Gardens - Waterways', 'East Melbourne', 'French Island', 'Benalla', 'Ferntree Gully - North', 'Coburg - East', 'Melbourne CBD - East', 'Ringwood', 'St Kilda - Central', 'Brunswick East', 'Bendigo Surrounds - South', 'Monbulk - Silvan', 'Alfredton', 'Springvale', 'Mernda - North', 'Doreen - North', 'Fitzroy North', 'Ardeer - Albion', 'Wantirna', 'Toorak', 'Melbourne CBD - North', 'Hoppers Crossing - South', 'The Basin', 'Pakenham - North East', 'Point Cook - East', 'Elwood', 'Essendon Airport', 'Cobblebank - Strathtulloh', 'Doreen - South', 'Altona Meadows', 'Bendigo', 'Brunswick - North', 'Melton West', 'Epping (Vic.) - West', 'Glen Waverley - East', 'St Albans - North', 'Ashburton (Vic.)', 'Narre Warren - South West', 'Abbotsford', 'Noble Park North', 'Wantirna South', 'Melbourne CBD - West', 'West Melbourne - Industrial', 'California Gully - Eaglehawk', 'Airport West', 'Cranbourne East - North', 'Merbein', 'Hoppers Crossing - North', 'East Bendigo - Kennington', 'Keilor Downs', 'Kew - South', 'Sunshine West', 'Buninyong', 'Doncaster East - North', 'Brunswick West', 'Clarinda - Oakleigh South', 'Horsham Surrounds', 'Coburg - West', 'Rowville - Central', 'Montrose', 'Avondale Heights', 'Truganina - North', 'Brighton (Vic.)', 'Lilydale - Coldstream', 'Alphington - Fairfield', 'Carrum Downs', 'Glenroy - West', 'Reservoir - South East', 'Hawthorn - North', 'Euroa', 'Broadmeadows', 'Eltham', 'Braybrook', 'Mount Evelyn', 'Fitzroy', 'Cranbourne', 'Lalor - East', 'Greensborough', 'Highett (West) - Cheltenham', 'Wangaratta', 'Wollert', 'Thomastown', 'Fawkner', 'Hawthorn East', 'Mildura - North', 'Melbourne Airport', 'Ararat', 'Heathcote', 'Blackburn', 'Glen Waverley - West', 'Clyde North - North', 'Cairnlea', 'Frankston South', 'Ivanhoe', 'Bayswater North', 'Burnside', 'Frankston North', 'Southbank - East', 'Templestowe Lower', 'Dingley Village', 'Mentone', 'Pascoe Vale South', 'Kurunjang - Toolern Vale', 'Forest Hill', 'Mount Eliza', 'Hampton Park - East', 'Cranbourne South', 'Brighton East', 'Geelong West - Hamlyn Heights', 'South Yarra - West', 'Heidelberg - Rosanna', 'Gowanbrae', 'Sunshine', 'Dandenong - North', 'Kings Park (Vic.)', 'Collingwood', 'West Wodonga', 'Kinglake', 'Keysborough - North', 'Hurstbridge', 'Murrumbeena', 'Bannockburn', 'Bundoora - North', 'Flora Hill - Spring Gully', 'Creswick - Clunes', 'Preston - West', 'Sunshine North', 'Strathfieldsaye', 'Tarneit - North', 'Preston - East', 'Bulleen', 'Croydon - East', 'Moe - Newborough', 'Southbank (West) - South Wharf', 'Carlton', 'South Morang - North', 'Beaumaris', 'Hadfield', 'Werribee - South', 'Mount Waverley - North', 'Springvale South', 'Frankston', 'Craigieburn - North West', 'Cranbourne North - East', 'Royal Botanic Gardens Victoria', 'Noble Park - East', 'Bacchus Marsh Surrounds', 'Rockbank - Mount Cottrell', 'Riddells Creek', 'Nunawading', 'Camperdown', 'Mornington - East', 'Flemington Racecourse', 'Ballarat East - Warrenheip', 'Balwyn North', 'Clifton Springs', 'Camberwell', 'Yarraville', 'Richmond (South) - Cremorne', 'Tarneit - Central', 'Hallam', 'Canadian - Mount Clear', 'Swan Hill', 'Traralgon - East', 'Ringwood East', 'Castlemaine', 'Maryborough (Vic.)', 'Bairnsdale', 'Braeside', 'Seabrook', 'Glen Iris - East', 'Narre Warren North', 'South Yarra - North', 'Epping - East', 'Doncaster', 'Keilor', 'Kilmore - Broadford', 'Mill Park - North', 'Ballarat North - Invermay', 'Essendon (West) - Aberfeldie', 'Craigieburn - North', 'Belgrave - Selby', 'Burnside Heights', 'Bentleigh East - North', 'Clyde North - South', 'Yallourn North - Glengarry', 'Smythes Creek', 'Northcote - East', 'Craigieburn - Central', 'Hamilton (Vic.)', 'Kialla', 'Moonee Ponds', 'Reservoir - North West', 'Epping - South', 'Donvale - Park Orchards', 'Vermont South', 'Charlemont', 'Tarneit - South', 'Cobram', 'Ferntree Gully (South) - Upper Ferntree Gully', 'Irymple', 'Baranduda - Leneva', 'Echuca', 'Drouin', 'Berwick - North', 'Docklands', 'Cranbourne West', 'Avoca', 'Port Melbourne', 'Lysterfield', 'Dandenong North', 'Burwood (Vic.)', 'Footscray', 'Brookfield', 'Kew East', 'Craigieburn - West', 'Glenroy - East', 'Ballarat', 'Bayswater', 'Port Melbourne Industrial', 'Point Cook - North East', 'Delahey', 'Taylors Hill', 'Templestowe', 'Chirnside Park', 'Werribee - East', 'Mulgrave', 'Melton South - Weir Views', 'Manor Lakes - Quandong', 'Ascot Vale', 'Horsham', 'Robinvale', 'Diggers Rest', 'Croydon - West', 'Shepparton - North', 'Essendon - East', 'Sydenham', 'Chelsea - Bonbeach', 'Colac', 'Altona North', 'Armadale']\n",
      "\n",
      "Number of unmatched sa2_names in sf: 273\n",
      "\n",
      "Number of None or empty sa2_names in missing_geometry: 0\n",
      "Number of None or empty sa2_names in sf: 0\n"
     ]
    }
   ],
   "source": [
    "# Get unique sa2_names from both dataframes\n",
    "missing_sa2names = set(missing_geometry['sa2_name'])\n",
    "sf_sa2names = set(sf['sa2_name'])\n",
    "\n",
    "# Find sa2_names in missing_geometry but not in sf\n",
    "only_in_missing = missing_sa2names - sf_sa2names\n",
    "\n",
    "# Find sa2_names in sf but not in missing_geometry\n",
    "only_in_sf = sf_sa2names - missing_sa2names\n",
    "\n",
    "print(\"sa2_names in missing_geometry but not in sf:\")\n",
    "print(list(only_in_missing))\n",
    "print(\"\\nNumber of unmatched sa2_names in missing_geometry:\", len(only_in_missing))\n",
    "\n",
    "print(\"\\nsa2_names in sf but not in missing_geometry:\")\n",
    "print(list(only_in_sf))\n",
    "print(\"\\nNumber of unmatched sa2_names in sf:\", len(only_in_sf))\n",
    "\n",
    "# Optional: Check for any sa2_names that are None or empty strings\n",
    "none_or_empty_in_missing = [name for name in missing_geometry['sa2_name'] if pd.isna(name) or name == '']\n",
    "none_or_empty_in_sf = [name for name in sf['sa2_name'] if pd.isna(name) or name == '']\n",
    "\n",
    "print(\"\\nNumber of None or empty sa2_names in missing_geometry:\", len(none_or_empty_in_missing))\n",
    "print(\"Number of None or empty sa2_names in sf:\", len(none_or_empty_in_sf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:53.447171Z",
     "start_time": "2024-09-25T07:10:53.172010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in missing_geometry: 297977\n",
      "Number of rows in sf: 522\n",
      "Number of rows in missing_merged_df: 297977\n",
      "\n",
      "Number of rows with null geometries in sf: 0\n",
      "\n",
      "Sample of rows with null geometries after merge:\n",
      "        Year Year ending       Police Region Local Government Area Postcode  \\\n",
      "204765  2017       March  1 North West Metro                  Hume     3059   \n",
      "204766  2017       March  1 North West Metro                  Hume     3059   \n",
      "204767  2017       March  1 North West Metro                  Hume     3059   \n",
      "204768  2017       March  1 North West Metro                  Hume     3059   \n",
      "204769  2017       March  1 North West Metro                  Hume     3059   \n",
      "\n",
      "           Suburb Location Division          Property Item  Number of Items  \\\n",
      "204765  Greenvale       2 Community               Clothing                6   \n",
      "204766  Greenvale       2 Community  Electrical Appliances               14   \n",
      "204767  Greenvale       2 Community           Garden Items                1   \n",
      "204768  Greenvale       2 Community                  Other                9   \n",
      "204769  Greenvale       2 Community      Personal Property               18   \n",
      "\n",
      "        Value of Items ($)           sa2_name geometry  \\\n",
      "204765               402.0  Greenvale - Bulla     None   \n",
      "204766              1705.0  Greenvale - Bulla     None   \n",
      "204767              5000.0  Greenvale - Bulla     None   \n",
      "204768              6960.0  Greenvale - Bulla     None   \n",
      "204769              1848.0  Greenvale - Bulla     None   \n",
      "\n",
      "                                              geometry_sf  \n",
      "204765  POLYGON ((144.7805 -37.61513, 144.77572 -37.61...  \n",
      "204766  POLYGON ((144.7805 -37.61513, 144.77572 -37.61...  \n",
      "204767  POLYGON ((144.7805 -37.61513, 144.77572 -37.61...  \n",
      "204768  POLYGON ((144.7805 -37.61513, 144.77572 -37.61...  \n",
      "204769  POLYGON ((144.7805 -37.61513, 144.77572 -37.61...  \n",
      "\n",
      "Columns in missing_merged_df:\n",
      "Index(['Year', 'Year ending', 'Police Region', 'Local Government Area',\n",
      "       'Postcode', 'Suburb', 'Location Division', 'Property Item',\n",
      "       'Number of Items', 'Value of Items ($)', 'sa2_name', 'geometry',\n",
      "       'geometry_sf'],\n",
      "      dtype='object')\n",
      "\n",
      "Number of rows with null geometries in missing_geometry: 0\n",
      "\n",
      "Number of rows with null geometries in geometry_sf column: 0\n",
      "\n",
      "Sample of geometry_sf column:\n",
      "0    POLYGON ((145.05176 -37.76678, 145.05188 -37.7...\n",
      "1    POLYGON ((145.05176 -37.76678, 145.05188 -37.7...\n",
      "2    POLYGON ((145.05176 -37.76678, 145.05188 -37.7...\n",
      "3    POLYGON ((145.05176 -37.76678, 145.05188 -37.7...\n",
      "4    POLYGON ((145.05176 -37.76678, 145.05188 -37.7...\n",
      "Name: geometry_sf, dtype: geometry\n",
      "\n",
      "Number of non-null geometries in original missing_geometry:\n",
      "204765\n",
      "\n",
      "Number of null geometries in new merge:\n",
      "0\n",
      "\n",
      "Sample of new merged geometries:\n",
      "0    POLYGON ((145.05176 -37.76678, 145.05188 -37.7...\n",
      "1    POLYGON ((145.05176 -37.76678, 145.05188 -37.7...\n",
      "2    POLYGON ((145.05176 -37.76678, 145.05188 -37.7...\n",
      "3    POLYGON ((145.05176 -37.76678, 145.05188 -37.7...\n",
      "4    POLYGON ((145.05176 -37.76678, 145.05188 -37.7...\n",
      "Name: geometry_new, dtype: geometry\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows in each dataframe\n",
    "print(f\"Number of rows in missing_geometry: {len(missing_geometry)}\")\n",
    "print(f\"Number of rows in sf: {len(sf)}\")\n",
    "print(f\"Number of rows in missing_merged_df: {len(missing_merged_df)}\")\n",
    "\n",
    "# Check if there are any rows where geometry is null in sf\n",
    "null_geometries_sf = sf['geometry'].isnull().sum()\n",
    "print(f\"\\nNumber of rows with null geometries in sf: {null_geometries_sf}\")\n",
    "\n",
    "# Check a sample of rows where geometry is null after the merge\n",
    "print(\"\\nSample of rows with null geometries after merge:\")\n",
    "print(missing_merged_df[missing_merged_df['geometry'].isnull()].head())\n",
    "\n",
    "# Check if the merge created duplicate columns\n",
    "print(\"\\nColumns in missing_merged_df:\")\n",
    "print(missing_merged_df.columns)\n",
    "\n",
    "# Check if there are any rows where geometry is null in sf\n",
    "null_geometries = sf['geometry'].isnull().sum()\n",
    "print(f\"\\nNumber of rows with null geometries in missing_geometry: {null_geometries}\")\n",
    "\n",
    "# If there's a 'geometry_sf' column, compare it with 'geometry'\n",
    "if 'geometry_sf' in missing_merged_df.columns:\n",
    "    null_geometries_sf_merged = missing_merged_df['geometry_sf'].isnull().sum()\n",
    "    print(f\"\\nNumber of rows with null geometries in geometry_sf column: {null_geometries_sf_merged}\")\n",
    "    \n",
    "    # Check if geometries are in geometry_sf instead of geometry\n",
    "    print(\"\\nSample of geometry_sf column:\")\n",
    "    print(missing_merged_df['geometry_sf'].head())\n",
    "\n",
    "# Check if the geometries are being overwritten during the merge\n",
    "if 'geometry' in missing_geometry.columns:\n",
    "    print(\"\\nNumber of non-null geometries in original missing_geometry:\")\n",
    "    print(missing_geometry['geometry'].notnull().sum())\n",
    "\n",
    "# Perform a new merge with a different suffix for the geometry column\n",
    "new_merged_df = missing_geometry.merge(sf[['sa2_name', 'geometry']], on='sa2_name', how='left', suffixes=('', '_new'))\n",
    "\n",
    "print(\"\\nNumber of null geometries in new merge:\")\n",
    "print(new_merged_df['geometry_new'].isnull().sum())\n",
    "\n",
    "print(\"\\nSample of new merged geometries:\")\n",
    "print(new_merged_df['geometry_new'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:54.195053Z",
     "start_time": "2024-09-25T07:10:53.452839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing geometry columns: Index(['Year', 'Year ending', 'Police Region', 'Local Government Area',\n",
      "       'Postcode', 'Suburb', 'Location Division', 'Property Item',\n",
      "       'Number of Items', 'Value of Items ($)', 'sa2_name', 'geometry'],\n",
      "      dtype='object')\n",
      "Sample rows from missing_geometry before merge:     Year Year ending       Police Region Local Government Area Postcode  \\\n",
      "45  2024       March  1 North West Metro               Banyule     3079   \n",
      "46  2024       March  1 North West Metro               Banyule     3079   \n",
      "47  2024       March  1 North West Metro               Banyule     3079   \n",
      "48  2024       March  1 North West Metro               Banyule     3079   \n",
      "49  2024       March  1 North West Metro               Banyule     3079   \n",
      "\n",
      "          Suburb Location Division  Property Item  Number of Items  \\\n",
      "45  Ivanhoe East     1 Residential  Cash/Document               10   \n",
      "46  Ivanhoe East     1 Residential       Clothing                2   \n",
      "47  Ivanhoe East     1 Residential      Jewellery                3   \n",
      "48  Ivanhoe East     1 Residential          Other                8   \n",
      "49  Ivanhoe East     1 Residential    Power Tools                3   \n",
      "\n",
      "    Value of Items ($)                  sa2_name  \\\n",
      "45               187.0  Ivanhoe East - Eaglemont   \n",
      "46               450.0  Ivanhoe East - Eaglemont   \n",
      "47              5000.0  Ivanhoe East - Eaglemont   \n",
      "48              2500.0  Ivanhoe East - Eaglemont   \n",
      "49              1350.0  Ivanhoe East - Eaglemont   \n",
      "\n",
      "                                             geometry  \n",
      "45  POLYGON ((145.03287 -37.74091, 145.0328 -37.74...  \n",
      "46  POLYGON ((145.03287 -37.74091, 145.0328 -37.74...  \n",
      "47  POLYGON ((145.03287 -37.74091, 145.0328 -37.74...  \n",
      "48  POLYGON ((145.03287 -37.74091, 145.0328 -37.74...  \n",
      "49  POLYGON ((145.03287 -37.74091, 145.0328 -37.74...  \n",
      "Columns after merge: Index(['Year', 'Year ending', 'Police Region', 'Local Government Area',\n",
      "       'Postcode', 'Suburb', 'Location Division', 'Property Item',\n",
      "       'Number of Items', 'Value of Items ($)', 'sa2_name', 'geometry_x',\n",
      "       'geometry_y'],\n",
      "      dtype='object')\n",
      "Sample rows after merge:    Year Year ending       Police Region Local Government Area Postcode  \\\n",
      "0  2024       March  1 North West Metro               Banyule     3079   \n",
      "1  2024       March  1 North West Metro               Banyule     3079   \n",
      "2  2024       March  1 North West Metro               Banyule     3079   \n",
      "3  2024       March  1 North West Metro               Banyule     3079   \n",
      "4  2024       March  1 North West Metro               Banyule     3079   \n",
      "\n",
      "         Suburb Location Division  Property Item  Number of Items  \\\n",
      "0  Ivanhoe East     1 Residential  Cash/Document               10   \n",
      "1  Ivanhoe East     1 Residential       Clothing                2   \n",
      "2  Ivanhoe East     1 Residential      Jewellery                3   \n",
      "3  Ivanhoe East     1 Residential          Other                8   \n",
      "4  Ivanhoe East     1 Residential    Power Tools                3   \n",
      "\n",
      "   Value of Items ($)                  sa2_name  \\\n",
      "0               187.0  Ivanhoe East - Eaglemont   \n",
      "1               450.0  Ivanhoe East - Eaglemont   \n",
      "2              5000.0  Ivanhoe East - Eaglemont   \n",
      "3              2500.0  Ivanhoe East - Eaglemont   \n",
      "4              1350.0  Ivanhoe East - Eaglemont   \n",
      "\n",
      "                                          geometry_x  \\\n",
      "0  POLYGON ((145.03287 -37.74091, 145.0328 -37.74...   \n",
      "1  POLYGON ((145.03287 -37.74091, 145.0328 -37.74...   \n",
      "2  POLYGON ((145.03287 -37.74091, 145.0328 -37.74...   \n",
      "3  POLYGON ((145.03287 -37.74091, 145.0328 -37.74...   \n",
      "4  POLYGON ((145.03287 -37.74091, 145.0328 -37.74...   \n",
      "\n",
      "                                          geometry_y  \n",
      "0  POLYGON ((145.05176 -37.76678, 145.05188 -37.7...  \n",
      "1  POLYGON ((145.05176 -37.76678, 145.05188 -37.7...  \n",
      "2  POLYGON ((145.05176 -37.76678, 145.05188 -37.7...  \n",
      "3  POLYGON ((145.05176 -37.76678, 145.05188 -37.7...  \n",
      "4  POLYGON ((145.05176 -37.76678, 145.05188 -37.7...  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'geometry'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/project-2-group-real-estate-industry-project-3/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'geometry'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[37], line 19\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSample rows after merge:\u001B[39m\u001B[38;5;124m\"\u001B[39m, final_missing_geometry_matched\u001B[38;5;241m.\u001B[39mhead())\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Step 4: Update geometry in missing_geometry DataFrame\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m missing_geometry[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgeometry\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mfinal_missing_geometry_matched\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgeometry\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Final count of rows with geometry after the match\u001B[39;00m\n\u001B[1;32m     22\u001B[0m final_geometry_count \u001B[38;5;241m=\u001B[39m missing_geometry[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgeometry\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mnotna()\u001B[38;5;241m.\u001B[39msum()\n",
      "File \u001B[0;32m~/PycharmProjects/project-2-group-real-estate-industry-project-3/.venv/lib/python3.12/site-packages/geopandas/geodataframe.py:1750\u001B[0m, in \u001B[0;36mGeoDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;124;03m    If the result is a column containing only 'geometry', return a\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;124;03m    GeoSeries. If it's a DataFrame with any columns of GeometryDtype,\u001B[39;00m\n\u001B[1;32m   1748\u001B[0m \u001B[38;5;124;03m    return a GeoDataFrame.\u001B[39;00m\n\u001B[1;32m   1749\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1750\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getitem__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1751\u001B[0m     \u001B[38;5;66;03m# Custom logic to avoid waiting for pandas GH51895\u001B[39;00m\n\u001B[1;32m   1752\u001B[0m     \u001B[38;5;66;03m# result is not geometry dtype for multi-indexes\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1754\u001B[0m         pd\u001B[38;5;241m.\u001B[39mapi\u001B[38;5;241m.\u001B[39mtypes\u001B[38;5;241m.\u001B[39mis_scalar(key)\n\u001B[1;32m   1755\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m key \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1758\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_geometry_type(result)\n\u001B[1;32m   1759\u001B[0m     ):\n",
      "File \u001B[0;32m~/PycharmProjects/project-2-group-real-estate-industry-project-3/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/PycharmProjects/project-2-group-real-estate-industry-project-3/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3810\u001B[0m     ):\n\u001B[1;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'geometry'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Ensure 'sa2_name' is populated in missing_geometry from previous steps\n",
    "print(\"Missing geometry columns:\", missing_geometry.columns)\n",
    "print(\"Sample rows from missing_geometry before merge:\", missing_geometry.head())\n",
    "\n",
    "# Step 2: Perform the merge operation, matching 'sa2_name' to get geometry from sf\n",
    "final_missing_geometry_matched = missing_geometry.merge(\n",
    "    sf[['sa2_name', 'geometry']], \n",
    "    on='sa2_name', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 3: Ensure 'geometry' is present after the merge\n",
    "print(\"Columns after merge:\", final_missing_geometry_matched.columns)\n",
    "print(\"Sample rows after merge:\", final_missing_geometry_matched.head())\n",
    "\n",
    "# Step 4: Update geometry in missing_geometry DataFrame\n",
    "missing_geometry['geometry'] = final_missing_geometry_matched['geometry']\n",
    "\n",
    "# Final count of rows with geometry after the match\n",
    "final_geometry_count = missing_geometry['geometry'].notna().sum()\n",
    "print(f\"\\nFinal count of rows with geometry: {final_geometry_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:54.197265Z",
     "start_time": "2024-09-25T07:10:54.197201Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# Assuming property, sf, and suburb_df are already loaded\n",
    "\n",
    "# Convert the PySpark DataFrame to Pandas\n",
    "property_pandas = property.toPandas()\n",
    "\n",
    "# Step 1: Perform the initial merge on 'suburb' from property and 'sa2_name' from sf to get geometry\n",
    "merged_gdf = property_pandas.merge(sf[['sa2_name', 'geometry']], \n",
    "                                   left_on='Suburb', right_on='sa2_name', \n",
    "                                   how='left')\n",
    "\n",
    "# Convert the merged DataFrame to a GeoDataFrame\n",
    "merged_gdf = gpd.GeoDataFrame(merged_gdf, geometry='geometry')\n",
    "\n",
    "# Step 2: Check which rows are missing geometry\n",
    "missing_geometry = merged_gdf[merged_gdf['geometry'].isnull()]\n",
    "\n",
    "# Step 3: Clean the locality column in suburb_df and map missing geometry rows\n",
    "suburb_df['locality'] = suburb_df['locality'].str.strip().str.title()\n",
    "\n",
    "# Step 4: Create a dictionary to map 'locality' to 'SA2_NAME_2021'\n",
    "locality_to_sa2_mapping = suburb_df.set_index('locality')['SA2_NAME_2021'].to_dict()\n",
    "\n",
    "# Step 5: Map missing 'Suburb' values to their corresponding 'SA2_NAME_2021'\n",
    "merged_gdf.loc[merged_gdf['sa2_name'].isna(), 'sa2_name'] = merged_gdf.loc[merged_gdf['sa2_name'].isna(), 'Suburb'].map(locality_to_sa2_mapping)\n",
    "\n",
    "# Step 6: For the rows where 'sa2_name' was updated, match with the sf data to get geometry\n",
    "rows_to_match = merged_gdf[merged_gdf['geometry'].isnull() & merged_gdf['sa2_name'].notna()]\n",
    "\n",
    "# Step 7: Merge these rows with the sf to get the geometry based on the newly updated 'sa2_name'\n",
    "final_merged_gdf = rows_to_match.merge(sf[['sa2_name', 'geometry']], \n",
    "                                       on='sa2_name', \n",
    "                                       how='left')\n",
    "\n",
    "# Step 8: Update the geometry for rows that were matched\n",
    "merged_gdf.update(final_merged_gdf)\n",
    "\n",
    "# Step 9: Check for any remaining unmatched suburbs after the final matching\n",
    "remaining_unmatched = merged_gdf[merged_gdf['geometry'].isnull()]['Suburb'].unique()\n",
    "\n",
    "print(f\"Remaining unmatched suburbs: {len(remaining_unmatched)}\")\n",
    "if len(remaining_unmatched) > 0:\n",
    "    print(\"Unmatched suburbs after final matching:\", remaining_unmatched)\n",
    "else:\n",
    "    print(\"All suburbs have been successfully matched with geometry.\")\n",
    "\n",
    "# Ensure the result is still a GeoDataFrame\n",
    "merged_gdf = gpd.GeoDataFrame(merged_gdf, geometry='geometry')\n",
    "\n",
    "# Display the final GeoDataFrame\n",
    "print(\"\\nFinal GeoDataFrame with geometry:\")\n",
    "print(merged_gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Replace the 'Suburb' values in missing_geometry with corresponding 'SA2_NAME_2021'\n",
    "missing_geometry['sa2_name'] = missing_geometry['Suburb'].map(locality_to_sa2_mapping)\n",
    "\n",
    "# Step 5: Check if any unmatched suburbs remain after the mapping\n",
    "unmatched_suburbs = missing_geometry[missing_geometry['sa2_name'].isnull()]\n",
    "\n",
    "# Check if there are any unmatched suburbs\n",
    "if unmatched_suburbs.empty:\n",
    "    print(\"All missing geometry suburbs have been successfully matched.\")\n",
    "else:\n",
    "    print(f\"There are {len(unmatched_suburbs)} suburbs that could not be matched with SA2_NAME_2021.\")\n",
    "    print(\"Unmatched suburbs:\")\n",
    "    print(unmatched_suburbs['Suburb'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Filter Victorian suburbs and clean 'locality' in suburb_df\n",
    "suburb_df_vic = suburb_df[suburb_df['state'] == 'VIC'].copy()\n",
    "suburb_df_vic['locality'] = suburb_df_vic['locality'].str.strip().str.upper()\n",
    "\n",
    "# Step 6: Create a mapping from 'locality' to 'SA2_NAME_2021'\n",
    "locality_to_sa2_mapping = suburb_df_vic.set_index('locality')['SA2_NAME_2021'].to_dict()\n",
    "\n",
    "# Step 7: Replace unmatched suburbs with SA2_NAME_2021 using the mapping\n",
    "property_pandas['Suburb'] = property_pandas['Suburb'].str.upper()\n",
    "property_pandas['Suburb'] = property_pandas['Suburb'].replace(locality_to_sa2_mapping)\n",
    "\n",
    "# Step 8: Perform the second merge to get geometry for the previously unmatched suburbs\n",
    "second_merge_df = property_pandas.merge(\n",
    "    sf[['sa2_name', 'geometry']],\n",
    "    left_on='Suburb',\n",
    "    right_on='sa2_name',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 9: Combine the results of the first and second merges, focusing on specific columns\n",
    "combined_df = pd.concat([merged_df[merged_df['geometry'].notnull()], second_merge_df], ignore_index=True)\n",
    "final_df = combined_df[property_pandas.columns.tolist() + ['sa2_name', 'geometry']]\n",
    "\n",
    "# Step 10: Identify remaining unmatched suburbs\n",
    "remaining_unmatched_df = final_df[final_df['geometry'].isnull()]\n",
    "remaining_unmatched_suburbs = remaining_unmatched_df['Suburb'].unique()\n",
    "\n",
    "print(f\"Remaining unmatched suburbs: {len(remaining_unmatched_suburbs)}\")\n",
    "print(\"Sample of remaining unmatched suburbs:\", remaining_unmatched_suburbs[:5])\n",
    "\n",
    "# Step 11: Convert to a GeoDataFrame with relevant columns\n",
    "final_merged_gdf = gpd.GeoDataFrame(final_df, geometry='geometry', crs=sf.crs)\n",
    "\n",
    "# Display the final GeoDataFrame\n",
    "final_merged_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the suburb you want to search for (e.g., 'Ivanhoe')\n",
    "suburb_to_search = 'Ivanhoe East'\n",
    "\n",
    "# Filter the final_merged_gdf for the specific suburb\n",
    "filtered_gdf = final_merged_gdf[final_merged_gdf['Suburb'].str.contains(suburb_to_search, case=False, na=False)]\n",
    "\n",
    "# Display the results\n",
    "print(f\"Results for '{suburb_to_search}':\")\n",
    "filtered_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_gdf.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T07:10:54.204727Z",
     "start_time": "2024-09-25T07:10:54.204164Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for duplicates in sa2_name in the shapefile (sf)\n",
    "duplicate_sa2 = sf[sf.duplicated(subset='sa2_name', keep=False)]\n",
    "print(f\"Duplicate SA2 names in shapefile: {duplicate_sa2.shape[0]}\")\n",
    "\n",
    "# Display duplicate SA2 names, if any\n",
    "if duplicate_sa2.shape[0] > 0:\n",
    "    print(duplicate_sa2['sa2_name'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gdf.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Step 1: Convert PySpark DataFrame to Pandas for easier handling\n",
    "property_df = property.toPandas()\n",
    "\n",
    "# Step 2: Perform initial merge of property_df and sf based on 'Suburb' and 'sa2_name'\n",
    "initial_merged_df = property_df.merge(sf[['sa2_name', 'geometry']], \n",
    "                                      left_on='Suburb', right_on='sa2_name', \n",
    "                                      how='left')\n",
    "\n",
    "# Step 3: Identify distinct unmatched suburbs (those with missing geometry after the initial merge)\n",
    "unmatched_suburbs_before = initial_merged_df[initial_merged_df['geometry'].isnull()]['Suburb'].unique()\n",
    "print(f\"Distinct unmatched suburbs before lookup: {len(unmatched_suburbs_before)}\")\n",
    "print(\"Unmatched suburbs before lookup:\", unmatched_suburbs_before)\n",
    "\n",
    "# Step 4: Load the suburb_df Parquet file\n",
    "suburb_df = pd.read_parquet('../data/landing/suburb_match/suburb_match.parquet')\n",
    "\n",
    "# Step 5: Filter only Victorian suburbs from suburb_df\n",
    "suburb_df_vic = suburb_df[suburb_df['state'] == 'VIC'].copy()\n",
    "\n",
    "# Step 6: Clean the locality data (in suburb_df) to standardize\n",
    "suburb_df_vic['locality'] = suburb_df_vic['locality'].str.strip().str.title()\n",
    "\n",
    "# Step 7: Create a dictionary to map 'locality' to 'SA2_NAME_2021'\n",
    "locality_to_sa2_mapping = suburb_df_vic.set_index('locality')['SA2_NAME_2021'].to_dict()\n",
    "\n",
    "# Step 8: Replace unmatched suburbs in the property DataFrame using the mapping\n",
    "property_df['Suburb'] = property_df['Suburb'].replace(locality_to_sa2_mapping)\n",
    "\n",
    "# Step 9: Perform a second merge with the sf DataFrame to find geometry for the renamed suburbs\n",
    "final_merged_df = property_df.merge(sf[['sa2_name', 'geometry']], \n",
    "                                    left_on='Suburb', right_on='sa2_name', \n",
    "                                    how='left')\n",
    "\n",
    "# Step 10: Identify distinct remaining unmatched suburbs (those with missing geometry)\n",
    "unmatched_suburbs_after = final_merged_df[final_merged_df['geometry'].isnull()]['Suburb'].unique()\n",
    "\n",
    "# Step 11: Output results\n",
    "print(f\"Distinct unmatched suburbs after lookup: {len(unmatched_suburbs_after)}\")\n",
    "if len(unmatched_suburbs_after) > 0:\n",
    "    print(\"Remaining unmatched suburbs:\", unmatched_suburbs_after)\n",
    "else:\n",
    "    print(\"All suburbs have been successfully matched with geometry.\")\n",
    "\n",
    "# Step 12: The final merged DataFrame with geometry\n",
    "# final_merged_df.head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert PySpark DataFrame to Pandas for easier handling\n",
    "property_df = property.toPandas()\n",
    "\n",
    "# Step 2: Ensure suburb names in property_df are in uppercase for consistent matching\n",
    "property_df['Suburb'] = property_df['Suburb'].str.upper()\n",
    "\n",
    "# Step 3: Perform initial merge of property_df and sf based on 'Suburb' and 'sa2_name'\n",
    "initial_merged_df = property_df.merge(sf[['sa2_name', 'geometry']], \n",
    "                                      left_on='Suburb', right_on='sa2_name', \n",
    "                                      how='left')\n",
    "\n",
    "# Step 4: Identify distinct unmatched suburbs (those with missing geometry after the initial merge)\n",
    "unmatched_suburbs_before = initial_merged_df[initial_merged_df['geometry'].isnull()]['Suburb'].unique()\n",
    "print(f\"Distinct unmatched suburbs before lookup: {len(unmatched_suburbs_before)}\")\n",
    "print(\"Unmatched suburbs before lookup:\", unmatched_suburbs_before)\n",
    "\n",
    "# Step 5: Load the suburb_df Parquet file\n",
    "suburb_df = pd.read_parquet('../data/landing/suburb_match/suburb_match.parquet')\n",
    "\n",
    "# Step 6: Filter only Victorian suburbs from suburb_df and ensure locality names are uppercase\n",
    "suburb_df_vic = suburb_df[suburb_df['state'] == 'VIC'].copy()\n",
    "suburb_df_vic['locality'] = suburb_df_vic['locality'].str.upper()\n",
    "\n",
    "# Step 7: Create a dictionary to map 'locality' to 'SA2_NAME_2021'\n",
    "locality_to_sa2_mapping = suburb_df_vic.set_index('locality')['SA2_NAME_2021'].to_dict()\n",
    "\n",
    "# Step 8: Replace unmatched suburbs in the property DataFrame using the mapping\n",
    "property_df['Suburb'] = property_df['Suburb'].replace(locality_to_sa2_mapping)\n",
    "\n",
    "# Step 9: Perform a second merge with the sf DataFrame to find geometry for the renamed suburbs\n",
    "final_merged_df = property_df.merge(sf[['sa2_name', 'geometry']], \n",
    "                                    left_on='Suburb', right_on='sa2_name', \n",
    "                                    how='left')\n",
    "\n",
    "# Step 10: Identify distinct remaining unmatched suburbs (those with missing geometry)\n",
    "unmatched_suburbs_after = final_merged_df[final_merged_df['geometry'].isnull()]['Suburb'].unique()\n",
    "\n",
    "# Step 11: Output results\n",
    "print(f\"Distinct unmatched suburbs after lookup: {len(unmatched_suburbs_after)}\")\n",
    "if len(unmatched_suburbs_after) > 0:\n",
    "    print(\"Remaining unmatched suburbs:\", unmatched_suburbs_after)\n",
    "else:\n",
    "    print(\"All suburbs have been successfully matched with geometry.\")\n",
    "\n",
    "# Step 12: The final merged DataFrame with geometry\n",
    "final_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for a specific suburb, e.g., 'Arcadia'\n",
    "specific_suburb = \"Ivanhoe\"\n",
    "suburb_check = final_merged_df[final_merged_df['sa2_name'] == specific_suburb]\n",
    "\n",
    "# Show the result\n",
    "suburb_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Step 1: Convert PySpark DataFrame to Pandas for easier handling\n",
    "property_df = property.toPandas()\n",
    "\n",
    "# Step 2: Perform initial merge of property_df and sf based on 'Suburb' and 'sa2_name'\n",
    "initial_merged_df = property_df.merge(sf[['sa2_name', 'geometry']], \n",
    "                                      left_on='Suburb', right_on='sa2_name', \n",
    "                                      how='left')\n",
    "\n",
    "# Step 3: Identify unmatched suburbs (those with missing geometry after the initial merge)\n",
    "unmatched_suburbs_before = initial_merged_df[initial_merged_df['geometry'].isnull()]['Suburb'].unique()\n",
    "print(f\"Unmatched suburbs before lookup: {len(unmatched_suburbs_before)}\")\n",
    "\n",
    "# Step 4: Load the suburb_df Parquet file\n",
    "suburb_df = pd.read_parquet('../data/landing/suburb_match/suburb_match.parquet')\n",
    "\n",
    "# Step 5: Filter only Victorian suburbs from suburb_df\n",
    "suburb_df_vic = suburb_df[suburb_df['state'] == 'VIC'].copy()\n",
    "\n",
    "# Step 6: Clean the locality data (in suburb_df) to standardize\n",
    "suburb_df_vic['locality'] = suburb_df_vic['locality'].str.strip().str.title()\n",
    "\n",
    "# Step 7: Create a dictionary to map 'locality' to 'SA2_NAME_2021'\n",
    "locality_to_sa2_mapping = suburb_df_vic.set_index('locality')['SA2_NAME_2021'].to_dict()\n",
    "\n",
    "# Step 8: Replace unmatched suburbs in the property DataFrame using the mapping\n",
    "property_df['Suburb'] = property_df['Suburb'].replace(locality_to_sa2_mapping)\n",
    "\n",
    "# Step 9: Perform a second merge with the sf DataFrame to find geometry for the renamed suburbs\n",
    "final_merged_df = property_df.merge(sf[['sa2_name', 'geometry']], \n",
    "                                    left_on='Suburb', right_on='sa2_name', \n",
    "                                    how='left')\n",
    "\n",
    "# Step 10: Identify any remaining unmatched suburbs (those with missing geometry)\n",
    "unmatched_suburbs_after = final_merged_df[final_merged_df['geometry'].isnull()]['Suburb'].unique()\n",
    "\n",
    "# Step 11: Output results\n",
    "print(f\"Unmatched suburbs after lookup: {len(unmatched_suburbs_after)}\")\n",
    "if len(unmatched_suburbs_after) > 0:\n",
    "    print(\"Remaining unmatched suburbs:\", unmatched_suburbs_after)\n",
    "else:\n",
    "    print(\"All suburbs have been successfully matched with geometry.\")\n",
    "\n",
    "# Step 12: The final merged DataFrame with geometry\n",
    "final_merged_df.head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file containing Locality and SA2 NAME 2021\n",
    "suburb_to_sa2_df = pd.read_csv('../data/landing/suburb_match/suburb_match.csv')\n",
    "\n",
    "suburb_to_sa2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburb_to_sa2_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identify unmatched suburbs with missing geometry\n",
    "unmatched_suburbs = merged_gdf[merged_gdf['geometry'].isnull()]['Suburb'].unique()\n",
    "\n",
    "# Convert to Parquet format\n",
    "suburb_to_sa2_df.to_parquet('../data/landing/suburb_match/suburb_match.parquet')\n",
    "\n",
    "# Load the Parquet file containing Locality and SA2 NAME 2021\n",
    "suburb_to_sa2_df = pd.read_parquet('../data/landing/suburb_match/suburb_match.parquet')\n",
    "\n",
    "# Assuming there is a column in the Parquet file that specifies the state, e.g., 'state'\n",
    "suburb_to_sa2_df_vic = suburb_to_sa2_df[suburb_to_sa2_df['state'] == 'VIC']\n",
    "\n",
    "# Clean the suburb data\n",
    "suburb_to_sa2_df_vic['locality'] = suburb_to_sa2_df_vic['locality'].str.strip().str.title()\n",
    "suburb_to_sa2_df_vic.drop_duplicates(subset=['locality'], inplace=True)\n",
    "\n",
    "# 3. Map unmatched suburbs to SA2 names using the Parquet data\n",
    "locality_to_sa2_mapping = suburb_to_sa2_df_vic.set_index('locality')['SA2_NAME_2021'].to_dict()\n",
    "\n",
    "# Replace unmatched suburbs in the merged_gdf with corresponding SA2 namesfff \n",
    "merged_gdf['Suburb'] = merged_gdf['Suburb'].replace(locality_to_sa2_mapping)\n",
    "\n",
    "# 5. Use the SA2 names to find the corresponding geometry from the shapefile\n",
    "# Merge based on the SA2 names (after the substitution)\n",
    "final_merged_gdf = merged_gdf.merge(sf[['sa2_name', 'geometry']], \n",
    "                                    left_on='Suburb', right_on='sa2_name', \n",
    "                                    how='left')\n",
    "\n",
    "# Check the updated GeoDataFrame to ensure the geometries are updated\n",
    "final_merged_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the merge, and rename the columns properly to avoid confusion\n",
    "final_merged_gdf = merged_gdf.merge(sf[['sa2_name', 'geometry']], \n",
    "                                    left_on='Suburb', right_on='sa2_name', \n",
    "                                    how='left')\n",
    "\n",
    "# Drop the redundant geometry_x and rename geometry_y to geometry\n",
    "final_merged_gdf = final_merged_gdf.drop(columns=['geometry_x', 'sa2_name_y'])\n",
    "final_merged_gdf = final_merged_gdf.rename(columns={'geometry_y': 'geometry'})\n",
    "\n",
    "# Now, check the updated GeoDataFrame to ensure the geometries are updated\n",
    "print(\"Columns in final_merged_gdf after cleaning:\", final_merged_gdf.columns)\n",
    "\n",
    "# 6. Identify remaining unmatched suburbs with missing geometry after the merge\n",
    "unmatched_suburbs_after = final_merged_gdf[final_merged_gdf['geometry'].isnull()]['Suburb'].unique()\n",
    "print(f\"Unmatched suburbs after SA2 mapping: {len(unmatched_suburbs_after)}\")\n",
    "\n",
    "# Print unmatched suburbs, if any\n",
    "if len(unmatched_suburbs_after) > 0:\n",
    "    print(\"Remaining unmatched suburbs:\")\n",
    "    print(unmatched_suburbs_after)\n",
    "else:\n",
    "    print(\"All unmatched suburbs have been successfully mapped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
