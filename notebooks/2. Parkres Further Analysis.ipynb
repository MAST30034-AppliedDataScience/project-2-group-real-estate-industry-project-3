{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:30:18.766343Z",
     "start_time": "2024-09-23T12:30:18.759193Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import functions as F  #filtering\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:30:19.179076Z",
     "start_time": "2024-09-23T12:30:18.771403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+--------------------+\n",
      "|                name|            sa2_name|postcode|            geometry|\n",
      "+--------------------+--------------------+--------+--------------------+\n",
      "|Lilydale-Warburto...|        Yarra Valley|    3139|POLYGON ((1034153...|\n",
      "|Nangana Bushland ...|        Yarra Valley|    3139|POLYGON ((1022203...|\n",
      "|Nillumbik G139 Bu...|Wattle Glen - Dia...|    3089|POLYGON ((989912....|\n",
      "|Lilydale-Warburto...|Lilydale - Coldst...|    3140|POLYGON ((1005216...|\n",
      "|Plenty Gorge Park...|  Plenty - Yarrambat|    3088|POLYGON ((983018....|\n",
      "+--------------------+--------------------+--------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# starting a Spark session\n",
    "spark = (\n",
    "    SparkSession.builder.appName('Parkres Further Analysis')\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"2g\")\n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# Read the dataset from a CSV file using PySpark\n",
    "parkres = spark.read.csv('../data/curated/parkres/parkres.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Drop the extra index column (_c0) if it exists\n",
    "parkres = parkres.drop('_c0')\n",
    "\n",
    "# Show the first few rows of the dataset to confirm\n",
    "parkres.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:30:19.507163Z",
     "start_time": "2024-09-23T12:30:19.183414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "+--------------------+-----------------+--------------------+-------------+------------------+-----------+----+-----+-------+------+---------------+--------------------+---------+--------------------+--------+---------+--------+-----------------+--------+--------------------+--------+-----------------+--------+--------+--------+---------+--------+--------------------+-----------------+\n|                 url|            price|             address|property_type|          latitude|  longitude|Beds|Baths|Parking|  bond|extracted_price|            geometry| sa2_code|            sa2_name|chg_flag|  chg_lbl|sa3_code|         sa3_name|sa4_code|            sa4_name|gcc_code|         gcc_name|ste_code|ste_name|aus_code| aus_name|areasqkm|            loci_uri|__index_level_0__|\n+--------------------+-----------------+--------------------+-------------+------------------+-----------+----+-----+-------+------+---------------+--------------------+---------+--------------------+--------+---------+--------+-----------------+--------+--------------------+--------+-----------------+--------+--------+--------+---------+--------+--------------------+-----------------+\n|https://www.domai...|        $1,400.00|10 Allara Court, ...|    Townhouse|-37.77427300000001|145.1811258| 4.0|  3.0|    2.0|9125.0|         1400.0|[01 01 00 00 00 C...|211021261|Donvale - Park Or...|       0|No change|   21102|Manningham - East|     211|Melbourne - Outer...|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia| 20.8028|http://linked.dat...|                0|\n|https://www.domai...|    $750 per week|7 Pine Ridge, Don...|        House|       -37.7912513|145.1756489| 4.0|  2.0|    0.0|3259.0|          750.0|[01 01 00 00 00 8...|211021261|Donvale - Park Or...|       0|No change|   21102|Manningham - East|     211|Melbourne - Outer...|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia| 20.8028|http://linked.dat...|                1|\n|https://www.domai...|   $1300 per week|20 Mulsanne Way, ...|        House|       -37.7972323|145.1812636| 5.0|  2.0|    2.0|5649.0|         1300.0|[01 01 00 00 00 9...|211021261|Donvale - Park Or...|       0|No change|   21102|Manningham - East|     211|Melbourne - Outer...|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia| 20.8028|http://linked.dat...|                2|\n|https://www.domai...|$825pw / $3585pcm|3 Monterey Cresce...|        House|        -37.792402|145.1743233| 3.0|  1.0|    5.0|3585.0|          825.0|[01 01 00 00 00 C...|211021261|Donvale - Park Or...|       0|No change|   21102|Manningham - East|     211|Melbourne - Outer...|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia| 20.8028|http://linked.dat...|                3|\n|https://www.domai...|          $680.00|3/49 Leslie Stree...|    Townhouse|       -37.7810117| 145.180705| 3.0|  2.0|    2.0|2955.0|          680.0|[01 01 00 00 00 2...|211021261|Donvale - Park Or...|       0|No change|   21102|Manningham - East|     211|Melbourne - Outer...|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia| 20.8028|http://linked.dat...|                4|\n+--------------------+-----------------+--------------------+-------------+------------------+-----------+----+-----+-------+------+---------------+--------------------+---------+--------------------+--------+---------+--------+-----------------+--------+--------------------+--------+-----------------+--------+--------+--------+---------+--------+--------------------+-----------------+",
      "text/html": "<table border='1'>\n<tr><th>url</th><th>price</th><th>address</th><th>property_type</th><th>latitude</th><th>longitude</th><th>Beds</th><th>Baths</th><th>Parking</th><th>bond</th><th>extracted_price</th><th>geometry</th><th>sa2_code</th><th>sa2_name</th><th>chg_flag</th><th>chg_lbl</th><th>sa3_code</th><th>sa3_name</th><th>sa4_code</th><th>sa4_name</th><th>gcc_code</th><th>gcc_name</th><th>ste_code</th><th>ste_name</th><th>aus_code</th><th>aus_name</th><th>areasqkm</th><th>loci_uri</th><th>__index_level_0__</th></tr>\n<tr><td>https://www.domai...</td><td>$1,400.00</td><td>10 Allara Court, ...</td><td>Townhouse</td><td>-37.77427300000001</td><td>145.1811258</td><td>4.0</td><td>3.0</td><td>2.0</td><td>9125.0</td><td>1400.0</td><td>[01 01 00 00 00 C...</td><td>211021261</td><td>Donvale - Park Or...</td><td>0</td><td>No change</td><td>21102</td><td>Manningham - East</td><td>211</td><td>Melbourne - Outer...</td><td>2GMEL</td><td>Greater Melbourne</td><td>2</td><td>Victoria</td><td>AUS</td><td>Australia</td><td>20.8028</td><td>http://linked.dat...</td><td>0</td></tr>\n<tr><td>https://www.domai...</td><td>$750 per week</td><td>7 Pine Ridge, Don...</td><td>House</td><td>-37.7912513</td><td>145.1756489</td><td>4.0</td><td>2.0</td><td>0.0</td><td>3259.0</td><td>750.0</td><td>[01 01 00 00 00 8...</td><td>211021261</td><td>Donvale - Park Or...</td><td>0</td><td>No change</td><td>21102</td><td>Manningham - East</td><td>211</td><td>Melbourne - Outer...</td><td>2GMEL</td><td>Greater Melbourne</td><td>2</td><td>Victoria</td><td>AUS</td><td>Australia</td><td>20.8028</td><td>http://linked.dat...</td><td>1</td></tr>\n<tr><td>https://www.domai...</td><td>$1300 per week</td><td>20 Mulsanne Way, ...</td><td>House</td><td>-37.7972323</td><td>145.1812636</td><td>5.0</td><td>2.0</td><td>2.0</td><td>5649.0</td><td>1300.0</td><td>[01 01 00 00 00 9...</td><td>211021261</td><td>Donvale - Park Or...</td><td>0</td><td>No change</td><td>21102</td><td>Manningham - East</td><td>211</td><td>Melbourne - Outer...</td><td>2GMEL</td><td>Greater Melbourne</td><td>2</td><td>Victoria</td><td>AUS</td><td>Australia</td><td>20.8028</td><td>http://linked.dat...</td><td>2</td></tr>\n<tr><td>https://www.domai...</td><td>$825pw / $3585pcm</td><td>3 Monterey Cresce...</td><td>House</td><td>-37.792402</td><td>145.1743233</td><td>3.0</td><td>1.0</td><td>5.0</td><td>3585.0</td><td>825.0</td><td>[01 01 00 00 00 C...</td><td>211021261</td><td>Donvale - Park Or...</td><td>0</td><td>No change</td><td>21102</td><td>Manningham - East</td><td>211</td><td>Melbourne - Outer...</td><td>2GMEL</td><td>Greater Melbourne</td><td>2</td><td>Victoria</td><td>AUS</td><td>Australia</td><td>20.8028</td><td>http://linked.dat...</td><td>3</td></tr>\n<tr><td>https://www.domai...</td><td>$680.00</td><td>3/49 Leslie Stree...</td><td>Townhouse</td><td>-37.7810117</td><td>145.180705</td><td>3.0</td><td>2.0</td><td>2.0</td><td>2955.0</td><td>680.0</td><td>[01 01 00 00 00 2...</td><td>211021261</td><td>Donvale - Park Or...</td><td>0</td><td>No change</td><td>21102</td><td>Manningham - East</td><td>211</td><td>Melbourne - Outer...</td><td>2GMEL</td><td>Greater Melbourne</td><td>2</td><td>Victoria</td><td>AUS</td><td>Australia</td><td>20.8028</td><td>http://linked.dat...</td><td>4</td></tr>\n</table>\n"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the domain parquet dataset\n",
    "domain = spark.read.parquet('../data/curated/domain_data')\n",
    "domain.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:30:19.791843Z",
     "start_time": "2024-09-23T12:30:19.510035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------+-------------+--------+---------+----+-----+-------+----+---------------+--------+--------+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-----------------+\n",
      "|url|price|address|property_type|latitude|longitude|Beds|Baths|Parking|bond|extracted_price|geometry|sa2_code|sa2_name|chg_flag|chg_lbl|sa3_code|sa3_name|sa4_code|sa4_name|gcc_code|gcc_name|ste_code|ste_name|aus_code|aus_name|areasqkm|loci_uri|__index_level_0__|\n",
      "+---+-----+-------+-------------+--------+---------+----+-----+-------+----+---------------+--------+--------+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-----------------+\n",
      "|  0|    0|      0|            0|       0|        0|   0|    0|      0|1199|              0|       0|       0|       0|       0|      0|       0|       0|       0|       0|       0|       0|       0|       0|       0|       0|       0|       0|                0|\n",
      "+---+-----+-------+-------------+--------+---------+----+-----+-------+----+---------------+--------+--------+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Check for null values in each column\n",
    "domain.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in domain.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:30:36.228720Z",
     "start_time": "2024-09-23T12:30:19.799106Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 89:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+--------------------+--------------------+-----------+-----------+----+-----+-------+------+---------------+--------------------+---------+-----------------+--------+---------+--------+------------+--------+--------------------+--------+-----------------+--------+--------+--------+---------+--------+--------------------+-----------------+--------------------+--------------------+--------+--------------------+--------------------+------------------+-----------------+------------------+\n",
      "|                 url|           price|             address|       property_type|   prop_lat|   prop_lon|Beds|Baths|Parking|  bond|extracted_price|            geometry| sa2_code|property_sa2_name|chg_flag|  chg_lbl|sa3_code|    sa3_name|sa4_code|            sa4_name|gcc_code|         gcc_name|ste_code|ste_name|aus_code| aus_name|areasqkm|            loci_uri|__index_level_0__|                name|            sa2_name|postcode|       park_geometry|       park_centroid| park_centroid_lat|park_centroid_lon|          distance|\n",
      "+--------------------+----------------+--------------------+--------------------+-----------+-----------+----+-----+-------+------+---------------+--------------------+---------+-----------------+--------+---------+--------+------------+--------+--------------------+--------+-----------------+--------+--------+--------+---------+--------+--------------------+-----------------+--------------------+--------------------+--------+--------------------+--------------------+------------------+-----------------+------------------+\n",
      "|https://www.domai...|   $690 Per Week|90 Wickhams Road,...|               House|  -37.79095| 145.566483| 3.0|  2.0|    4.0|2998.0|          690.0|[01 01 00 00 00 A...|211051286|     Yarra Valley|       0|No change|   21105|Yarra Ranges|     211|Melbourne - Outer...|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia|729.7582|http://linked.dat...|             5294|Yarra Valley Park...|Warrandyte - Wong...|    3111|POLYGON ((990878....|-4288358.54470186...|-4288358.544701863|990868.3816606078| 259.9745567502766|\n",
      "|https://www.domai...|            $738|37 MONBULK-SEVILL...|Apartment / Unit ...|-37.7857874|145.4667604| 1.0|  1.0|    0.0|  NULL|          738.0|[01 01 00 00 00 2...|211051285| Wandin - Seville|       0|No change|   21105|Yarra Ranges|     211|Melbourne - Outer...|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia|111.7555|http://linked.dat...|             5296|Yarra Valley Park...|Warrandyte - Wong...|    3111|POLYGON ((990878....|-4288358.54470186...|-4288358.544701863|990868.3816606078|268.42900145854645|\n",
      "|https://www.domai...|$730.00 per week|5 Morris Court, W...|               House|-37.7756867|145.4272857| 3.0|  2.0|    2.0|3172.0|          730.0|[01 01 00 00 00 8...|211051285| Wandin - Seville|       0|No change|   21105|Yarra Ranges|     211|Melbourne - Outer...|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia|111.7555|http://linked.dat...|             5295|Yarra Valley Park...|Warrandyte - Wong...|    3111|POLYGON ((990878....|-4288358.54470186...|-4288358.544701863|990868.3816606078|272.07456568431184|\n",
      "|https://www.domai...|   $500 per week|136a Belgrave-Hal...|Apartment / Unit ...|-37.9310902| 145.359687| 3.0|  2.0|    1.0|2173.0|          500.0|[01 01 00 00 00 7...|211051274| Belgrave - Selby|       0|No change|   21105|Yarra Ranges|     211|Melbourne - Outer...|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia|  55.652|http://linked.dat...|             2203|Yarra Valley Park...|Warrandyte - Wong...|    3111|POLYGON ((990878....|-4288358.54470186...|-4288358.544701863|990868.3816606078| 272.5943617408172|\n",
      "|https://www.domai...|         $650 pw|39 Sandells Road,...|               House|-37.9002756|145.3459308| 3.0|  1.0|    0.0|2824.0|          650.0|[01 01 00 00 00 B...|211051284|   Upwey - Tecoma|       0|No change|   21105|Yarra Ranges|     211|Melbourne - Outer...|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia|  8.8907|http://linked.dat...|             2204|Yarra Valley Park...|Warrandyte - Wong...|    3111|POLYGON ((990878....|-4288358.54470186...|-4288358.544701863|990868.3816606078| 274.6854608987869|\n",
      "+--------------------+----------------+--------------------+--------------------+-----------+-----------+----+-----+-------+------+---------------+--------------------+---------+-----------------+--------+---------+--------+------------+--------+--------------------+--------+-----------------+--------+--------+--------+---------+--------+--------------------+-----------------+--------------------+--------------------+--------+--------------------+--------------------+------------------+-----------------+------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "from shapely import wkt\n",
    "from pyspark.sql.functions import udf\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# Function to calculate distance between two points (Haversine formula)\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth's radius in km\n",
    "    \n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# UDF to convert WKT geometry to centroid coordinates\n",
    "def get_centroid(geometry):\n",
    "    try:\n",
    "        shape = wkt.loads(geometry)\n",
    "        centroid = shape.centroid\n",
    "        return f\"{centroid.y},{centroid.x}\"\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Register UDFs\n",
    "distance_udf = udf(calculate_distance, DoubleType())\n",
    "centroid_udf = udf(get_centroid, StringType())\n",
    "\n",
    "# Prepare park data\n",
    "parkres = parkres.withColumnRenamed(\"geometry\", \"park_geometry\")\n",
    "parkres = parkres.withColumn(\"park_centroid\", centroid_udf(F.col(\"park_geometry\")))\n",
    "parkres = parkres.withColumn(\"park_centroid_lat\", F.split(F.col(\"park_centroid\"), \",\")[0].cast(DoubleType()))\n",
    "parkres = parkres.withColumn(\"park_centroid_lon\", F.split(F.col(\"park_centroid\"), \",\")[1].cast(DoubleType()))\n",
    "\n",
    "# Prepare domain data\n",
    "domain = domain.withColumnRenamed(\"latitude\", \"prop_lat\")\n",
    "domain = domain.withColumnRenamed(\"longitude\", \"prop_lon\")\n",
    "domain = domain.withColumnRenamed(\"sa2_name\", \"property_sa2_name\")\n",
    "\n",
    "# Cross join to calculate the distance between each property and every park\n",
    "result = domain.crossJoin(F.broadcast(parkres))\n",
    "\n",
    "# Calculate distances between properties and park centroids\n",
    "result = result.withColumn(\"distance\", \n",
    "    distance_udf(F.col(\"prop_lat\"), F.col(\"prop_lon\"), \n",
    "                 F.col(\"park_centroid_lat\"), F.col(\"park_centroid_lon\")))\n",
    "result.orderBy(\"distance\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 92:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------+---------------+---------------------+----------------------+---------------------------------------------+-----------------------+\n",
      "|address                                            |extracted_price|nearest_park_distance|nearest_park_name     |property_sa2_name                            |park_sa2_name          |\n",
      "+---------------------------------------------------+---------------+---------------------+----------------------+---------------------------------------------+-----------------------+\n",
      "|90 Wickhams Road, Launching Place VIC 3139         |690.0          |259.9745567502766    |Yarra Valley Parklands|Yarra Valley                                 |Warrandyte - Wonga Park|\n",
      "|37 MONBULK-SEVILLE ROAD, Seville VIC 3139          |738.0          |268.42900145854645   |Yarra Valley Parklands|Wandin - Seville                             |Warrandyte - Wonga Park|\n",
      "|5 Morris Court, Wandin North VIC 3139              |730.0          |272.07456568431184   |Yarra Valley Parklands|Wandin - Seville                             |Warrandyte - Wonga Park|\n",
      "|136a Belgrave-Hallam Road, Belgrave South VIC 3160 |500.0          |272.5943617408172    |Yarra Valley Parklands|Belgrave - Selby                             |Warrandyte - Wonga Park|\n",
      "|39 Sandells Road, Tecoma VIC 3160                  |650.0          |274.6854608987869    |Yarra Valley Parklands|Upwey - Tecoma                               |Warrandyte - Wonga Park|\n",
      "|30 Glenfern Avenue, Upwey VIC 3158                 |685.0          |275.3540964765436    |Yarra Valley Parklands|Upwey - Tecoma                               |Warrandyte - Wonga Park|\n",
      "|20 Deans Road, Upwey VIC 3158                      |675.0          |275.78327888782206   |Yarra Valley Parklands|Upwey - Tecoma                               |Warrandyte - Wonga Park|\n",
      "|26 Olivette Avenue, Upwey VIC 3158                 |1350.0         |276.39701884064255   |Yarra Valley Parklands|Upwey - Tecoma                               |Warrandyte - Wonga Park|\n",
      "|57 Old Belgrave Road, Upper Ferntree Gully VIC 3156|550.0          |277.0089889950123    |Yarra Valley Parklands|Ferntree Gully (South) - Upper Ferntree Gully|Warrandyte - Wonga Park|\n",
      "|372 Swansea Road, Lilydale VIC 3140                |650.0          |277.5220151350886    |Yarra Valley Parklands|Lilydale - Coldstream                        |Warrandyte - Wonga Park|\n",
      "+---------------------------------------------------+---------------+---------------------+----------------------+---------------------------------------------+-----------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Find the nearest park for each property\n",
    "window_spec = Window.partitionBy(\"__index_level_0__\").orderBy(\"distance\")\n",
    "nearest_park = result.withColumn(\"row\", F.row_number().over(window_spec)) \\\n",
    "    .filter(F.col(\"row\") == 1) \\\n",
    "    .select(\n",
    "        \"__index_level_0__\",\n",
    "        F.col(\"distance\").alias(\"nearest_park_distance\"),\n",
    "        F.col(\"name\").alias(\"nearest_park_name\"),\n",
    "        F.col(\"sa2_name\").alias(\"park_sa2_name\")\n",
    "    )\n",
    "\n",
    "# Join back to the original domain data\n",
    "final_result = domain.join(nearest_park, on=\"__index_level_0__\")\n",
    "\n",
    "# Show the result for validation\n",
    "final_result.select(\n",
    "    \"address\", \n",
    "    \"extracted_price\", \n",
    "    \"nearest_park_distance\", \n",
    "    \"nearest_park_name\", \n",
    "    \"property_sa2_name\", \n",
    "    \"park_sa2_name\"\n",
    ") \\\n",
    "    .orderBy(\"nearest_park_distance\") \\\n",
    "    .show(10, truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T12:30:46.801299Z",
     "start_time": "2024-09-23T12:30:36.235679Z"
    }
   },
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:30:46.823068Z",
     "start_time": "2024-09-23T12:30:46.811328Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\('\n",
      "/var/folders/_7/sr3p02zn35v2xg1fm8dsbz6c0000gn/T/ipykernel_31872/2575708135.py:1: SyntaxWarning: invalid escape sequence '\\('\n",
      "  '''from pyspark.sql import functions as F\n"
     ]
    },
    {
     "data": {
      "text/plain": "'from pyspark.sql import functions as F\\nfrom pyspark.sql.types import DoubleType\\nfrom math import radians, sin, cos, sqrt, atan2\\n\\n# Helper function to parse geometry\\ndef parse_geometry(geom):\\n    coords = F.split(F.regexp_extract(geom, r\"POINT\\\\((.*?)\\\\)\", 1), \" \")\\n    return F.struct(\\n        coords[0].cast(DoubleType()).alias(\"longitude\"),\\n        coords[1].cast(DoubleType()).alias(\"latitude\")\\n    )\\n\\n# Haversine distance function with null handling\\n@F.udf(returnType=DoubleType())\\ndef haversine_distance(lat1, lon1, lat2, lon2):\\n    if lat1 is None or lon1 is None or lat2 is None or lon2 is None:\\n        return None\\n    \\n    R = 6371  # Earth\\'s radius in kilometers\\n    \\n    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\\n    dlat = lat2 - lat1\\n    dlon = lon2 - lon1\\n    \\n    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\\n    c = 2 * atan2(sqrt(a), sqrt(1-a))\\n    return R * c\\n\\n# Load data\\nparkres = spark.read.csv(\\'../data/curated/parkres/parkres.csv\\', header=True, inferSchema=True)\\ndomain = spark.read.parquet(\\'../data/curated/domain_data\\')\\n\\n# Display schema and sample data\\nprint(\"parkres schema:\")\\nparkres.printSchema()\\nprint(\"\\nSample parkres data:\")\\nparkres.show(5, truncate=False)\\n\\nprint(\"\\ndomain schema:\")\\ndomain.printSchema()\\nprint(\"\\nSample domain data:\")\\ndomain.show(5, truncate=False)\\n\\n# Parse geometry for parkres\\nparkres = parkres.withColumn(\"park_coords\", parse_geometry(F.col(\"geometry\")))\\n\\n# Prepare domain data\\ndomain = domain.select(\\n    \"url\", \"extracted_price\", \\n    F.col(\"latitude\").cast(DoubleType()),\\n    F.col(\"longitude\").cast(DoubleType())\\n).withColumn(\"property_coords\", F.struct(\"latitude\", \"longitude\"))\\n\\n# Calculate distances using cross join\\ncrossed = domain.crossJoin(F.broadcast(parkres))\\nwith_distances = crossed.withColumn(\"distance_to_park\",\\n    haversine_distance(\\n        F.col(\"property_coords.latitude\"), F.col(\"property_coords.longitude\"),\\n        F.col(\"park_coords.latitude\"), F.col(\"park_coords.longitude\")\\n    )\\n)\\n\\n# Find nearest park for each property\\nnearest_park = with_distances.groupBy(\"url\").agg(\\n    F.min(\"distance_to_park\").alias(\"nearest_park_distance\")\\n)\\n\\n# Join back to get full property data with nearest park distance\\nresult = domain.join(nearest_park, on=\"url\")\\n\\n# Analyze by distance ranges\\nanalysis = result.groupBy(F.round(F.col(\"nearest_park_distance\")).alias(\"distance_km\"))     .agg(\\n        F.avg(\"extracted_price\").alias(\"avg_price\"),\\n        F.count(\"url\").alias(\"property_count\")\\n    )     .orderBy(\"distance_km\")\\n\\n# Show results\\nprint(\"\\nFinal analysis:\")\\nanalysis.show()\\n\\n# Optional: Count null distances\\nnull_distances = result.filter(F.col(\"nearest_park_distance\").isNull()).count()\\nprint(f\"\\nNumber of properties with null distances: {null_distances}\")'"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# Helper function to parse geometry\n",
    "def parse_geometry(geom):\n",
    "    coords = F.split(F.regexp_extract(geom, r\"POINT\\((.*?)\\)\", 1), \" \")\n",
    "    return F.struct(\n",
    "        coords[0].cast(DoubleType()).alias(\"longitude\"),\n",
    "        coords[1].cast(DoubleType()).alias(\"latitude\")\n",
    "    )\n",
    "\n",
    "# Haversine distance function with null handling\n",
    "@F.udf(returnType=DoubleType())\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    if lat1 is None or lon1 is None or lat2 is None or lon2 is None:\n",
    "        return None\n",
    "    \n",
    "    R = 6371  # Earth's radius in kilometers\n",
    "    \n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    return R * c\n",
    "\n",
    "# Load data\n",
    "parkres = spark.read.csv('../data/curated/parkres/parkres.csv', header=True, inferSchema=True)\n",
    "domain = spark.read.parquet('../data/curated/domain_data')\n",
    "\n",
    "# Display schema and sample data\n",
    "print(\"parkres schema:\")\n",
    "parkres.printSchema()\n",
    "print(\"\\nSample parkres data:\")\n",
    "parkres.show(5, truncate=False)\n",
    "\n",
    "print(\"\\ndomain schema:\")\n",
    "domain.printSchema()\n",
    "print(\"\\nSample domain data:\")\n",
    "domain.show(5, truncate=False)\n",
    "\n",
    "# Parse geometry for parkres\n",
    "parkres = parkres.withColumn(\"park_coords\", parse_geometry(F.col(\"geometry\")))\n",
    "\n",
    "# Prepare domain data\n",
    "domain = domain.select(\n",
    "    \"url\", \"extracted_price\", \n",
    "    F.col(\"latitude\").cast(DoubleType()),\n",
    "    F.col(\"longitude\").cast(DoubleType())\n",
    ").withColumn(\"property_coords\", F.struct(\"latitude\", \"longitude\"))\n",
    "\n",
    "# Calculate distances using cross join\n",
    "crossed = domain.crossJoin(F.broadcast(parkres))\n",
    "with_distances = crossed.withColumn(\"distance_to_park\",\n",
    "    haversine_distance(\n",
    "        F.col(\"property_coords.latitude\"), F.col(\"property_coords.longitude\"),\n",
    "        F.col(\"park_coords.latitude\"), F.col(\"park_coords.longitude\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Find nearest park for each property\n",
    "nearest_park = with_distances.groupBy(\"url\").agg(\n",
    "    F.min(\"distance_to_park\").alias(\"nearest_park_distance\")\n",
    ")\n",
    "\n",
    "# Join back to get full property data with nearest park distance\n",
    "result = domain.join(nearest_park, on=\"url\")\n",
    "\n",
    "# Analyze by distance ranges\n",
    "analysis = result.groupBy(F.round(F.col(\"nearest_park_distance\")).alias(\"distance_km\")) \\\n",
    "    .agg(\n",
    "        F.avg(\"extracted_price\").alias(\"avg_price\"),\n",
    "        F.count(\"url\").alias(\"property_count\")\n",
    "    ) \\\n",
    "    .orderBy(\"distance_km\")\n",
    "\n",
    "# Show results\n",
    "print(\"\\nFinal analysis:\")\n",
    "analysis.show()\n",
    "\n",
    "# Optional: Count null distances\n",
    "null_distances = result.filter(F.col(\"nearest_park_distance\").isNull()).count()\n",
    "print(f\"\\nNumber of properties with null distances: {null_distances}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:30:46.841711Z",
     "start_time": "2024-09-23T12:30:46.827034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'import geopandas as gpd\\nfrom shapely.geometry import Point\\nfrom shapely import wkt\\nimport pandas as pd\\n\\n# Step 1: Inspect the domain dataset\\nprint(domain.show(5))  # Show a few rows to ensure data exists in \\'latitude\\' and \\'longitude\\'\\n\\n# Convert Spark DataFrame to Pandas\\ndomain_pd = domain.select(\\'url\\', \\'latitude\\', \\'longitude\\').toPandas()\\n\\n# Step 2: Check for null values in domain\\'s latitude and longitude\\nprint(\"Checking for null values in domain dataset:\")\\nprint(domain_pd.isnull().sum())  # This will show if there are any null latitudes or longitudes\\n\\n# Step 3: Check if lat/lon columns are valid in the domain\\ndomain_pd = domain_pd.dropna(subset=[\\'latitude\\', \\'longitude\\'])\\nprint(f\"Number of valid rows in domain dataset after dropping nulls: {len(domain_pd)}\")\\n\\n# Step 4: Inspect the parkres dataset\\nprint(parkres.show(5))  # Show a few rows to ensure data exists in \\'geometry\\'\\n\\n# Convert Spark DataFrame to Pandas\\nparkres_pd = parkres.select(\\'sa2_name\\', \\'geometry\\').toPandas()\\n\\n# Step 5: Check for null values in parkres dataset\\nprint(\"Checking for null values in parkres dataset:\")\\nprint(parkres_pd.isnull().sum())  # This will show if there are any null geometries\\n\\n# Step 6: Check if geometry column is valid in parkres\\nparkres_pd = parkres_pd.dropna(subset=[\\'geometry\\'])\\nprint(f\"Number of valid rows in parkres dataset after dropping null geometries: {len(parkres_pd)}\")\\n\\n# Step 7: Try converting both datasets to GeoDataFrames\\nif not domain_pd.empty and not parkres_pd.empty:\\n    # Create GeoDataFrame for domain\\n    domain_gdf = gpd.GeoDataFrame(domain_pd, geometry=gpd.points_from_xy(domain_pd.longitude, domain_pd.latitude), crs=\"EPSG:4326\")\\n\\n    # Create GeoDataFrame for parkres\\n    parkres_gdf = gpd.GeoDataFrame(parkres_pd, geometry=parkres_pd[\\'geometry\\'].apply(wkt.loads), crs=\"EPSG:4326\")\\n\\n    print(\"Successfully created GeoDataFrames for both datasets.\")\\nelse:\\n    print(\"One of the datasets is still empty after handling missing values.\")'"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkt\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Inspect the domain dataset\n",
    "print(domain.show(5))  # Show a few rows to ensure data exists in 'latitude' and 'longitude'\n",
    "\n",
    "# Convert Spark DataFrame to Pandas\n",
    "domain_pd = domain.select('url', 'latitude', 'longitude').toPandas()\n",
    "\n",
    "# Step 2: Check for null values in domain's latitude and longitude\n",
    "print(\"Checking for null values in domain dataset:\")\n",
    "print(domain_pd.isnull().sum())  # This will show if there are any null latitudes or longitudes\n",
    "\n",
    "# Step 3: Check if lat/lon columns are valid in the domain\n",
    "domain_pd = domain_pd.dropna(subset=['latitude', 'longitude'])\n",
    "print(f\"Number of valid rows in domain dataset after dropping nulls: {len(domain_pd)}\")\n",
    "\n",
    "# Step 4: Inspect the parkres dataset\n",
    "print(parkres.show(5))  # Show a few rows to ensure data exists in 'geometry'\n",
    "\n",
    "# Convert Spark DataFrame to Pandas\n",
    "parkres_pd = parkres.select('sa2_name', 'geometry').toPandas()\n",
    "\n",
    "# Step 5: Check for null values in parkres dataset\n",
    "print(\"Checking for null values in parkres dataset:\")\n",
    "print(parkres_pd.isnull().sum())  # This will show if there are any null geometries\n",
    "\n",
    "# Step 6: Check if geometry column is valid in parkres\n",
    "parkres_pd = parkres_pd.dropna(subset=['geometry'])\n",
    "print(f\"Number of valid rows in parkres dataset after dropping null geometries: {len(parkres_pd)}\")\n",
    "\n",
    "# Step 7: Try converting both datasets to GeoDataFrames\n",
    "if not domain_pd.empty and not parkres_pd.empty:\n",
    "    # Create GeoDataFrame for domain\n",
    "    domain_gdf = gpd.GeoDataFrame(domain_pd, geometry=gpd.points_from_xy(domain_pd.longitude, domain_pd.latitude), crs=\"EPSG:4326\")\n",
    "\n",
    "    # Create GeoDataFrame for parkres\n",
    "    parkres_gdf = gpd.GeoDataFrame(parkres_pd, geometry=parkres_pd['geometry'].apply(wkt.loads), crs=\"EPSG:4326\")\n",
    "\n",
    "    print(\"Successfully created GeoDataFrames for both datasets.\")\n",
    "else:\n",
    "    print(\"One of the datasets is still empty after handling missing values.\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:30:46.853156Z",
     "start_time": "2024-09-23T12:30:46.844966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'from pyspark.sql import functions as F\\nfrom pyspark.sql.types import DoubleType\\nfrom shapely import wkb, wkt\\nfrom shapely.ops import nearest_points\\n\\n# Define UDF for geospatial operations\\n@F.udf(returnType=DoubleType())\\ndef calculate_distance(lat, lon, park_geom_wkt):\\n    point = wkt.loads(f\"POINT({lon} {lat})\")\\n    park = wkt.loads(park_geom_wkt)\\n    nearest_point = nearest_points(point, park.exterior)[1]\\n    return point.distance(nearest_point) * 111000  # Approximate conversion to meters\\n\\n# Convert binary WKB to WKT\\ndef wkb_to_wkt(wkb_value):\\n    if wkb_value is None:\\n        return None\\n    return wkb.loads(wkb_value).wkt\\n\\nwkb_to_wkt_udf = F.udf(wkb_to_wkt, returnType=F.StringType())\\n\\n# Prepare domain DataFrame\\ndomain_prepared = domain.withColumn(\"domain_geometry_wkt\", wkb_to_wkt_udf(F.col(\"geometry\")))\\n\\n# Rename parkres geometry column to avoid conflict\\nparkres_prepared = parkres.withColumnRenamed(\"geometry\", \"park_geometry\")\\n\\n# Cross join domain with parkres\\njoined = domain_prepared.crossJoin(parkres_prepared)\\n\\n# Calculate distances\\njoined = joined.withColumn(\"distance\", \\n                           calculate_distance(F.col(\"latitude\"), \\n                                              F.col(\"longitude\"), \\n                                              F.col(\"park_geometry\")))\\n\\n# Find the minimum distance for each domain entry\\nresult = joined.groupBy(\"url\", \"address\", \"__index_level_0__\")     .agg(F.min(\"distance\").alias(\"min_distance_to_park_border\"), \\n         F.first(\"name\").alias(\"nearest_park_name\"))\\n\\n# Show the results\\nresult.show(truncate=False)\\n\\n# If you want to save the results\\n# result.write.parquet(\"path/to/save/results.parquet\")'"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType\n",
    "from shapely import wkb, wkt\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "# Define UDF for geospatial operations\n",
    "@F.udf(returnType=DoubleType())\n",
    "def calculate_distance(lat, lon, park_geom_wkt):\n",
    "    point = wkt.loads(f\"POINT({lon} {lat})\")\n",
    "    park = wkt.loads(park_geom_wkt)\n",
    "    nearest_point = nearest_points(point, park.exterior)[1]\n",
    "    return point.distance(nearest_point) * 111000  # Approximate conversion to meters\n",
    "\n",
    "# Convert binary WKB to WKT\n",
    "def wkb_to_wkt(wkb_value):\n",
    "    if wkb_value is None:\n",
    "        return None\n",
    "    return wkb.loads(wkb_value).wkt\n",
    "\n",
    "wkb_to_wkt_udf = F.udf(wkb_to_wkt, returnType=F.StringType())\n",
    "\n",
    "# Prepare domain DataFrame\n",
    "domain_prepared = domain.withColumn(\"domain_geometry_wkt\", wkb_to_wkt_udf(F.col(\"geometry\")))\n",
    "\n",
    "# Rename parkres geometry column to avoid conflict\n",
    "parkres_prepared = parkres.withColumnRenamed(\"geometry\", \"park_geometry\")\n",
    "\n",
    "# Cross join domain with parkres\n",
    "joined = domain_prepared.crossJoin(parkres_prepared)\n",
    "\n",
    "# Calculate distances\n",
    "joined = joined.withColumn(\"distance\", \n",
    "                           calculate_distance(F.col(\"latitude\"), \n",
    "                                              F.col(\"longitude\"), \n",
    "                                              F.col(\"park_geometry\")))\n",
    "\n",
    "# Find the minimum distance for each domain entry\n",
    "result = joined.groupBy(\"url\", \"address\", \"__index_level_0__\") \\\n",
    "    .agg(F.min(\"distance\").alias(\"min_distance_to_park_border\"), \n",
    "         F.first(\"name\").alias(\"nearest_park_name\"))\n",
    "\n",
    "# Show the results\n",
    "result.show(truncate=False)\n",
    "\n",
    "# If you want to save the results\n",
    "# result.write.parquet(\"path/to/save/results.parquet\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:30:46.865683Z",
     "start_time": "2024-09-23T12:30:46.855895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'from pyspark.sql import functions as F\\nfrom pyspark.sql.types import DoubleType\\nfrom shapely import wkb, wkt\\nfrom shapely.ops import nearest_points\\nimport math\\n\\n# Define the Haversine formula to calculate distance in meters between two lat/lon points\\ndef haversine_distance(lat1, lon1, lat2, lon2):\\n    R = 6371000  # Radius of Earth in meters\\n    phi1 = math.radians(lat1)\\n    phi2 = math.radians(lat2)\\n    delta_phi = math.radians(lat2 - lat1)\\n    delta_lambda = math.radians(lon2 - lon1)\\n\\n    a = math.sin(delta_phi / 2) ** 2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2) ** 2\\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\\n\\n    return R * c  # Distance in meters\\n\\n# Define UDF for geospatial operations using Haversine formula\\n@F.udf(returnType=DoubleType())\\ndef calculate_distance(lat, lon, park_geom_wkt):\\n    point = wkt.loads(f\"POINT({lon} {lat})\")\\n    park = wkt.loads(park_geom_wkt)\\n    \\n    # Find the nearest point on the park boundary\\n    nearest_point = nearest_points(point, park.exterior)[1]\\n    \\n    # Calculate the Haversine distance between the property point and nearest park point\\n    return haversine_distance(lat, lon, nearest_point.y, nearest_point.x)\\n\\n# Convert binary WKB to WKT\\ndef wkb_to_wkt(wkb_value):\\n    if wkb_value is None:\\n        return None\\n    return wkb.loads(wkb_value).wkt\\n\\nwkb_to_wkt_udf = F.udf(wkb_to_wkt, returnType=F.StringType())\\n\\n# Prepare domain DataFrame\\ndomain_prepared = domain.withColumn(\"domain_geometry_wkt\", wkb_to_wkt_udf(F.col(\"geometry\")))\\n\\n# Rename parkres geometry column to avoid conflict\\nparkres_prepared = parkres.withColumnRenamed(\"geometry\", \"park_geometry\")\\n\\n# Cross join domain with parkres\\njoined = domain_prepared.crossJoin(parkres_prepared)\\n\\n# Calculate distances using the improved method (Haversine formula)\\njoined = joined.withColumn(\"distance\", \\n                           calculate_distance(F.col(\"latitude\"), \\n                                              F.col(\"longitude\"), \\n                                              F.col(\"park_geometry\")))\\n\\n# Find the minimum distance for each domain entry\\nresult = joined.groupBy(\"url\", \"address\", \"__index_level_0__\")     .agg(F.min(\"distance\").alias(\"min_distance_to_park_border\"), \\n         F.first(\"name\").alias(\"nearest_park_name\"))\\n\\n# Show the results\\nresult.show(truncate=False)\\n\\n# Optional: Save the results if needed\\n# result.write.parquet(\"path/to/save/results.parquet\")'"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType\n",
    "from shapely import wkb, wkt\n",
    "from shapely.ops import nearest_points\n",
    "import math\n",
    "\n",
    "# Define the Haversine formula to calculate distance in meters between two lat/lon points\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  # Radius of Earth in meters\n",
    "    phi1 = math.radians(lat1)\n",
    "    phi2 = math.radians(lat2)\n",
    "    delta_phi = math.radians(lat2 - lat1)\n",
    "    delta_lambda = math.radians(lon2 - lon1)\n",
    "\n",
    "    a = math.sin(delta_phi / 2) ** 2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    return R * c  # Distance in meters\n",
    "\n",
    "# Define UDF for geospatial operations using Haversine formula\n",
    "@F.udf(returnType=DoubleType())\n",
    "def calculate_distance(lat, lon, park_geom_wkt):\n",
    "    point = wkt.loads(f\"POINT({lon} {lat})\")\n",
    "    park = wkt.loads(park_geom_wkt)\n",
    "    \n",
    "    # Find the nearest point on the park boundary\n",
    "    nearest_point = nearest_points(point, park.exterior)[1]\n",
    "    \n",
    "    # Calculate the Haversine distance between the property point and nearest park point\n",
    "    return haversine_distance(lat, lon, nearest_point.y, nearest_point.x)\n",
    "\n",
    "# Convert binary WKB to WKT\n",
    "def wkb_to_wkt(wkb_value):\n",
    "    if wkb_value is None:\n",
    "        return None\n",
    "    return wkb.loads(wkb_value).wkt\n",
    "\n",
    "wkb_to_wkt_udf = F.udf(wkb_to_wkt, returnType=F.StringType())\n",
    "\n",
    "# Prepare domain DataFrame\n",
    "domain_prepared = domain.withColumn(\"domain_geometry_wkt\", wkb_to_wkt_udf(F.col(\"geometry\")))\n",
    "\n",
    "# Rename parkres geometry column to avoid conflict\n",
    "parkres_prepared = parkres.withColumnRenamed(\"geometry\", \"park_geometry\")\n",
    "\n",
    "# Cross join domain with parkres\n",
    "joined = domain_prepared.crossJoin(parkres_prepared)\n",
    "\n",
    "# Calculate distances using the improved method (Haversine formula)\n",
    "joined = joined.withColumn(\"distance\", \n",
    "                           calculate_distance(F.col(\"latitude\"), \n",
    "                                              F.col(\"longitude\"), \n",
    "                                              F.col(\"park_geometry\")))\n",
    "\n",
    "# Find the minimum distance for each domain entry\n",
    "result = joined.groupBy(\"url\", \"address\", \"__index_level_0__\") \\\n",
    "    .agg(F.min(\"distance\").alias(\"min_distance_to_park_border\"), \n",
    "         F.first(\"name\").alias(\"nearest_park_name\"))\n",
    "\n",
    "# Show the results\n",
    "result.show(truncate=False)\n",
    "\n",
    "# Optional: Save the results if needed\n",
    "# result.write.parquet(\"path/to/save/results.parquet\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:30:46.883979Z",
     "start_time": "2024-09-23T12:30:46.874697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'from pyspark.sql.functions import udf\\nfrom pyspark.sql.types import DoubleType, StringType\\nfrom shapely import wkb, wkt\\nimport math\\n\\ndef haversine_distance(lat1, lon1, lat2, lon2):\\n    R = 6371  # Radius of Earth in kilometers\\n    \\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\\n    \\n    dlat = lat2 - lat1\\n    dlon = lon2 - lon1\\n    \\n    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\\n    c = 2 * math.asin(math.sqrt(a))\\n    \\n    return R * c * 1000  # Distance in meters\\n\\n@udf(returnType=DoubleType())\\ndef calculate_distance(lat, lon, park_geom_wkt):\\n    if lat is None or lon is None or park_geom_wkt is None:\\n        return None\\n    \\n    point = wkt.loads(f\"POINT({lon} {lat})\")\\n    park = wkt.loads(park_geom_wkt)\\n    \\n    # Find the nearest point on the park boundary\\n    nearest_point = park.exterior.interpolate(park.exterior.project(point))\\n    \\n    return haversine_distance(lat, lon, nearest_point.y, nearest_point.x)\\n\\n@udf(returnType=StringType())\\ndef wkb_to_wkt(wkb_value):\\n    if wkb_value is None:\\n        return None\\n    return wkb.loads(wkb_value).wkt\\n\\n# Prepare domain DataFrame\\ndomain_prepared = domain.withColumn(\"domain_geometry_wkt\", wkb_to_wkt(domain.geometry))\\n\\n# Rename parkres geometry column to avoid conflict\\nparkres_prepared = parkres.withColumnRenamed(\"geometry\", \"park_geometry\")\\n\\n# Join domain with parkres\\njoined = domain_prepared.crossJoin(parkres_prepared)\\n\\n# Calculate distances\\njoined = joined.withColumn(\"distance\",\\n                           calculate_distance(joined.latitude,\\n                                              joined.longitude,\\n                                              joined.park_geometry))\\n\\n# Find the minimum distance for each domain entry\\nresult = joined.groupBy(\"url\", \"address\", \"__index_level_0__\")     .agg({\"distance\": \"min\", \"name\": \"first\"})     .withColumnRenamed(\"min(distance)\", \"min_distance_to_park_border\")     .withColumnRenamed(\"first(name)\", \"nearest_park_name\")\\n\\n# Show the results\\nresult.show(truncate=False)\\n\\n# Optional: Save the results if needed\\n# result.write.parquet(\"path/to/save/results.parquet\")'"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "from shapely import wkb, wkt\n",
    "import math\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radius of Earth in kilometers\n",
    "    \n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    \n",
    "    return R * c * 1000  # Distance in meters\n",
    "\n",
    "@udf(returnType=DoubleType())\n",
    "def calculate_distance(lat, lon, park_geom_wkt):\n",
    "    if lat is None or lon is None or park_geom_wkt is None:\n",
    "        return None\n",
    "    \n",
    "    point = wkt.loads(f\"POINT({lon} {lat})\")\n",
    "    park = wkt.loads(park_geom_wkt)\n",
    "    \n",
    "    # Find the nearest point on the park boundary\n",
    "    nearest_point = park.exterior.interpolate(park.exterior.project(point))\n",
    "    \n",
    "    return haversine_distance(lat, lon, nearest_point.y, nearest_point.x)\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def wkb_to_wkt(wkb_value):\n",
    "    if wkb_value is None:\n",
    "        return None\n",
    "    return wkb.loads(wkb_value).wkt\n",
    "\n",
    "# Prepare domain DataFrame\n",
    "domain_prepared = domain.withColumn(\"domain_geometry_wkt\", wkb_to_wkt(domain.geometry))\n",
    "\n",
    "# Rename parkres geometry column to avoid conflict\n",
    "parkres_prepared = parkres.withColumnRenamed(\"geometry\", \"park_geometry\")\n",
    "\n",
    "# Join domain with parkres\n",
    "joined = domain_prepared.crossJoin(parkres_prepared)\n",
    "\n",
    "# Calculate distances\n",
    "joined = joined.withColumn(\"distance\",\n",
    "                           calculate_distance(joined.latitude,\n",
    "                                              joined.longitude,\n",
    "                                              joined.park_geometry))\n",
    "\n",
    "# Find the minimum distance for each domain entry\n",
    "result = joined.groupBy(\"url\", \"address\", \"__index_level_0__\") \\\n",
    "    .agg({\"distance\": \"min\", \"name\": \"first\"}) \\\n",
    "    .withColumnRenamed(\"min(distance)\", \"min_distance_to_park_border\") \\\n",
    "    .withColumnRenamed(\"first(name)\", \"nearest_park_name\")\n",
    "\n",
    "# Show the results\n",
    "result.show(truncate=False)\n",
    "\n",
    "# Optional: Save the results if needed\n",
    "# result.write.parquet(\"path/to/save/results.parquet\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:30:47.020491Z",
     "start_time": "2024-09-23T12:30:46.887421Z"
    }
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `latitude` cannot be resolved. Did you mean one of the following? [`Baths`, `aus_code`, `bond`, `loci_uri`, `postcode`].;\n'Project [url#6064, price#6065, address#6066, property_type#6067, prop_lat#6704, prop_lon#6734, Beds#6070, Baths#6071, Parking#6072, bond#6073, extracted_price#6074, geometry#6075, sa2_code#6076, property_sa2_name#6764, chg_flag#6078, chg_lbl#6079, sa3_code#6080, sa3_name#6081, sa4_code#6082, sa4_name#6083, gcc_code#6084, gcc_name#6085, ste_code#6086, ste_name#6087, ... 14 more fields]\n+- Join Cross\n   :- Project [url#6064, price#6065, address#6066, property_type#6067, prop_lat#6704, prop_lon#6734, Beds#6070, Baths#6071, Parking#6072, bond#6073, extracted_price#6074, geometry#6075, sa2_code#6076, property_sa2_name#6764, chg_flag#6078, chg_lbl#6079, sa3_code#6080, sa3_name#6081, sa4_code#6082, sa4_name#6083, gcc_code#6084, gcc_name#6085, ste_code#6086, ste_name#6087, ... 6 more fields]\n   :  +- Project [url#6064, price#6065, address#6066, property_type#6067, prop_lat#6704, prop_lon#6734, Beds#6070, Baths#6071, Parking#6072, bond#6073, extracted_price#6074, geometry#6075, sa2_code#6076, sa2_name#6077 AS property_sa2_name#6764, chg_flag#6078, chg_lbl#6079, sa3_code#6080, sa3_name#6081, sa4_code#6082, sa4_name#6083, gcc_code#6084, gcc_name#6085, ste_code#6086, ste_name#6087, ... 5 more fields]\n   :     +- Project [url#6064, price#6065, address#6066, property_type#6067, prop_lat#6704, longitude#6069 AS prop_lon#6734, Beds#6070, Baths#6071, Parking#6072, bond#6073, extracted_price#6074, geometry#6075, sa2_code#6076, sa2_name#6077, chg_flag#6078, chg_lbl#6079, sa3_code#6080, sa3_name#6081, sa4_code#6082, sa4_name#6083, gcc_code#6084, gcc_name#6085, ste_code#6086, ste_name#6087, ... 5 more fields]\n   :        +- Project [url#6064, price#6065, address#6066, property_type#6067, latitude#6068 AS prop_lat#6704, longitude#6069, Beds#6070, Baths#6071, Parking#6072, bond#6073, extracted_price#6074, geometry#6075, sa2_code#6076, sa2_name#6077, chg_flag#6078, chg_lbl#6079, sa3_code#6080, sa3_name#6081, sa4_code#6082, sa4_name#6083, gcc_code#6084, gcc_name#6085, ste_code#6086, ste_name#6087, ... 5 more fields]\n   :           +- Relation [url#6064,price#6065,address#6066,property_type#6067,latitude#6068,longitude#6069,Beds#6070,Baths#6071,Parking#6072,bond#6073,extracted_price#6074,geometry#6075,sa2_code#6076,sa2_name#6077,chg_flag#6078,chg_lbl#6079,sa3_code#6080,sa3_name#6081,sa4_code#6082,sa4_name#6083,gcc_code#6084,gcc_name#6085,ste_code#6086,ste_name#6087,... 5 more fields] parquet\n   +- Project [name#6029, sa2_name#6030, postcode#6031, park_geometry#6677, park_centroid#6683, park_centroid_lat#6689, cast(split(park_centroid#6683, ,, -1)[1] as double) AS park_centroid_lon#6696]\n      +- Project [name#6029, sa2_name#6030, postcode#6031, park_geometry#6677, park_centroid#6683, cast(split(park_centroid#6683, ,, -1)[0] as double) AS park_centroid_lat#6689]\n         +- Project [name#6029, sa2_name#6030, postcode#6031, park_geometry#6677, get_centroid(park_geometry#6677)#6682 AS park_centroid#6683]\n            +- Project [name#6029, sa2_name#6030, postcode#6031, geometry#6032 AS park_geometry#6677]\n               +- Project [name#6029, sa2_name#6030, postcode#6031, geometry#6032]\n                  +- Relation [_c0#6028,name#6029,sa2_name#6030,postcode#6031,geometry#6032] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[68], line 57\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# Calculate distances\u001B[39;00m\n\u001B[1;32m     56\u001B[0m distance_calc \u001B[38;5;241m=\u001B[39m calculate_distance(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlatitude\u001B[39m\u001B[38;5;124m\"\u001B[39m), col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlongitude\u001B[39m\u001B[38;5;124m\"\u001B[39m), col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpark_geometry\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m---> 57\u001B[0m joined \u001B[38;5;241m=\u001B[39m \u001B[43mjoined\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwithColumn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdistance_result\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdistance_calc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m joined \u001B[38;5;241m=\u001B[39m joined\u001B[38;5;241m.\u001B[39mwithColumn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdistance\u001B[39m\u001B[38;5;124m\"\u001B[39m, col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdistance_result.distance\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m     59\u001B[0m joined \u001B[38;5;241m=\u001B[39m joined\u001B[38;5;241m.\u001B[39mwithColumn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdistance_error\u001B[39m\u001B[38;5;124m\"\u001B[39m, col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdistance_result.error\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "File \u001B[0;32m~/PycharmProjects/project-2-group-real-estate-industry-project-3/.venv/lib/python3.12/site-packages/pyspark/sql/dataframe.py:5176\u001B[0m, in \u001B[0;36mDataFrame.withColumn\u001B[0;34m(self, colName, col)\u001B[0m\n\u001B[1;32m   5171\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(col, Column):\n\u001B[1;32m   5172\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n\u001B[1;32m   5173\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNOT_COLUMN\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   5174\u001B[0m         message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcol\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(col)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n\u001B[1;32m   5175\u001B[0m     )\n\u001B[0;32m-> 5176\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwithColumn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcolName\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcol\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jc\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
      "File \u001B[0;32m~/PycharmProjects/project-2-group-real-estate-industry-project-3/.venv/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/PycharmProjects/project-2-group-real-estate-industry-project-3/.venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:185\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    181\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 185\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `latitude` cannot be resolved. Did you mean one of the following? [`Baths`, `aus_code`, `bond`, `loci_uri`, `postcode`].;\n'Project [url#6064, price#6065, address#6066, property_type#6067, prop_lat#6704, prop_lon#6734, Beds#6070, Baths#6071, Parking#6072, bond#6073, extracted_price#6074, geometry#6075, sa2_code#6076, property_sa2_name#6764, chg_flag#6078, chg_lbl#6079, sa3_code#6080, sa3_name#6081, sa4_code#6082, sa4_name#6083, gcc_code#6084, gcc_name#6085, ste_code#6086, ste_name#6087, ... 14 more fields]\n+- Join Cross\n   :- Project [url#6064, price#6065, address#6066, property_type#6067, prop_lat#6704, prop_lon#6734, Beds#6070, Baths#6071, Parking#6072, bond#6073, extracted_price#6074, geometry#6075, sa2_code#6076, property_sa2_name#6764, chg_flag#6078, chg_lbl#6079, sa3_code#6080, sa3_name#6081, sa4_code#6082, sa4_name#6083, gcc_code#6084, gcc_name#6085, ste_code#6086, ste_name#6087, ... 6 more fields]\n   :  +- Project [url#6064, price#6065, address#6066, property_type#6067, prop_lat#6704, prop_lon#6734, Beds#6070, Baths#6071, Parking#6072, bond#6073, extracted_price#6074, geometry#6075, sa2_code#6076, sa2_name#6077 AS property_sa2_name#6764, chg_flag#6078, chg_lbl#6079, sa3_code#6080, sa3_name#6081, sa4_code#6082, sa4_name#6083, gcc_code#6084, gcc_name#6085, ste_code#6086, ste_name#6087, ... 5 more fields]\n   :     +- Project [url#6064, price#6065, address#6066, property_type#6067, prop_lat#6704, longitude#6069 AS prop_lon#6734, Beds#6070, Baths#6071, Parking#6072, bond#6073, extracted_price#6074, geometry#6075, sa2_code#6076, sa2_name#6077, chg_flag#6078, chg_lbl#6079, sa3_code#6080, sa3_name#6081, sa4_code#6082, sa4_name#6083, gcc_code#6084, gcc_name#6085, ste_code#6086, ste_name#6087, ... 5 more fields]\n   :        +- Project [url#6064, price#6065, address#6066, property_type#6067, latitude#6068 AS prop_lat#6704, longitude#6069, Beds#6070, Baths#6071, Parking#6072, bond#6073, extracted_price#6074, geometry#6075, sa2_code#6076, sa2_name#6077, chg_flag#6078, chg_lbl#6079, sa3_code#6080, sa3_name#6081, sa4_code#6082, sa4_name#6083, gcc_code#6084, gcc_name#6085, ste_code#6086, ste_name#6087, ... 5 more fields]\n   :           +- Relation [url#6064,price#6065,address#6066,property_type#6067,latitude#6068,longitude#6069,Beds#6070,Baths#6071,Parking#6072,bond#6073,extracted_price#6074,geometry#6075,sa2_code#6076,sa2_name#6077,chg_flag#6078,chg_lbl#6079,sa3_code#6080,sa3_name#6081,sa4_code#6082,sa4_name#6083,gcc_code#6084,gcc_name#6085,ste_code#6086,ste_name#6087,... 5 more fields] parquet\n   +- Project [name#6029, sa2_name#6030, postcode#6031, park_geometry#6677, park_centroid#6683, park_centroid_lat#6689, cast(split(park_centroid#6683, ,, -1)[1] as double) AS park_centroid_lon#6696]\n      +- Project [name#6029, sa2_name#6030, postcode#6031, park_geometry#6677, park_centroid#6683, cast(split(park_centroid#6683, ,, -1)[0] as double) AS park_centroid_lat#6689]\n         +- Project [name#6029, sa2_name#6030, postcode#6031, park_geometry#6677, get_centroid(park_geometry#6677)#6682 AS park_centroid#6683]\n            +- Project [name#6029, sa2_name#6030, postcode#6031, geometry#6032 AS park_geometry#6677]\n               +- Project [name#6029, sa2_name#6030, postcode#6031, geometry#6032]\n                  +- Relation [_c0#6028,name#6029,sa2_name#6030,postcode#6031,geometry#6032] csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, col, lit\n",
    "from pyspark.sql.types import DoubleType, StringType, StructType, StructField\n",
    "import shapely\n",
    "from shapely import wkb, wkt\n",
    "from pyproj import Geod\n",
    "import sys\n",
    "\n",
    "# Use WGS84 ellipsoid for distance calculations\n",
    "geod = Geod(ellps=\"WGS84\")\n",
    "\n",
    "# Define a struct to return both distance and error message\n",
    "result_schema = StructType([\n",
    "    StructField(\"distance\", DoubleType(), True),\n",
    "    StructField(\"error\", StringType(), True)\n",
    "])\n",
    "\n",
    "@udf(returnType=result_schema)\n",
    "def calculate_distance(lat, lon, park_geom_wkt):\n",
    "    try:\n",
    "        if lat is None or lon is None or park_geom_wkt is None:\n",
    "            return (None, \"One or more input values are None\")\n",
    "        \n",
    "        lat, lon = float(lat), float(lon)\n",
    "        point = wkt.loads(f\"POINT({lon} {lat})\")\n",
    "        park = wkt.loads(park_geom_wkt)\n",
    "        \n",
    "        # Find the nearest point on the park boundary\n",
    "        nearest_point = park.exterior.interpolate(park.exterior.project(point))\n",
    "        \n",
    "        # Calculate the geodesic distance\n",
    "        _, _, distance = geod.inv(lon, lat, nearest_point.x, nearest_point.y)\n",
    "        \n",
    "        return (float(distance), None)\n",
    "    except Exception as e:\n",
    "        return (None, str(e))\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def wkb_to_wkt(wkb_value):\n",
    "    try:\n",
    "        if wkb_value is None:\n",
    "            return None\n",
    "        return wkb.loads(wkb_value).wkt\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Prepare domain DataFrame\n",
    "domain_prepared = domain.withColumn(\"domain_geometry_wkt\", wkb_to_wkt(col(\"geometry\")))\n",
    "\n",
    "# Rename parkres geometry column to avoid conflict\n",
    "parkres_prepared = parkres.withColumnRenamed(\"geometry\", \"park_geometry\")\n",
    "\n",
    "# Join domain with parkres\n",
    "joined = domain_prepared.crossJoin(parkres_prepared)\n",
    "\n",
    "# Calculate distances\n",
    "distance_calc = calculate_distance(col(\"latitude\"), col(\"longitude\"), col(\"park_geometry\"))\n",
    "joined = joined.withColumn(\"distance_result\", distance_calc)\n",
    "joined = joined.withColumn(\"distance\", col(\"distance_result.distance\"))\n",
    "joined = joined.withColumn(\"distance_error\", col(\"distance_result.error\"))\n",
    "\n",
    "# Find the minimum distance for each domain entry\n",
    "result = joined.groupBy(\"url\", \"address\", \"__index_level_0__\") \\\n",
    "    .agg({\"distance\": \"min\", \"name\": \"first\", \"distance_error\": \"first\"}) \\\n",
    "    .withColumnRenamed(\"min(distance)\", \"min_distance_to_park_border\") \\\n",
    "    .withColumnRenamed(\"first(name)\", \"nearest_park_name\") \\\n",
    "    .withColumnRenamed(\"first(distance_error)\", \"error_message\")\n",
    "\n",
    "# Show the results\n",
    "result.show(truncate=False)\n",
    "\n",
    "# Optional: Save the results if needed\n",
    "# result.write.parquet(\"path/to/save/results.parquet\")\n",
    "\n",
    "# Print some debug information\n",
    "print(\"Sample of domain_geometry_wkt:\")\n",
    "domain_prepared.select(\"domain_geometry_wkt\").show(5, truncate=False)\n",
    "\n",
    "print(\"\\nSample of park_geometry:\")\n",
    "parkres_prepared.select(\"park_geometry\").show(5, truncate=False)\n",
    "\n",
    "print(\"\\nSample of latitude and longitude:\")\n",
    "domain_prepared.select(\"latitude\", \"longitude\").show(5, truncate=False)\n",
    "\n",
    "print(\"\\nUnique error messages:\")\n",
    "result.select(\"error_message\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sqrt, pow, min as spark_min, first\n",
    "from pyspark.sql.types import DoubleType\n",
    "from math import radians\n",
    "\n",
    "# Approximate radius of earth in km\n",
    "R = 6371.0\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    # Convert decimal degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = pow(sin(dlat/2), 2) + cos(lat1) * cos(lat2) * pow(sin(dlon/2), 2)\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    distance = R * c\n",
    "    \n",
    "    return distance\n",
    "\n",
    "# Register the UDF\n",
    "haversine_udf = F.udf(haversine_distance, DoubleType())\n",
    "\n",
    "# Assuming 'domain' is your DataFrame with property data\n",
    "# and 'parkres' is your DataFrame with park data\n",
    "\n",
    "# Calculate the distance for each property-park pair\n",
    "result = domain.crossJoin(parkres) \\\n",
    "    .withColumn(\"distance\", \n",
    "                haversine_udf(\n",
    "                    col(\"latitude\"), col(\"longitude\"), \n",
    "                    col(\"park_latitude\"), col(\"park_longitude\")\n",
    "                )) \\\n",
    "    .groupBy(\"url\", \"address\", \"__index_level_0__\") \\\n",
    "    .agg(\n",
    "        spark_min(\"distance\").alias(\"min_distance_to_park_border\"),\n",
    "        first(\"park_name\").alias(\"nearest_park_name\")\n",
    "    )\n",
    "\n",
    "# Show the results\n",
    "result.show(truncate=False)\n",
    "\n",
    "# Optional: Save the results if needed\n",
    "# result.write.parquet(\"path/to/save/results.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
