{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:23:56.163911Z",
     "start_time": "2024-09-23T13:23:55.897655Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import functions as F  #filtering\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:24:02.158555Z",
     "start_time": "2024-09-23T13:23:56.164521Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/23 23:23:57 WARN Utils: Your hostname, coldbrew.local resolves to a loopback address: 127.0.0.1; using 172.16.119.16 instead (on interface en0)\n",
      "24/09/23 23:23:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/23 23:23:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/09/23 23:23:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+--------------------+\n",
      "|                name|            sa2_name|postcode|            geometry|\n",
      "+--------------------+--------------------+--------+--------------------+\n",
      "|Lilydale-Warburto...|        Yarra Valley|    3139|POLYGON ((145.687...|\n",
      "|Nangana Bushland ...|        Yarra Valley|    3139|POLYGON ((145.565...|\n",
      "|Nillumbik G139 Bu...|Wattle Glen - Dia...|    3089|POLYGON ((145.178...|\n",
      "|Lilydale-Warburto...|Lilydale - Coldst...|    3140|POLYGON ((145.360...|\n",
      "|Plenty Gorge Park...|  Plenty - Yarrambat|    3088|POLYGON ((145.099...|\n",
      "+--------------------+--------------------+--------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# starting a Spark session\n",
    "spark = (\n",
    "    SparkSession.builder.appName('Parkres Further Analysis')\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"2g\")\n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# Read the dataset from a CSV file using PySpark\n",
    "parkres = spark.read.csv('../data/curated/parkres/parkres.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Drop the extra index column (_c0) if it exists\n",
    "parkres = parkres.drop('_c0')\n",
    "\n",
    "# Show the first few rows of the dataset to confirm\n",
    "parkres.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:24:03.415241Z",
     "start_time": "2024-09-23T13:24:02.159597Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/23 23:24:02 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": "+--------------------+-----------------+--------------------+-------------+------------------+-----------+----+-----+-------+------+---------------+--------------------+---------+--------------------+--------+---------+--------+-----------------+--------+--------------------+--------+-----------------+--------+--------+--------+---------+--------+--------------------+-----------------+\n|                 url|            price|             address|property_type|          latitude|  longitude|Beds|Baths|Parking|  bond|extracted_price|            geometry| sa2_code|            sa2_name|chg_flag|  chg_lbl|sa3_code|         sa3_name|sa4_code|            sa4_name|gcc_code|         gcc_name|ste_code|ste_name|aus_code| aus_name|areasqkm|            loci_uri|__index_level_0__|\n+--------------------+-----------------+--------------------+-------------+------------------+-----------+----+-----+-------+------+---------------+--------------------+---------+--------------------+--------+---------+--------+-----------------+--------+--------------------+--------+-----------------+--------+--------+--------+---------+--------+--------------------+-----------------+\n|https://www.domai...|        $1,400.00|10 Allara Court, ...|    Townhouse|-37.77427300000001|145.1811258| 4.0|  3.0|    2.0|9125.0|         1400.0|[01 01 00 00 00 C...|211021261|Donvale - Park Or...|       0|No change|   21102|Manningham - East|     211|Melbourne - Outer...|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia| 20.8028|http://linked.dat...|                0|\n|https://www.domai...|    $750 per week|7 Pine Ridge, Don...|        House|       -37.7912513|145.1756489| 4.0|  2.0|    0.0|3259.0|          750.0|[01 01 00 00 00 8...|211021261|Donvale - Park Or...|       0|No change|   21102|Manningham - East|     211|Melbourne - Outer...|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia| 20.8028|http://linked.dat...|                1|\n|https://www.domai...|   $1300 per week|20 Mulsanne Way, ...|        House|       -37.7972323|145.1812636| 5.0|  2.0|    2.0|5649.0|         1300.0|[01 01 00 00 00 9...|211021261|Donvale - Park Or...|       0|No change|   21102|Manningham - East|     211|Melbourne - Outer...|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia| 20.8028|http://linked.dat...|                2|\n|https://www.domai...|$825pw / $3585pcm|3 Monterey Cresce...|        House|        -37.792402|145.1743233| 3.0|  1.0|    5.0|3585.0|          825.0|[01 01 00 00 00 C...|211021261|Donvale - Park Or...|       0|No change|   21102|Manningham - East|     211|Melbourne - Outer...|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia| 20.8028|http://linked.dat...|                3|\n|https://www.domai...|          $680.00|3/49 Leslie Stree...|    Townhouse|       -37.7810117| 145.180705| 3.0|  2.0|    2.0|2955.0|          680.0|[01 01 00 00 00 2...|211021261|Donvale - Park Or...|       0|No change|   21102|Manningham - East|     211|Melbourne - Outer...|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia| 20.8028|http://linked.dat...|                4|\n+--------------------+-----------------+--------------------+-------------+------------------+-----------+----+-----+-------+------+---------------+--------------------+---------+--------------------+--------+---------+--------+-----------------+--------+--------------------+--------+-----------------+--------+--------+--------+---------+--------+--------------------+-----------------+",
      "text/html": "<table border='1'>\n<tr><th>url</th><th>price</th><th>address</th><th>property_type</th><th>latitude</th><th>longitude</th><th>Beds</th><th>Baths</th><th>Parking</th><th>bond</th><th>extracted_price</th><th>geometry</th><th>sa2_code</th><th>sa2_name</th><th>chg_flag</th><th>chg_lbl</th><th>sa3_code</th><th>sa3_name</th><th>sa4_code</th><th>sa4_name</th><th>gcc_code</th><th>gcc_name</th><th>ste_code</th><th>ste_name</th><th>aus_code</th><th>aus_name</th><th>areasqkm</th><th>loci_uri</th><th>__index_level_0__</th></tr>\n<tr><td>https://www.domai...</td><td>$1,400.00</td><td>10 Allara Court, ...</td><td>Townhouse</td><td>-37.77427300000001</td><td>145.1811258</td><td>4.0</td><td>3.0</td><td>2.0</td><td>9125.0</td><td>1400.0</td><td>[01 01 00 00 00 C...</td><td>211021261</td><td>Donvale - Park Or...</td><td>0</td><td>No change</td><td>21102</td><td>Manningham - East</td><td>211</td><td>Melbourne - Outer...</td><td>2GMEL</td><td>Greater Melbourne</td><td>2</td><td>Victoria</td><td>AUS</td><td>Australia</td><td>20.8028</td><td>http://linked.dat...</td><td>0</td></tr>\n<tr><td>https://www.domai...</td><td>$750 per week</td><td>7 Pine Ridge, Don...</td><td>House</td><td>-37.7912513</td><td>145.1756489</td><td>4.0</td><td>2.0</td><td>0.0</td><td>3259.0</td><td>750.0</td><td>[01 01 00 00 00 8...</td><td>211021261</td><td>Donvale - Park Or...</td><td>0</td><td>No change</td><td>21102</td><td>Manningham - East</td><td>211</td><td>Melbourne - Outer...</td><td>2GMEL</td><td>Greater Melbourne</td><td>2</td><td>Victoria</td><td>AUS</td><td>Australia</td><td>20.8028</td><td>http://linked.dat...</td><td>1</td></tr>\n<tr><td>https://www.domai...</td><td>$1300 per week</td><td>20 Mulsanne Way, ...</td><td>House</td><td>-37.7972323</td><td>145.1812636</td><td>5.0</td><td>2.0</td><td>2.0</td><td>5649.0</td><td>1300.0</td><td>[01 01 00 00 00 9...</td><td>211021261</td><td>Donvale - Park Or...</td><td>0</td><td>No change</td><td>21102</td><td>Manningham - East</td><td>211</td><td>Melbourne - Outer...</td><td>2GMEL</td><td>Greater Melbourne</td><td>2</td><td>Victoria</td><td>AUS</td><td>Australia</td><td>20.8028</td><td>http://linked.dat...</td><td>2</td></tr>\n<tr><td>https://www.domai...</td><td>$825pw / $3585pcm</td><td>3 Monterey Cresce...</td><td>House</td><td>-37.792402</td><td>145.1743233</td><td>3.0</td><td>1.0</td><td>5.0</td><td>3585.0</td><td>825.0</td><td>[01 01 00 00 00 C...</td><td>211021261</td><td>Donvale - Park Or...</td><td>0</td><td>No change</td><td>21102</td><td>Manningham - East</td><td>211</td><td>Melbourne - Outer...</td><td>2GMEL</td><td>Greater Melbourne</td><td>2</td><td>Victoria</td><td>AUS</td><td>Australia</td><td>20.8028</td><td>http://linked.dat...</td><td>3</td></tr>\n<tr><td>https://www.domai...</td><td>$680.00</td><td>3/49 Leslie Stree...</td><td>Townhouse</td><td>-37.7810117</td><td>145.180705</td><td>3.0</td><td>2.0</td><td>2.0</td><td>2955.0</td><td>680.0</td><td>[01 01 00 00 00 2...</td><td>211021261</td><td>Donvale - Park Or...</td><td>0</td><td>No change</td><td>21102</td><td>Manningham - East</td><td>211</td><td>Melbourne - Outer...</td><td>2GMEL</td><td>Greater Melbourne</td><td>2</td><td>Victoria</td><td>AUS</td><td>Australia</td><td>20.8028</td><td>http://linked.dat...</td><td>4</td></tr>\n</table>\n"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the domain parquet dataset\n",
    "domain = spark.read.parquet('../data/curated/domain_data')\n",
    "domain.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:24:04.029741Z",
     "start_time": "2024-09-23T13:24:03.417738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------+-------------+--------+---------+----+-----+-------+----+---------------+--------+--------+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-----------------+\n",
      "|url|price|address|property_type|latitude|longitude|Beds|Baths|Parking|bond|extracted_price|geometry|sa2_code|sa2_name|chg_flag|chg_lbl|sa3_code|sa3_name|sa4_code|sa4_name|gcc_code|gcc_name|ste_code|ste_name|aus_code|aus_name|areasqkm|loci_uri|__index_level_0__|\n",
      "+---+-----+-------+-------------+--------+---------+----+-----+-------+----+---------------+--------+--------+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-----------------+\n",
      "|  0|    0|      0|            0|       0|        0|   0|    0|      0|1199|              0|       0|       0|       0|       0|      0|       0|       0|       0|       0|       0|       0|       0|       0|       0|       0|       0|       0|                0|\n",
      "+---+-----+-------+-------------+--------+---------+----+-----+-------+----+---------------+--------+--------+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Check for null values in each column\n",
    "domain.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in domain.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:24:19.444861Z",
     "start_time": "2024-09-23T13:24:04.030657Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+--------------------+-----------+-----------+----+-----+-------+------+---------------+--------------------+---------+--------------------+--------+---------+--------+--------+--------+-----------------+--------+-----------------+--------+--------+--------+---------+--------+--------------------+-----------------+--------------------+--------------------+--------+--------------------+--------------------+------------------+------------------+--------------------+\n",
      "|                 url|              price|             address|       property_type|   prop_lat|   prop_lon|Beds|Baths|Parking|  bond|extracted_price|            geometry| sa2_code|   property_sa2_name|chg_flag|  chg_lbl|sa3_code|sa3_name|sa4_code|         sa4_name|gcc_code|         gcc_name|ste_code|ste_name|aus_code| aus_name|areasqkm|            loci_uri|__index_level_0__|                name|            sa2_name|postcode|       park_geometry|       park_centroid| park_centroid_lat| park_centroid_lon|            distance|\n",
      "+--------------------+-------------------+--------------------+--------------------+-----------+-----------+----+-----+-------+------+---------------+--------------------+---------+--------------------+--------+---------+--------+--------+--------+-----------------+--------+-----------------+--------+--------+--------+---------+--------+--------------------+-----------------+--------------------+--------------------+--------+--------------------+--------------------+------------------+------------------+--------------------+\n",
      "|https://www.domai...|        $680 weekly|509/20 Shamrock S...|Apartment / Unit ...|-37.8101409|145.0082181| 2.0|  2.0|    1.0|2955.0|          680.0|[01 01 00 00 00 8...|206071139|          Abbotsford|       0|No change|   20607|   Yarra|     206|Melbourne - Inner|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia|  1.7405|http://linked.dat...|             6912|Lower Yarra River...|          Abbotsford|    3067|POLYGON ((145.008...|-37.8100701995760...|-37.81007019957607|145.00875369488278|0.047703829463742776|\n",
      "|https://www.domai...|$550 pw / $2390 pcm|214/20 Shamrock S...|Apartment / Unit ...|-37.8101409|145.0082181| 1.0|  1.0|    0.0|2390.0|          550.0|[01 01 00 00 00 8...|206071139|          Abbotsford|       0|No change|   20607|   Yarra|     206|Melbourne - Inner|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia|  1.7405|http://linked.dat...|             6891|Lower Yarra River...|          Abbotsford|    3067|POLYGON ((145.008...|-37.8100701995760...|-37.81007019957607|145.00875369488278|0.047703829463742776|\n",
      "|https://www.domai...|        $450 weekly|930/20 Shamrock S...|Apartment / Unit ...|-37.8101409|145.0082181| 1.0|  1.0|    0.0|1956.0|          450.0|[01 01 00 00 00 8...|206071139|          Abbotsford|       0|No change|   20607|   Yarra|     206|Melbourne - Inner|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia|  1.7405|http://linked.dat...|             6899|Lower Yarra River...|          Abbotsford|    3067|POLYGON ((145.008...|-37.8100701995760...|-37.81007019957607|145.00875369488278|0.047703829463742776|\n",
      "|https://www.domai...|  $475pw / $2064pcm|208/20 Shamrock S...|Apartment / Unit ...|-37.8101409|145.0082181| 2.0|  1.0|    0.0|2064.0|          475.0|[01 01 00 00 00 8...|206071139|          Abbotsford|       0|No change|   20607|   Yarra|     206|Melbourne - Inner|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia|  1.7405|http://linked.dat...|             6925|Lower Yarra River...|          Abbotsford|    3067|POLYGON ((145.008...|-37.8100701995760...|-37.81007019957607|145.00875369488278|0.047703829463742776|\n",
      "|https://www.domai...|      $540 per week|49 Constellation ...|               House|-37.8507304|144.7431695| 3.0|  2.0|    2.0|2346.0|          540.0|[01 01 00 00 00 4...|213051587|Truganina - South...|       1|      New|   21305| Wyndham|     213| Melbourne - West|   2GMEL|Greater Melbourne|       2|Victoria|     AUS|Australia|  4.2675|http://linked.dat...|             2677|Truganina South N...|Truganina - South...|    3027|POLYGON ((144.745...|-37.8502480372750...|-37.85024803727507|  144.743457192342| 0.05928663072570662|\n",
      "+--------------------+-------------------+--------------------+--------------------+-----------+-----------+----+-----+-------+------+---------------+--------------------+---------+--------------------+--------+---------+--------+--------+--------+-----------------+--------+-----------------+--------+--------+--------+---------+--------+--------------------+-----------------+--------------------+--------------------+--------+--------------------+--------------------+------------------+------------------+--------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "from shapely import wkt\n",
    "from pyspark.sql.functions import udf\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# Function to calculate distance between two points (Haversine formula)\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth's radius in km\n",
    "    \n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# UDF to convert WKT geometry to centroid coordinates\n",
    "def get_centroid(geometry):\n",
    "    try:\n",
    "        shape = wkt.loads(geometry)\n",
    "        centroid = shape.centroid\n",
    "        return f\"{centroid.y},{centroid.x}\"\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Register UDFs\n",
    "distance_udf = udf(calculate_distance, DoubleType())\n",
    "centroid_udf = udf(get_centroid, StringType())\n",
    "\n",
    "# Prepare park data\n",
    "parkres = parkres.withColumnRenamed(\"geometry\", \"park_geometry\")\n",
    "parkres = parkres.withColumn(\"park_centroid\", centroid_udf(F.col(\"park_geometry\")))\n",
    "parkres = parkres.withColumn(\"park_centroid_lat\", F.split(F.col(\"park_centroid\"), \",\")[0].cast(DoubleType()))\n",
    "parkres = parkres.withColumn(\"park_centroid_lon\", F.split(F.col(\"park_centroid\"), \",\")[1].cast(DoubleType()))\n",
    "\n",
    "# Prepare domain data\n",
    "domain = domain.withColumnRenamed(\"latitude\", \"prop_lat\")\n",
    "domain = domain.withColumnRenamed(\"longitude\", \"prop_lon\")\n",
    "domain = domain.withColumnRenamed(\"sa2_name\", \"property_sa2_name\")\n",
    "\n",
    "# Cross join to calculate the distance between each property and every park\n",
    "result = domain.crossJoin(F.broadcast(parkres))\n",
    "\n",
    "# Calculate distances between properties and park centroids\n",
    "result = result.withColumn(\"distance\", \n",
    "    distance_udf(F.col(\"prop_lat\"), F.col(\"prop_lon\"), \n",
    "                 F.col(\"park_centroid_lat\"), F.col(\"park_centroid_lon\")))\n",
    "result.orderBy(\"distance\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+---------------+---------------------+-------------------------------------------+----------------------+----------------------+\n",
      "|address                                      |extracted_price|nearest_park_distance|nearest_park_name                          |property_sa2_name     |park_sa2_name         |\n",
      "+---------------------------------------------+---------------+---------------------+-------------------------------------------+----------------------+----------------------+\n",
      "|930/20 Shamrock Street, Abbotsford VIC 3067  |450.0          |0.047703829463742776 |Lower Yarra River land (addition) Park     |Abbotsford            |Abbotsford            |\n",
      "|214/20 Shamrock Street, Abbotsford VIC 3067  |550.0          |0.047703829463742776 |Lower Yarra River land (addition) Park     |Abbotsford            |Abbotsford            |\n",
      "|509/20 Shamrock St, Abbotsford VIC 3067      |680.0          |0.047703829463742776 |Lower Yarra River land (addition) Park     |Abbotsford            |Abbotsford            |\n",
      "|208/20 Shamrock Street, Abbotsford VIC 3067  |475.0          |0.047703829463742776 |Lower Yarra River land (addition) Park     |Abbotsford            |Abbotsford            |\n",
      "|49 Constellation Circuit, Truganina VIC 3029 |540.0          |0.05928663072570662  |Truganina South Nature Conservation Reserve|Truganina - South East|Truganina - South East|\n",
      "|26 Galactic Way, Truganina VIC 3029          |580.0          |0.06334998151424667  |Truganina South Nature Conservation Reserve|Truganina - South East|Truganina - South East|\n",
      "|A909/627 Victoria Street, Abbotsford VIC 3067|895.0          |0.06752859631359583  |Lower Yarra River land (addition) Park     |Abbotsford            |Abbotsford            |\n",
      "|A914/627 Victoria Street, Abbotsford VIC 3067|795.0          |0.06752859631359583  |Lower Yarra River land (addition) Park     |Abbotsford            |Abbotsford            |\n",
      "|A915/627 Victoria Street, Abbotsford VIC 3067|750.0          |0.06752859631359583  |Lower Yarra River land (addition) Park     |Abbotsford            |Abbotsford            |\n",
      "|4/11 River St, Richmond VIC 3121             |750.0          |0.07212508054409197  |Lower Yarra River land                     |Richmond - North      |Richmond - North      |\n",
      "+---------------------------------------------+---------------+---------------------+-------------------------------------------+----------------------+----------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Find the nearest park for each property\n",
    "window_spec = Window.partitionBy(\"__index_level_0__\").orderBy(\"distance\")\n",
    "nearest_park = result.withColumn(\"row\", F.row_number().over(window_spec)) \\\n",
    "    .filter(F.col(\"row\") == 1) \\\n",
    "    .select(\n",
    "        \"__index_level_0__\",\n",
    "        F.col(\"distance\").alias(\"nearest_park_distance\"),\n",
    "        F.col(\"name\").alias(\"nearest_park_name\"),\n",
    "        F.col(\"sa2_name\").alias(\"park_sa2_name\")\n",
    "    )\n",
    "\n",
    "# Join back to the original domain data\n",
    "final_result = domain.join(nearest_park, on=\"__index_level_0__\")\n",
    "\n",
    "# Show the result for validation\n",
    "final_result.select(\n",
    "    \"address\", \n",
    "    \"extracted_price\", \n",
    "    \"nearest_park_distance\", \n",
    "    \"nearest_park_name\", \n",
    "    \"property_sa2_name\", \n",
    "    \"park_sa2_name\"\n",
    ") \\\n",
    "    .orderBy(\"nearest_park_distance\") \\\n",
    "    .show(10, truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:24:29.820608Z",
     "start_time": "2024-09-23T13:24:19.446675Z"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:24:29.835493Z",
     "start_time": "2024-09-23T13:24:29.822176Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\('\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\('\n",
      "/var/folders/_7/sr3p02zn35v2xg1fm8dsbz6c0000gn/T/ipykernel_1165/2575708135.py:1: SyntaxWarning: invalid escape sequence '\\('\n",
      "  '''from pyspark.sql import functions as F\n"
     ]
    },
    {
     "data": {
      "text/plain": "'from pyspark.sql import functions as F\\nfrom pyspark.sql.types import DoubleType\\nfrom math import radians, sin, cos, sqrt, atan2\\n\\n# Helper function to parse geometry\\ndef parse_geometry(geom):\\n    coords = F.split(F.regexp_extract(geom, r\"POINT\\\\((.*?)\\\\)\", 1), \" \")\\n    return F.struct(\\n        coords[0].cast(DoubleType()).alias(\"longitude\"),\\n        coords[1].cast(DoubleType()).alias(\"latitude\")\\n    )\\n\\n# Haversine distance function with null handling\\n@F.udf(returnType=DoubleType())\\ndef haversine_distance(lat1, lon1, lat2, lon2):\\n    if lat1 is None or lon1 is None or lat2 is None or lon2 is None:\\n        return None\\n    \\n    R = 6371  # Earth\\'s radius in kilometers\\n    \\n    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\\n    dlat = lat2 - lat1\\n    dlon = lon2 - lon1\\n    \\n    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\\n    c = 2 * atan2(sqrt(a), sqrt(1-a))\\n    return R * c\\n\\n# Load data\\nparkres = spark.read.csv(\\'../data/curated/parkres/parkres.csv\\', header=True, inferSchema=True)\\ndomain = spark.read.parquet(\\'../data/curated/domain_data\\')\\n\\n# Display schema and sample data\\nprint(\"parkres schema:\")\\nparkres.printSchema()\\nprint(\"\\nSample parkres data:\")\\nparkres.show(5, truncate=False)\\n\\nprint(\"\\ndomain schema:\")\\ndomain.printSchema()\\nprint(\"\\nSample domain data:\")\\ndomain.show(5, truncate=False)\\n\\n# Parse geometry for parkres\\nparkres = parkres.withColumn(\"park_coords\", parse_geometry(F.col(\"geometry\")))\\n\\n# Prepare domain data\\ndomain = domain.select(\\n    \"url\", \"extracted_price\", \\n    F.col(\"latitude\").cast(DoubleType()),\\n    F.col(\"longitude\").cast(DoubleType())\\n).withColumn(\"property_coords\", F.struct(\"latitude\", \"longitude\"))\\n\\n# Calculate distances using cross join\\ncrossed = domain.crossJoin(F.broadcast(parkres))\\nwith_distances = crossed.withColumn(\"distance_to_park\",\\n    haversine_distance(\\n        F.col(\"property_coords.latitude\"), F.col(\"property_coords.longitude\"),\\n        F.col(\"park_coords.latitude\"), F.col(\"park_coords.longitude\")\\n    )\\n)\\n\\n# Find nearest park for each property\\nnearest_park = with_distances.groupBy(\"url\").agg(\\n    F.min(\"distance_to_park\").alias(\"nearest_park_distance\")\\n)\\n\\n# Join back to get full property data with nearest park distance\\nresult = domain.join(nearest_park, on=\"url\")\\n\\n# Analyze by distance ranges\\nanalysis = result.groupBy(F.round(F.col(\"nearest_park_distance\")).alias(\"distance_km\"))     .agg(\\n        F.avg(\"extracted_price\").alias(\"avg_price\"),\\n        F.count(\"url\").alias(\"property_count\")\\n    )     .orderBy(\"distance_km\")\\n\\n# Show results\\nprint(\"\\nFinal analysis:\")\\nanalysis.show()\\n\\n# Optional: Count null distances\\nnull_distances = result.filter(F.col(\"nearest_park_distance\").isNull()).count()\\nprint(f\"\\nNumber of properties with null distances: {null_distances}\")'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# Helper function to parse geometry\n",
    "def parse_geometry(geom):\n",
    "    coords = F.split(F.regexp_extract(geom, r\"POINT\\((.*?)\\)\", 1), \" \")\n",
    "    return F.struct(\n",
    "        coords[0].cast(DoubleType()).alias(\"longitude\"),\n",
    "        coords[1].cast(DoubleType()).alias(\"latitude\")\n",
    "    )\n",
    "\n",
    "# Haversine distance function with null handling\n",
    "@F.udf(returnType=DoubleType())\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    if lat1 is None or lon1 is None or lat2 is None or lon2 is None:\n",
    "        return None\n",
    "    \n",
    "    R = 6371  # Earth's radius in kilometers\n",
    "    \n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    return R * c\n",
    "\n",
    "# Load data\n",
    "parkres = spark.read.csv('../data/curated/parkres/parkres.csv', header=True, inferSchema=True)\n",
    "domain = spark.read.parquet('../data/curated/domain_data')\n",
    "\n",
    "# Display schema and sample data\n",
    "print(\"parkres schema:\")\n",
    "parkres.printSchema()\n",
    "print(\"\\nSample parkres data:\")\n",
    "parkres.show(5, truncate=False)\n",
    "\n",
    "print(\"\\ndomain schema:\")\n",
    "domain.printSchema()\n",
    "print(\"\\nSample domain data:\")\n",
    "domain.show(5, truncate=False)\n",
    "\n",
    "# Parse geometry for parkres\n",
    "parkres = parkres.withColumn(\"park_coords\", parse_geometry(F.col(\"geometry\")))\n",
    "\n",
    "# Prepare domain data\n",
    "domain = domain.select(\n",
    "    \"url\", \"extracted_price\", \n",
    "    F.col(\"latitude\").cast(DoubleType()),\n",
    "    F.col(\"longitude\").cast(DoubleType())\n",
    ").withColumn(\"property_coords\", F.struct(\"latitude\", \"longitude\"))\n",
    "\n",
    "# Calculate distances using cross join\n",
    "crossed = domain.crossJoin(F.broadcast(parkres))\n",
    "with_distances = crossed.withColumn(\"distance_to_park\",\n",
    "    haversine_distance(\n",
    "        F.col(\"property_coords.latitude\"), F.col(\"property_coords.longitude\"),\n",
    "        F.col(\"park_coords.latitude\"), F.col(\"park_coords.longitude\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Find nearest park for each property\n",
    "nearest_park = with_distances.groupBy(\"url\").agg(\n",
    "    F.min(\"distance_to_park\").alias(\"nearest_park_distance\")\n",
    ")\n",
    "\n",
    "# Join back to get full property data with nearest park distance\n",
    "result = domain.join(nearest_park, on=\"url\")\n",
    "\n",
    "# Analyze by distance ranges\n",
    "analysis = result.groupBy(F.round(F.col(\"nearest_park_distance\")).alias(\"distance_km\")) \\\n",
    "    .agg(\n",
    "        F.avg(\"extracted_price\").alias(\"avg_price\"),\n",
    "        F.count(\"url\").alias(\"property_count\")\n",
    "    ) \\\n",
    "    .orderBy(\"distance_km\")\n",
    "\n",
    "# Show results\n",
    "print(\"\\nFinal analysis:\")\n",
    "analysis.show()\n",
    "\n",
    "# Optional: Count null distances\n",
    "null_distances = result.filter(F.col(\"nearest_park_distance\").isNull()).count()\n",
    "print(f\"\\nNumber of properties with null distances: {null_distances}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:24:29.842028Z",
     "start_time": "2024-09-23T13:24:29.836861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'import geopandas as gpd\\nfrom shapely.geometry import Point\\nfrom shapely import wkt\\nimport pandas as pd\\n\\n# Step 1: Inspect the domain dataset\\nprint(domain.show(5))  # Show a few rows to ensure data exists in \\'latitude\\' and \\'longitude\\'\\n\\n# Convert Spark DataFrame to Pandas\\ndomain_pd = domain.select(\\'url\\', \\'latitude\\', \\'longitude\\').toPandas()\\n\\n# Step 2: Check for null values in domain\\'s latitude and longitude\\nprint(\"Checking for null values in domain dataset:\")\\nprint(domain_pd.isnull().sum())  # This will show if there are any null latitudes or longitudes\\n\\n# Step 3: Check if lat/lon columns are valid in the domain\\ndomain_pd = domain_pd.dropna(subset=[\\'latitude\\', \\'longitude\\'])\\nprint(f\"Number of valid rows in domain dataset after dropping nulls: {len(domain_pd)}\")\\n\\n# Step 4: Inspect the parkres dataset\\nprint(parkres.show(5))  # Show a few rows to ensure data exists in \\'geometry\\'\\n\\n# Convert Spark DataFrame to Pandas\\nparkres_pd = parkres.select(\\'sa2_name\\', \\'geometry\\').toPandas()\\n\\n# Step 5: Check for null values in parkres dataset\\nprint(\"Checking for null values in parkres dataset:\")\\nprint(parkres_pd.isnull().sum())  # This will show if there are any null geometries\\n\\n# Step 6: Check if geometry column is valid in parkres\\nparkres_pd = parkres_pd.dropna(subset=[\\'geometry\\'])\\nprint(f\"Number of valid rows in parkres dataset after dropping null geometries: {len(parkres_pd)}\")\\n\\n# Step 7: Try converting both datasets to GeoDataFrames\\nif not domain_pd.empty and not parkres_pd.empty:\\n    # Create GeoDataFrame for domain\\n    domain_gdf = gpd.GeoDataFrame(domain_pd, geometry=gpd.points_from_xy(domain_pd.longitude, domain_pd.latitude), crs=\"EPSG:4326\")\\n\\n    # Create GeoDataFrame for parkres\\n    parkres_gdf = gpd.GeoDataFrame(parkres_pd, geometry=parkres_pd[\\'geometry\\'].apply(wkt.loads), crs=\"EPSG:4326\")\\n\\n    print(\"Successfully created GeoDataFrames for both datasets.\")\\nelse:\\n    print(\"One of the datasets is still empty after handling missing values.\")'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkt\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Inspect the domain dataset\n",
    "print(domain.show(5))  # Show a few rows to ensure data exists in 'latitude' and 'longitude'\n",
    "\n",
    "# Convert Spark DataFrame to Pandas\n",
    "domain_pd = domain.select('url', 'latitude', 'longitude').toPandas()\n",
    "\n",
    "# Step 2: Check for null values in domain's latitude and longitude\n",
    "print(\"Checking for null values in domain dataset:\")\n",
    "print(domain_pd.isnull().sum())  # This will show if there are any null latitudes or longitudes\n",
    "\n",
    "# Step 3: Check if lat/lon columns are valid in the domain\n",
    "domain_pd = domain_pd.dropna(subset=['latitude', 'longitude'])\n",
    "print(f\"Number of valid rows in domain dataset after dropping nulls: {len(domain_pd)}\")\n",
    "\n",
    "# Step 4: Inspect the parkres dataset\n",
    "print(parkres.show(5))  # Show a few rows to ensure data exists in 'geometry'\n",
    "\n",
    "# Convert Spark DataFrame to Pandas\n",
    "parkres_pd = parkres.select('sa2_name', 'geometry').toPandas()\n",
    "\n",
    "# Step 5: Check for null values in parkres dataset\n",
    "print(\"Checking for null values in parkres dataset:\")\n",
    "print(parkres_pd.isnull().sum())  # This will show if there are any null geometries\n",
    "\n",
    "# Step 6: Check if geometry column is valid in parkres\n",
    "parkres_pd = parkres_pd.dropna(subset=['geometry'])\n",
    "print(f\"Number of valid rows in parkres dataset after dropping null geometries: {len(parkres_pd)}\")\n",
    "\n",
    "# Step 7: Try converting both datasets to GeoDataFrames\n",
    "if not domain_pd.empty and not parkres_pd.empty:\n",
    "    # Create GeoDataFrame for domain\n",
    "    domain_gdf = gpd.GeoDataFrame(domain_pd, geometry=gpd.points_from_xy(domain_pd.longitude, domain_pd.latitude), crs=\"EPSG:4326\")\n",
    "\n",
    "    # Create GeoDataFrame for parkres\n",
    "    parkres_gdf = gpd.GeoDataFrame(parkres_pd, geometry=parkres_pd['geometry'].apply(wkt.loads), crs=\"EPSG:4326\")\n",
    "\n",
    "    print(\"Successfully created GeoDataFrames for both datasets.\")\n",
    "else:\n",
    "    print(\"One of the datasets is still empty after handling missing values.\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:24:29.847323Z",
     "start_time": "2024-09-23T13:24:29.843603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'from pyspark.sql import functions as F\\nfrom pyspark.sql.types import DoubleType\\nfrom shapely import wkb, wkt\\nfrom shapely.ops import nearest_points\\n\\n# Define UDF for geospatial operations\\n@F.udf(returnType=DoubleType())\\ndef calculate_distance(lat, lon, park_geom_wkt):\\n    point = wkt.loads(f\"POINT({lon} {lat})\")\\n    park = wkt.loads(park_geom_wkt)\\n    nearest_point = nearest_points(point, park.exterior)[1]\\n    return point.distance(nearest_point) * 111000  # Approximate conversion to meters\\n\\n# Convert binary WKB to WKT\\ndef wkb_to_wkt(wkb_value):\\n    if wkb_value is None:\\n        return None\\n    return wkb.loads(wkb_value).wkt\\n\\nwkb_to_wkt_udf = F.udf(wkb_to_wkt, returnType=F.StringType())\\n\\n# Prepare domain DataFrame\\ndomain_prepared = domain.withColumn(\"domain_geometry_wkt\", wkb_to_wkt_udf(F.col(\"geometry\")))\\n\\n# Rename parkres geometry column to avoid conflict\\nparkres_prepared = parkres.withColumnRenamed(\"geometry\", \"park_geometry\")\\n\\n# Cross join domain with parkres\\njoined = domain_prepared.crossJoin(parkres_prepared)\\n\\n# Calculate distances\\njoined = joined.withColumn(\"distance\", \\n                           calculate_distance(F.col(\"latitude\"), \\n                                              F.col(\"longitude\"), \\n                                              F.col(\"park_geometry\")))\\n\\n# Find the minimum distance for each domain entry\\nresult = joined.groupBy(\"url\", \"address\", \"__index_level_0__\")     .agg(F.min(\"distance\").alias(\"min_distance_to_park_border\"), \\n         F.first(\"name\").alias(\"nearest_park_name\"))\\n\\n# Show the results\\nresult.show(truncate=False)\\n\\n# If you want to save the results\\n# result.write.parquet(\"path/to/save/results.parquet\")'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType\n",
    "from shapely import wkb, wkt\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "# Define UDF for geospatial operations\n",
    "@F.udf(returnType=DoubleType())\n",
    "def calculate_distance(lat, lon, park_geom_wkt):\n",
    "    point = wkt.loads(f\"POINT({lon} {lat})\")\n",
    "    park = wkt.loads(park_geom_wkt)\n",
    "    nearest_point = nearest_points(point, park.exterior)[1]\n",
    "    return point.distance(nearest_point) * 111000  # Approximate conversion to meters\n",
    "\n",
    "# Convert binary WKB to WKT\n",
    "def wkb_to_wkt(wkb_value):\n",
    "    if wkb_value is None:\n",
    "        return None\n",
    "    return wkb.loads(wkb_value).wkt\n",
    "\n",
    "wkb_to_wkt_udf = F.udf(wkb_to_wkt, returnType=F.StringType())\n",
    "\n",
    "# Prepare domain DataFrame\n",
    "domain_prepared = domain.withColumn(\"domain_geometry_wkt\", wkb_to_wkt_udf(F.col(\"geometry\")))\n",
    "\n",
    "# Rename parkres geometry column to avoid conflict\n",
    "parkres_prepared = parkres.withColumnRenamed(\"geometry\", \"park_geometry\")\n",
    "\n",
    "# Cross join domain with parkres\n",
    "joined = domain_prepared.crossJoin(parkres_prepared)\n",
    "\n",
    "# Calculate distances\n",
    "joined = joined.withColumn(\"distance\", \n",
    "                           calculate_distance(F.col(\"latitude\"), \n",
    "                                              F.col(\"longitude\"), \n",
    "                                              F.col(\"park_geometry\")))\n",
    "\n",
    "# Find the minimum distance for each domain entry\n",
    "result = joined.groupBy(\"url\", \"address\", \"__index_level_0__\") \\\n",
    "    .agg(F.min(\"distance\").alias(\"min_distance_to_park_border\"), \n",
    "         F.first(\"name\").alias(\"nearest_park_name\"))\n",
    "\n",
    "# Show the results\n",
    "result.show(truncate=False)\n",
    "\n",
    "# If you want to save the results\n",
    "# result.write.parquet(\"path/to/save/results.parquet\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:24:29.862070Z",
     "start_time": "2024-09-23T13:24:29.857783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'from pyspark.sql import functions as F\\nfrom pyspark.sql.types import DoubleType\\nfrom shapely import wkb, wkt\\nfrom shapely.ops import nearest_points\\nimport math\\n\\n# Define the Haversine formula to calculate distance in meters between two lat/lon points\\ndef haversine_distance(lat1, lon1, lat2, lon2):\\n    R = 6371000  # Radius of Earth in meters\\n    phi1 = math.radians(lat1)\\n    phi2 = math.radians(lat2)\\n    delta_phi = math.radians(lat2 - lat1)\\n    delta_lambda = math.radians(lon2 - lon1)\\n\\n    a = math.sin(delta_phi / 2) ** 2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2) ** 2\\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\\n\\n    return R * c  # Distance in meters\\n\\n# Define UDF for geospatial operations using Haversine formula\\n@F.udf(returnType=DoubleType())\\ndef calculate_distance(lat, lon, park_geom_wkt):\\n    point = wkt.loads(f\"POINT({lon} {lat})\")\\n    park = wkt.loads(park_geom_wkt)\\n    \\n    # Find the nearest point on the park boundary\\n    nearest_point = nearest_points(point, park.exterior)[1]\\n    \\n    # Calculate the Haversine distance between the property point and nearest park point\\n    return haversine_distance(lat, lon, nearest_point.y, nearest_point.x)\\n\\n# Convert binary WKB to WKT\\ndef wkb_to_wkt(wkb_value):\\n    if wkb_value is None:\\n        return None\\n    return wkb.loads(wkb_value).wkt\\n\\nwkb_to_wkt_udf = F.udf(wkb_to_wkt, returnType=F.StringType())\\n\\n# Prepare domain DataFrame\\ndomain_prepared = domain.withColumn(\"domain_geometry_wkt\", wkb_to_wkt_udf(F.col(\"geometry\")))\\n\\n# Rename parkres geometry column to avoid conflict\\nparkres_prepared = parkres.withColumnRenamed(\"geometry\", \"park_geometry\")\\n\\n# Cross join domain with parkres\\njoined = domain_prepared.crossJoin(parkres_prepared)\\n\\n# Calculate distances using the improved method (Haversine formula)\\njoined = joined.withColumn(\"distance\", \\n                           calculate_distance(F.col(\"latitude\"), \\n                                              F.col(\"longitude\"), \\n                                              F.col(\"park_geometry\")))\\n\\n# Find the minimum distance for each domain entry\\nresult = joined.groupBy(\"url\", \"address\", \"__index_level_0__\")     .agg(F.min(\"distance\").alias(\"min_distance_to_park_border\"), \\n         F.first(\"name\").alias(\"nearest_park_name\"))\\n\\n# Show the results\\nresult.show(truncate=False)\\n\\n# Optional: Save the results if needed\\n# result.write.parquet(\"path/to/save/results.parquet\")'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType\n",
    "from shapely import wkb, wkt\n",
    "from shapely.ops import nearest_points\n",
    "import math\n",
    "\n",
    "# Define the Haversine formula to calculate distance in meters between two lat/lon points\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  # Radius of Earth in meters\n",
    "    phi1 = math.radians(lat1)\n",
    "    phi2 = math.radians(lat2)\n",
    "    delta_phi = math.radians(lat2 - lat1)\n",
    "    delta_lambda = math.radians(lon2 - lon1)\n",
    "\n",
    "    a = math.sin(delta_phi / 2) ** 2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    return R * c  # Distance in meters\n",
    "\n",
    "# Define UDF for geospatial operations using Haversine formula\n",
    "@F.udf(returnType=DoubleType())\n",
    "def calculate_distance(lat, lon, park_geom_wkt):\n",
    "    point = wkt.loads(f\"POINT({lon} {lat})\")\n",
    "    park = wkt.loads(park_geom_wkt)\n",
    "    \n",
    "    # Find the nearest point on the park boundary\n",
    "    nearest_point = nearest_points(point, park.exterior)[1]\n",
    "    \n",
    "    # Calculate the Haversine distance between the property point and nearest park point\n",
    "    return haversine_distance(lat, lon, nearest_point.y, nearest_point.x)\n",
    "\n",
    "# Convert binary WKB to WKT\n",
    "def wkb_to_wkt(wkb_value):\n",
    "    if wkb_value is None:\n",
    "        return None\n",
    "    return wkb.loads(wkb_value).wkt\n",
    "\n",
    "wkb_to_wkt_udf = F.udf(wkb_to_wkt, returnType=F.StringType())\n",
    "\n",
    "# Prepare domain DataFrame\n",
    "domain_prepared = domain.withColumn(\"domain_geometry_wkt\", wkb_to_wkt_udf(F.col(\"geometry\")))\n",
    "\n",
    "# Rename parkres geometry column to avoid conflict\n",
    "parkres_prepared = parkres.withColumnRenamed(\"geometry\", \"park_geometry\")\n",
    "\n",
    "# Cross join domain with parkres\n",
    "joined = domain_prepared.crossJoin(parkres_prepared)\n",
    "\n",
    "# Calculate distances using the improved method (Haversine formula)\n",
    "joined = joined.withColumn(\"distance\", \n",
    "                           calculate_distance(F.col(\"latitude\"), \n",
    "                                              F.col(\"longitude\"), \n",
    "                                              F.col(\"park_geometry\")))\n",
    "\n",
    "# Find the minimum distance for each domain entry\n",
    "result = joined.groupBy(\"url\", \"address\", \"__index_level_0__\") \\\n",
    "    .agg(F.min(\"distance\").alias(\"min_distance_to_park_border\"), \n",
    "         F.first(\"name\").alias(\"nearest_park_name\"))\n",
    "\n",
    "# Show the results\n",
    "result.show(truncate=False)\n",
    "\n",
    "# Optional: Save the results if needed\n",
    "# result.write.parquet(\"path/to/save/results.parquet\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:24:29.866955Z",
     "start_time": "2024-09-23T13:24:29.863271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'from pyspark.sql.functions import udf\\nfrom pyspark.sql.types import DoubleType, StringType\\nfrom shapely import wkb, wkt\\nimport math\\n\\ndef haversine_distance(lat1, lon1, lat2, lon2):\\n    R = 6371  # Radius of Earth in kilometers\\n    \\n    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\\n    \\n    dlat = lat2 - lat1\\n    dlon = lon2 - lon1\\n    \\n    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\\n    c = 2 * math.asin(math.sqrt(a))\\n    \\n    return R * c * 1000  # Distance in meters\\n\\n@udf(returnType=DoubleType())\\ndef calculate_distance(lat, lon, park_geom_wkt):\\n    if lat is None or lon is None or park_geom_wkt is None:\\n        return None\\n    \\n    point = wkt.loads(f\"POINT({lon} {lat})\")\\n    park = wkt.loads(park_geom_wkt)\\n    \\n    # Find the nearest point on the park boundary\\n    nearest_point = park.exterior.interpolate(park.exterior.project(point))\\n    \\n    return haversine_distance(lat, lon, nearest_point.y, nearest_point.x)\\n\\n@udf(returnType=StringType())\\ndef wkb_to_wkt(wkb_value):\\n    if wkb_value is None:\\n        return None\\n    return wkb.loads(wkb_value).wkt\\n\\n# Prepare domain DataFrame\\ndomain_prepared = domain.withColumn(\"domain_geometry_wkt\", wkb_to_wkt(domain.geometry))\\n\\n# Rename parkres geometry column to avoid conflict\\nparkres_prepared = parkres.withColumnRenamed(\"geometry\", \"park_geometry\")\\n\\n# Join domain with parkres\\njoined = domain_prepared.crossJoin(parkres_prepared)\\n\\n# Calculate distances\\njoined = joined.withColumn(\"distance\",\\n                           calculate_distance(joined.latitude,\\n                                              joined.longitude,\\n                                              joined.park_geometry))\\n\\n# Find the minimum distance for each domain entry\\nresult = joined.groupBy(\"url\", \"address\", \"__index_level_0__\")     .agg({\"distance\": \"min\", \"name\": \"first\"})     .withColumnRenamed(\"min(distance)\", \"min_distance_to_park_border\")     .withColumnRenamed(\"first(name)\", \"nearest_park_name\")\\n\\n# Show the results\\nresult.show(truncate=False)\\n\\n# Optional: Save the results if needed\\n# result.write.parquet(\"path/to/save/results.parquet\")'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "from shapely import wkb, wkt\n",
    "import math\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radius of Earth in kilometers\n",
    "    \n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    \n",
    "    return R * c * 1000  # Distance in meters\n",
    "\n",
    "@udf(returnType=DoubleType())\n",
    "def calculate_distance(lat, lon, park_geom_wkt):\n",
    "    if lat is None or lon is None or park_geom_wkt is None:\n",
    "        return None\n",
    "    \n",
    "    point = wkt.loads(f\"POINT({lon} {lat})\")\n",
    "    park = wkt.loads(park_geom_wkt)\n",
    "    \n",
    "    # Find the nearest point on the park boundary\n",
    "    nearest_point = park.exterior.interpolate(park.exterior.project(point))\n",
    "    \n",
    "    return haversine_distance(lat, lon, nearest_point.y, nearest_point.x)\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def wkb_to_wkt(wkb_value):\n",
    "    if wkb_value is None:\n",
    "        return None\n",
    "    return wkb.loads(wkb_value).wkt\n",
    "\n",
    "# Prepare domain DataFrame\n",
    "domain_prepared = domain.withColumn(\"domain_geometry_wkt\", wkb_to_wkt(domain.geometry))\n",
    "\n",
    "# Rename parkres geometry column to avoid conflict\n",
    "parkres_prepared = parkres.withColumnRenamed(\"geometry\", \"park_geometry\")\n",
    "\n",
    "# Join domain with parkres\n",
    "joined = domain_prepared.crossJoin(parkres_prepared)\n",
    "\n",
    "# Calculate distances\n",
    "joined = joined.withColumn(\"distance\",\n",
    "                           calculate_distance(joined.latitude,\n",
    "                                              joined.longitude,\n",
    "                                              joined.park_geometry))\n",
    "\n",
    "# Find the minimum distance for each domain entry\n",
    "result = joined.groupBy(\"url\", \"address\", \"__index_level_0__\") \\\n",
    "    .agg({\"distance\": \"min\", \"name\": \"first\"}) \\\n",
    "    .withColumnRenamed(\"min(distance)\", \"min_distance_to_park_border\") \\\n",
    "    .withColumnRenamed(\"first(name)\", \"nearest_park_name\")\n",
    "\n",
    "# Show the results\n",
    "result.show(truncate=False)\n",
    "\n",
    "# Optional: Save the results if needed\n",
    "# result.write.parquet(\"path/to/save/results.parquet\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:24:30.335402Z",
     "start_time": "2024-09-23T13:24:29.868659Z"
    }
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `latitude` cannot be resolved. Did you mean one of the following? [`Baths`, `aus_code`, `bond`, `loci_uri`, `postcode`].;\n'Project [url#53, price#54, address#55, property_type#56, prop_lat#693, prop_lon#723, Beds#59, Baths#60, Parking#61, bond#62, extracted_price#63, geometry#64, sa2_code#65, property_sa2_name#753, chg_flag#67, chg_lbl#68, sa3_code#69, sa3_name#70, sa4_code#71, sa4_name#72, gcc_code#73, gcc_name#74, ste_code#75, ste_name#76, ... 14 more fields]\n+- Join Cross\n   :- Project [url#53, price#54, address#55, property_type#56, prop_lat#693, prop_lon#723, Beds#59, Baths#60, Parking#61, bond#62, extracted_price#63, geometry#64, sa2_code#65, property_sa2_name#753, chg_flag#67, chg_lbl#68, sa3_code#69, sa3_name#70, sa4_code#71, sa4_name#72, gcc_code#73, gcc_name#74, ste_code#75, ste_name#76, ... 6 more fields]\n   :  +- Project [url#53, price#54, address#55, property_type#56, prop_lat#693, prop_lon#723, Beds#59, Baths#60, Parking#61, bond#62, extracted_price#63, geometry#64, sa2_code#65, sa2_name#66 AS property_sa2_name#753, chg_flag#67, chg_lbl#68, sa3_code#69, sa3_name#70, sa4_code#71, sa4_name#72, gcc_code#73, gcc_name#74, ste_code#75, ste_name#76, ... 5 more fields]\n   :     +- Project [url#53, price#54, address#55, property_type#56, prop_lat#693, longitude#58 AS prop_lon#723, Beds#59, Baths#60, Parking#61, bond#62, extracted_price#63, geometry#64, sa2_code#65, sa2_name#66, chg_flag#67, chg_lbl#68, sa3_code#69, sa3_name#70, sa4_code#71, sa4_name#72, gcc_code#73, gcc_name#74, ste_code#75, ste_name#76, ... 5 more fields]\n   :        +- Project [url#53, price#54, address#55, property_type#56, latitude#57 AS prop_lat#693, longitude#58, Beds#59, Baths#60, Parking#61, bond#62, extracted_price#63, geometry#64, sa2_code#65, sa2_name#66, chg_flag#67, chg_lbl#68, sa3_code#69, sa3_name#70, sa4_code#71, sa4_name#72, gcc_code#73, gcc_name#74, ste_code#75, ste_name#76, ... 5 more fields]\n   :           +- Relation [url#53,price#54,address#55,property_type#56,latitude#57,longitude#58,Beds#59,Baths#60,Parking#61,bond#62,extracted_price#63,geometry#64,sa2_code#65,sa2_name#66,chg_flag#67,chg_lbl#68,sa3_code#69,sa3_name#70,sa4_code#71,sa4_name#72,gcc_code#73,gcc_name#74,ste_code#75,ste_name#76,... 5 more fields] parquet\n   +- Project [name#18, sa2_name#19, postcode#20, park_geometry#666, park_centroid#672, park_centroid_lat#678, cast(split(park_centroid#672, ,, -1)[1] as double) AS park_centroid_lon#685]\n      +- Project [name#18, sa2_name#19, postcode#20, park_geometry#666, park_centroid#672, cast(split(park_centroid#672, ,, -1)[0] as double) AS park_centroid_lat#678]\n         +- Project [name#18, sa2_name#19, postcode#20, park_geometry#666, get_centroid(park_geometry#666)#671 AS park_centroid#672]\n            +- Project [name#18, sa2_name#19, postcode#20, geometry#21 AS park_geometry#666]\n               +- Project [name#18, sa2_name#19, postcode#20, geometry#21]\n                  +- Relation [_c0#17,name#18,sa2_name#19,postcode#20,geometry#21] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 57\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# Calculate distances\u001B[39;00m\n\u001B[1;32m     56\u001B[0m distance_calc \u001B[38;5;241m=\u001B[39m calculate_distance(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlatitude\u001B[39m\u001B[38;5;124m\"\u001B[39m), col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlongitude\u001B[39m\u001B[38;5;124m\"\u001B[39m), col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpark_geometry\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m---> 57\u001B[0m joined \u001B[38;5;241m=\u001B[39m \u001B[43mjoined\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwithColumn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdistance_result\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdistance_calc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m joined \u001B[38;5;241m=\u001B[39m joined\u001B[38;5;241m.\u001B[39mwithColumn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdistance\u001B[39m\u001B[38;5;124m\"\u001B[39m, col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdistance_result.distance\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m     59\u001B[0m joined \u001B[38;5;241m=\u001B[39m joined\u001B[38;5;241m.\u001B[39mwithColumn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdistance_error\u001B[39m\u001B[38;5;124m\"\u001B[39m, col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdistance_result.error\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "File \u001B[0;32m~/PycharmProjects/project-2-group-real-estate-industry-project-3/.venv/lib/python3.12/site-packages/pyspark/sql/dataframe.py:5176\u001B[0m, in \u001B[0;36mDataFrame.withColumn\u001B[0;34m(self, colName, col)\u001B[0m\n\u001B[1;32m   5171\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(col, Column):\n\u001B[1;32m   5172\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n\u001B[1;32m   5173\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNOT_COLUMN\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   5174\u001B[0m         message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcol\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(col)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n\u001B[1;32m   5175\u001B[0m     )\n\u001B[0;32m-> 5176\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwithColumn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcolName\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcol\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jc\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
      "File \u001B[0;32m~/PycharmProjects/project-2-group-real-estate-industry-project-3/.venv/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/PycharmProjects/project-2-group-real-estate-industry-project-3/.venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:185\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    181\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 185\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `latitude` cannot be resolved. Did you mean one of the following? [`Baths`, `aus_code`, `bond`, `loci_uri`, `postcode`].;\n'Project [url#53, price#54, address#55, property_type#56, prop_lat#693, prop_lon#723, Beds#59, Baths#60, Parking#61, bond#62, extracted_price#63, geometry#64, sa2_code#65, property_sa2_name#753, chg_flag#67, chg_lbl#68, sa3_code#69, sa3_name#70, sa4_code#71, sa4_name#72, gcc_code#73, gcc_name#74, ste_code#75, ste_name#76, ... 14 more fields]\n+- Join Cross\n   :- Project [url#53, price#54, address#55, property_type#56, prop_lat#693, prop_lon#723, Beds#59, Baths#60, Parking#61, bond#62, extracted_price#63, geometry#64, sa2_code#65, property_sa2_name#753, chg_flag#67, chg_lbl#68, sa3_code#69, sa3_name#70, sa4_code#71, sa4_name#72, gcc_code#73, gcc_name#74, ste_code#75, ste_name#76, ... 6 more fields]\n   :  +- Project [url#53, price#54, address#55, property_type#56, prop_lat#693, prop_lon#723, Beds#59, Baths#60, Parking#61, bond#62, extracted_price#63, geometry#64, sa2_code#65, sa2_name#66 AS property_sa2_name#753, chg_flag#67, chg_lbl#68, sa3_code#69, sa3_name#70, sa4_code#71, sa4_name#72, gcc_code#73, gcc_name#74, ste_code#75, ste_name#76, ... 5 more fields]\n   :     +- Project [url#53, price#54, address#55, property_type#56, prop_lat#693, longitude#58 AS prop_lon#723, Beds#59, Baths#60, Parking#61, bond#62, extracted_price#63, geometry#64, sa2_code#65, sa2_name#66, chg_flag#67, chg_lbl#68, sa3_code#69, sa3_name#70, sa4_code#71, sa4_name#72, gcc_code#73, gcc_name#74, ste_code#75, ste_name#76, ... 5 more fields]\n   :        +- Project [url#53, price#54, address#55, property_type#56, latitude#57 AS prop_lat#693, longitude#58, Beds#59, Baths#60, Parking#61, bond#62, extracted_price#63, geometry#64, sa2_code#65, sa2_name#66, chg_flag#67, chg_lbl#68, sa3_code#69, sa3_name#70, sa4_code#71, sa4_name#72, gcc_code#73, gcc_name#74, ste_code#75, ste_name#76, ... 5 more fields]\n   :           +- Relation [url#53,price#54,address#55,property_type#56,latitude#57,longitude#58,Beds#59,Baths#60,Parking#61,bond#62,extracted_price#63,geometry#64,sa2_code#65,sa2_name#66,chg_flag#67,chg_lbl#68,sa3_code#69,sa3_name#70,sa4_code#71,sa4_name#72,gcc_code#73,gcc_name#74,ste_code#75,ste_name#76,... 5 more fields] parquet\n   +- Project [name#18, sa2_name#19, postcode#20, park_geometry#666, park_centroid#672, park_centroid_lat#678, cast(split(park_centroid#672, ,, -1)[1] as double) AS park_centroid_lon#685]\n      +- Project [name#18, sa2_name#19, postcode#20, park_geometry#666, park_centroid#672, cast(split(park_centroid#672, ,, -1)[0] as double) AS park_centroid_lat#678]\n         +- Project [name#18, sa2_name#19, postcode#20, park_geometry#666, get_centroid(park_geometry#666)#671 AS park_centroid#672]\n            +- Project [name#18, sa2_name#19, postcode#20, geometry#21 AS park_geometry#666]\n               +- Project [name#18, sa2_name#19, postcode#20, geometry#21]\n                  +- Relation [_c0#17,name#18,sa2_name#19,postcode#20,geometry#21] csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, col, lit\n",
    "from pyspark.sql.types import DoubleType, StringType, StructType, StructField\n",
    "import shapely\n",
    "from shapely import wkb, wkt\n",
    "from pyproj import Geod\n",
    "import sys\n",
    "\n",
    "# Use WGS84 ellipsoid for distance calculations\n",
    "geod = Geod(ellps=\"WGS84\")\n",
    "\n",
    "# Define a struct to return both distance and error message\n",
    "result_schema = StructType([\n",
    "    StructField(\"distance\", DoubleType(), True),\n",
    "    StructField(\"error\", StringType(), True)\n",
    "])\n",
    "\n",
    "@udf(returnType=result_schema)\n",
    "def calculate_distance(lat, lon, park_geom_wkt):\n",
    "    try:\n",
    "        if lat is None or lon is None or park_geom_wkt is None:\n",
    "            return (None, \"One or more input values are None\")\n",
    "        \n",
    "        lat, lon = float(lat), float(lon)\n",
    "        point = wkt.loads(f\"POINT({lon} {lat})\")\n",
    "        park = wkt.loads(park_geom_wkt)\n",
    "        \n",
    "        # Find the nearest point on the park boundary\n",
    "        nearest_point = park.exterior.interpolate(park.exterior.project(point))\n",
    "        \n",
    "        # Calculate the geodesic distance\n",
    "        _, _, distance = geod.inv(lon, lat, nearest_point.x, nearest_point.y)\n",
    "        \n",
    "        return (float(distance), None)\n",
    "    except Exception as e:\n",
    "        return (None, str(e))\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def wkb_to_wkt(wkb_value):\n",
    "    try:\n",
    "        if wkb_value is None:\n",
    "            return None\n",
    "        return wkb.loads(wkb_value).wkt\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Prepare domain DataFrame\n",
    "domain_prepared = domain.withColumn(\"domain_geometry_wkt\", wkb_to_wkt(col(\"geometry\")))\n",
    "\n",
    "# Rename parkres geometry column to avoid conflict\n",
    "parkres_prepared = parkres.withColumnRenamed(\"geometry\", \"park_geometry\")\n",
    "\n",
    "# Join domain with parkres\n",
    "joined = domain_prepared.crossJoin(parkres_prepared)\n",
    "\n",
    "# Calculate distances\n",
    "distance_calc = calculate_distance(col(\"latitude\"), col(\"longitude\"), col(\"park_geometry\"))\n",
    "joined = joined.withColumn(\"distance_result\", distance_calc)\n",
    "joined = joined.withColumn(\"distance\", col(\"distance_result.distance\"))\n",
    "joined = joined.withColumn(\"distance_error\", col(\"distance_result.error\"))\n",
    "\n",
    "# Find the minimum distance for each domain entry\n",
    "result = joined.groupBy(\"url\", \"address\", \"__index_level_0__\") \\\n",
    "    .agg({\"distance\": \"min\", \"name\": \"first\", \"distance_error\": \"first\"}) \\\n",
    "    .withColumnRenamed(\"min(distance)\", \"min_distance_to_park_border\") \\\n",
    "    .withColumnRenamed(\"first(name)\", \"nearest_park_name\") \\\n",
    "    .withColumnRenamed(\"first(distance_error)\", \"error_message\")\n",
    "\n",
    "# Show the results\n",
    "result.show(truncate=False)\n",
    "\n",
    "# Optional: Save the results if needed\n",
    "# result.write.parquet(\"path/to/save/results.parquet\")\n",
    "\n",
    "# Print some debug information\n",
    "print(\"Sample of domain_geometry_wkt:\")\n",
    "domain_prepared.select(\"domain_geometry_wkt\").show(5, truncate=False)\n",
    "\n",
    "print(\"\\nSample of park_geometry:\")\n",
    "parkres_prepared.select(\"park_geometry\").show(5, truncate=False)\n",
    "\n",
    "print(\"\\nSample of latitude and longitude:\")\n",
    "domain_prepared.select(\"latitude\", \"longitude\").show(5, truncate=False)\n",
    "\n",
    "print(\"\\nUnique error messages:\")\n",
    "result.select(\"error_message\").distinct().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sqrt, pow, min as spark_min, first\n",
    "from pyspark.sql.types import DoubleType\n",
    "from math import radians\n",
    "\n",
    "# Approximate radius of earth in km\n",
    "R = 6371.0\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    # Convert decimal degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = pow(sin(dlat/2), 2) + cos(lat1) * cos(lat2) * pow(sin(dlon/2), 2)\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    distance = R * c\n",
    "    \n",
    "    return distance\n",
    "\n",
    "# Register the UDF\n",
    "haversine_udf = F.udf(haversine_distance, DoubleType())\n",
    "\n",
    "# Assuming 'domain' is your DataFrame with property data\n",
    "# and 'parkres' is your DataFrame with park data\n",
    "\n",
    "# Calculate the distance for each property-park pair\n",
    "result = domain.crossJoin(parkres) \\\n",
    "    .withColumn(\"distance\", \n",
    "                haversine_udf(\n",
    "                    col(\"latitude\"), col(\"longitude\"), \n",
    "                    col(\"park_latitude\"), col(\"park_longitude\")\n",
    "                )) \\\n",
    "    .groupBy(\"url\", \"address\", \"__index_level_0__\") \\\n",
    "    .agg(\n",
    "        spark_min(\"distance\").alias(\"min_distance_to_park_border\"),\n",
    "        first(\"park_name\").alias(\"nearest_park_name\")\n",
    "    )\n",
    "\n",
    "# Show the results\n",
    "result.show(truncate=False)\n",
    "\n",
    "# Optional: Save the results if needed\n",
    "# result.write.parquet(\"path/to/save/results.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
